{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "import itertools\n",
    "import numpy as np  # Matrix and vector computation package\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt  # Plotting library\n",
    "import seaborn as sns  # Fancier plots\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Set seaborn plotting style\n",
    "sns.set_style('darkgrid')\n",
    "# Set the seed for reproducability\n",
    "np.random.seed(seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sort_dataset(dataset_length, seq_length, max_number=999):\n",
    "    x_train = np.random.randint(low=0, high=max_number+1, size=(dataset_length, seq_length, 1))\n",
    "    y_train = np.sort(x_train, axis=1)\n",
    "    \n",
    "    x_test = np.random.randint(low=0, high=max_number+1, size=(dataset_length, seq_length, 1))\n",
    "    y_test = np.sort(x_test, axis=1)\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "def create_dummy_dataset(dataset_length, seq_length, max_number):\n",
    "    lower_bound = -1 * max_number\n",
    "    x_train = np.random.randint(low=lower_bound, high=max_number+1, size=(dataset_length, seq_length, 1))\n",
    "    y_train = np.where(x_train.sum(axis=2) > 0, 1, 0).reshape(x_train.shape)\n",
    "    \n",
    "    x_test = np.random.randint(low=lower_bound, high=max_number+1, size=(dataset_length, seq_length, 1))\n",
    "    y_test = np.where(x_test.sum(axis=2) > 0, 1, 0).reshape(x_train.shape)\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the linear tensor transformation layer\n",
    "class TensorLinear(object):\n",
    "    \"\"\"The linear tensor layer applies a linear tensor dot product \n",
    "    and a bias to its input.\"\"\"\n",
    "    def __init__(self, n_in, n_out, tensor_order, W=None, b=None):\n",
    "        \"\"\"Initialse the weight W and bias b parameters.\"\"\"\n",
    "        a = np.sqrt(6.0 / (n_in + n_out))\n",
    "        self.W = (np.random.uniform(-a, a, (n_in, n_out)) \n",
    "                  if W is None else W)\n",
    "        self.b = (np.zeros((n_out)) if b is None else b)\n",
    "        # Axes summed over in backprop\n",
    "        self.bpAxes = tuple(range(tensor_order-1))\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"Perform forward step transformation with the help \n",
    "        of a tensor product.\"\"\"\n",
    "        # Same as: Y[i,j,:] = np.dot(X[i,j,:], self.W) + self.b \n",
    "        #          (for i,j in X.shape[0:1])\n",
    "        # Same as: Y = np.einsum('ijk,kl->ijl', X, self.W) + self.b\n",
    "        return np.tensordot(X, self.W, axes=((-1),(0))) + self.b\n",
    "\n",
    "    def backward(self, X, gY):\n",
    "        \"\"\"Return the gradient of the parmeters and the inputs of \n",
    "        this layer.\"\"\"\n",
    "        # Same as: gW = np.einsum('ijk,ijl->kl', X, gY)\n",
    "        # Same as: gW += np.dot(X[:,j,:].T, gY[:,j,:]) \n",
    "        #          (for i,j in X.shape[0:1])\n",
    "        gW = np.tensordot(X, gY, axes=(self.bpAxes, self.bpAxes))\n",
    "        gB = np.sum(gY, axis=self.bpAxes)\n",
    "        # Same as: gX = np.einsum('ijk,kl->ijl', gY, self.W.T)\n",
    "        # Same as: gX[i,j,:] = np.dot(gY[i,j,:], self.W.T) \n",
    "        #          (for i,j in gY.shape[0:1])\n",
    "        gX = np.tensordot(gY, self.W.T, axes=((-1),(0)))  \n",
    "        return gX, gW, gB\n",
    "\n",
    "# Define the logistic classifier layer\n",
    "class LogisticClassifier(object):\n",
    "    \"\"\"The logistic layer applies the logistic function to its \n",
    "    inputs.\"\"\"\n",
    "   \n",
    "    def forward(self, X):\n",
    "        \"\"\"Perform the forward step transformation.\"\"\"\n",
    "        return 1. / (1. + np.exp(-X))\n",
    "    \n",
    "    def backward(self, Y, T):\n",
    "        \"\"\"Return the gradient with respect to the loss function \n",
    "        at the inputs of this layer.\"\"\"\n",
    "        # Average by the number of samples and sequence length.\n",
    "        return (Y - T) / (Y.shape[0] * Y.shape[1])\n",
    "    \n",
    "    def loss(self, Y, T):\n",
    "        \"\"\"Compute the loss at the output.\"\"\"\n",
    "        return -np.mean((T * np.log(Y)) + ((1-T) * np.log(1-Y)))\n",
    "\n",
    "class LogisticClassifierSoftmax:\n",
    "    def forward(self, X, theta = 1.0, axis = 2):\n",
    "        \"Takes X as 3d tensor\"\n",
    "\n",
    "        # multiply y against the theta parameter,\n",
    "        y = X * float(theta)\n",
    "        # subtract the max for numerical stability\n",
    "        y = y - np.expand_dims(np.max(y, axis = axis), axis)\n",
    "        # exponentiate y\n",
    "        y = np.exp(y)\n",
    "        # take the sum along the specified axis\n",
    "        ax_sum = np.expand_dims(np.sum(y, axis = axis), axis)\n",
    "        # finally: divide elementwise\n",
    "        return y / ax_sum\n",
    "        \n",
    "    def loss(self, Y, T):\n",
    "        \"\"\"\n",
    "        Y is the output from fully connected layer passed through softmax (batch_size x num_examples x num_classes)\n",
    "        T is labels (batch_size x num_examples x 1)\n",
    "            Note that y is not one-hot encoded vector. \n",
    "            It can be computed as y.argmax(axis=1) from one-hot encoded vectors of labels if required.\n",
    "        \"\"\"\n",
    "#         print(f\"Y.shape {Y.shape}\")\n",
    "#         print(f\"T.shape {T.shape}\")\n",
    "        m = T.shape[1]\n",
    "        #ps = self.forward(Y, axis=2)\n",
    "\n",
    "        losses = []\n",
    "        for idx, p in enumerate(Y):  \n",
    "            log_likelihood = -np.log(p[range(m), T[idx].flatten()])\n",
    "            loss = np.sum(log_likelihood) / m\n",
    "            losses.append(loss)\n",
    "        return np.mean(losses)\n",
    "\n",
    "    def backward(self, X, T):\n",
    "        \"\"\"\n",
    "        X is the output from fully connected layer passed through softmax (batch_size x num_examples x num_classes)\n",
    "        T is labels (batch_size x num_examples x 1)\n",
    "            Note that y is not one-hot encoded vector. \n",
    "            It can be computed as y.argmax(axis=1) from one-hot encoded vectors of labels if required.\n",
    "        \"\"\"\n",
    "        delta = np.zeros(X.shape)\n",
    "        m = T.shape[1]\n",
    "        \n",
    "        for idx in range(len(delta)):\n",
    "            #x = Y[idx]\n",
    "            #grad = self.forward(x, axis=1)\n",
    "            #grad = x\n",
    "            grad = X[idx]\n",
    "            grad[range(m),T[idx].flatten()] -= 1\n",
    "            grad = grad/m\n",
    "            delta[idx] = grad\n",
    "        return delta\n",
    "\n",
    "# Define tanh layer\n",
    "class TanH(object):\n",
    "    \"\"\"TanH applies the tanh function to its inputs.\"\"\"\n",
    "    \n",
    "    def forward(self, X):\n",
    "        \"\"\"Perform the forward step transformation.\"\"\"\n",
    "        return np.tanh(X) \n",
    "    \n",
    "    def backward(self, Y, output_grad):\n",
    "        \"\"\"Return the gradient at the inputs of this layer.\"\"\"\n",
    "        gTanh = 1.0 - (Y**2)\n",
    "        return (gTanh * output_grad)\n",
    "\n",
    "# Define internal state update layer\n",
    "class RecurrentStateUpdate(object):\n",
    "    \"\"\"Update a given state.\"\"\"\n",
    "    def __init__(self, nbStates, W, b):\n",
    "        \"\"\"Initialse the linear transformation and tanh transfer \n",
    "        function.\"\"\"\n",
    "        self.linear = TensorLinear(nbStates, nbStates, 2, W, b)\n",
    "        self.tanh = TanH()\n",
    "\n",
    "    def forward(self, Xk, Sk):\n",
    "        \"\"\"Return state k+1 from input and state k.\"\"\"\n",
    "        return self.tanh.forward(Xk + self.linear.forward(Sk))\n",
    "    \n",
    "    def backward(self, Sk0, Sk1, output_grad):\n",
    "        \"\"\"Return the gradient of the parmeters and the inputs of \n",
    "        this layer.\"\"\"\n",
    "        gZ = self.tanh.backward(Sk1, output_grad)\n",
    "        gSk0, gW, gB = self.linear.backward(Sk0, gZ)\n",
    "        return gZ, gSk0, gW, gB\n",
    "\n",
    "# Define layer that unfolds the states over time\n",
    "class RecurrentStateUnfold(object):\n",
    "    \"\"\"Unfold the recurrent states.\"\"\"\n",
    "    def __init__(self, nbStates, nbTimesteps):\n",
    "        \"\"\"Initialse the shared parameters, the inital state and \n",
    "        state update function.\"\"\"\n",
    "        a = np.sqrt(6. / (nbStates * 2))\n",
    "        self.W = np.random.uniform(-a, a, (nbStates, nbStates))\n",
    "        self.b = np.zeros((self.W.shape[0]))  # Shared bias\n",
    "        self.S0 = np.zeros(nbStates)  # Initial state\n",
    "        self.nbTimesteps = nbTimesteps  # Timesteps to unfold\n",
    "        self.stateUpdate = RecurrentStateUpdate(\n",
    "            nbStates, self.W, self.b)  # State update function\n",
    "        \n",
    "    def forward(self, X):\n",
    "        \"\"\"Iteratively apply forward step to all states.\"\"\"\n",
    "        # State tensor\n",
    "        S = np.zeros((X.shape[0], X.shape[1]+1, self.W.shape[0]))\n",
    "        S[:,0,:] = self.S0  # Set initial state\n",
    "        for k in range(self.nbTimesteps):\n",
    "            # Update the states iteratively\n",
    "            S[:,k+1,:] = self.stateUpdate.forward(X[:,k,:], S[:,k,:])\n",
    "        return S\n",
    "    \n",
    "    def backward(self, X, S, gY):\n",
    "        \"\"\"Return the gradient of the parmeters and the inputs of \n",
    "        this layer.\"\"\"\n",
    "        # Initialise gradient of state outputs\n",
    "        gSk = np.zeros_like(gY[:,self.nbTimesteps-1,:])\n",
    "        # Initialse gradient tensor for state inputs\n",
    "        gZ = np.zeros_like(X)\n",
    "        gWSum = np.zeros_like(self.W)  # Initialise weight gradients\n",
    "        gBSum = np.zeros_like(self.b)  # Initialse bias gradients\n",
    "        # Propagate the gradients iteratively\n",
    "        for k in range(self.nbTimesteps-1, -1, -1):\n",
    "            # Gradient at state output is gradient from previous state \n",
    "            #  plus gradient from output\n",
    "            gSk += gY[:,k,:]\n",
    "            # Propgate the gradient back through one state\n",
    "            gZ[:,k,:], gSk, gW, gB = self.stateUpdate.backward(\n",
    "                S[:,k,:], S[:,k+1,:], gSk)\n",
    "            gWSum += gW  # Update total weight gradient\n",
    "            gBSum += gB  # Update total bias gradient\n",
    "        # Get gradient of initial state over all samples\n",
    "        gS0 = np.sum(gSk, axis=0)\n",
    "        return gZ, gWSum, gBSum, gS0\n",
    "\n",
    "# Define the full network\n",
    "class RnnBinaryAdder(object):\n",
    "    \"\"\"RNN to perform binary addition of 2 numbers.\"\"\"\n",
    "    def __init__(self, nb_of_inputs, nb_of_outputs, nb_of_states, \n",
    "                 sequence_len):\n",
    "        \"\"\"Initialse the network layers.\"\"\"\n",
    "        # Input layer\n",
    "        self.tensorInput = TensorLinear(nb_of_inputs, nb_of_states, 3)\n",
    "        # Recurrent layer\n",
    "        self.rnnUnfold = RecurrentStateUnfold(nb_of_states, sequence_len)\n",
    "        # Linear output transform\n",
    "        self.tensorOutput = TensorLinear(nb_of_states, nb_of_outputs, 3)\n",
    "        self.classifier = LogisticClassifierSoftmax()  # Classification output\n",
    "        #self.classifier = LogisticClassifier()  # Classification output\n",
    "        self.sequence_len = sequence_len\n",
    "        \n",
    "    def forward(self, X):\n",
    "        \"\"\"Perform the forward propagation of input X through all \n",
    "        layers.\"\"\"\n",
    "        # Linear input transformation\n",
    "        recIn = self.tensorInput.forward(X)\n",
    "        # Forward propagate through time and return states\n",
    "        S = self.rnnUnfold.forward(recIn)\n",
    "        # Linear output transformation\n",
    "        Z = self.tensorOutput.forward(S[:,1:self.sequence_len+1,:])\n",
    "        Y = self.classifier.forward(Z)  # Classification probabilities\n",
    "        # Return: input to recurrent layer, states, input to classifier, \n",
    "        #  output\n",
    "        return recIn, S, Z, Y\n",
    "    \n",
    "    def backward(self, X, Y, recIn, S, T):\n",
    "        \"\"\"Perform the backward propagation through all layers.\n",
    "        Input: input samples, network output, input to recurrent \n",
    "        layer, states, targets.\"\"\"\n",
    "        gZ = self.classifier.backward(Y, T)  # Get output gradient\n",
    "        gRecOut, gWout, gBout = self.tensorOutput.backward(\n",
    "            S[:,1:self.sequence_len+1,:], gZ)\n",
    "        # Propagate gradient backwards through time\n",
    "        gRnnIn, gWrec, gBrec, gS0 = self.rnnUnfold.backward(\n",
    "            recIn, S, gRecOut)\n",
    "        gX, gWin, gBin = self.tensorInput.backward(X, gRnnIn)\n",
    "        # Return the parameter gradients of: linear output weights, \n",
    "        #  linear output bias, recursive weights, recursive bias, #\n",
    "        #  linear input weights, linear input bias, initial state.\n",
    "        return gWout, gBout, gWrec, gBrec, gWin, gBin, gS0\n",
    "    \n",
    "    def getOutput(self, X):\n",
    "        \"\"\"Get the output probabilities of input X.\"\"\"\n",
    "        recIn, S, Z, Y = self.forward(X)\n",
    "        return Y\n",
    "    \n",
    "    def getBinaryOutput(self, X):\n",
    "        \"\"\"Get the binary output of input X.\"\"\"\n",
    "        return np.around(self.getOutput(X))\n",
    "    \n",
    "    def getParamGrads(self, X, T):\n",
    "        \"\"\"Return the gradients with respect to input X and \n",
    "        target T as a list. The list has the same order as the \n",
    "        get_params_iter iterator.\"\"\"\n",
    "        recIn, S, Z, Y = self.forward(X)\n",
    "        gWout, gBout, gWrec, gBrec, gWin, gBin, gS0 = self.backward(\n",
    "            X, Y, recIn, S, T)\n",
    "        return [g for g in itertools.chain(\n",
    "                np.nditer(gS0),\n",
    "                np.nditer(gWin),\n",
    "                np.nditer(gBin),\n",
    "                np.nditer(gWrec),\n",
    "                np.nditer(gBrec),\n",
    "                np.nditer(gWout),\n",
    "                np.nditer(gBout))]\n",
    "    \n",
    "    def loss(self, Y, T):\n",
    "        \"\"\"Return the loss of input X w.r.t. targets T.\"\"\"\n",
    "        return self.classifier.loss(Y, T)\n",
    "    \n",
    "    def get_params_iter(self):\n",
    "        \"\"\"Return an iterator over the parameters.\n",
    "        The iterator has the same order as get_params_grad.\n",
    "        The elements returned by the iterator are editable in-place.\"\"\"\n",
    "        return itertools.chain(\n",
    "            np.nditer(self.rnnUnfold.S0, op_flags=['readwrite']),\n",
    "            np.nditer(self.tensorInput.W, op_flags=['readwrite']),\n",
    "            np.nditer(self.tensorInput.b, op_flags=['readwrite']),\n",
    "            np.nditer(self.rnnUnfold.W, op_flags=['readwrite']),\n",
    "            np.nditer(self.rnnUnfold.b, op_flags=['readwrite']),\n",
    "            np.nditer(self.tensorOutput.W, op_flags=['readwrite']), \n",
    "            np.nditer(self.tensorOutput.b, op_flags=['readwrite']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n",
      "Epoch 30\n",
      "Epoch 31\n",
      "Epoch 32\n",
      "Epoch 33\n",
      "Epoch 34\n",
      "Epoch 35\n",
      "Epoch 36\n",
      "Epoch 37\n",
      "Epoch 38\n",
      "Epoch 39\n",
      "Epoch 40\n",
      "Epoch 41\n",
      "Epoch 42\n",
      "Epoch 43\n",
      "Epoch 44\n",
      "Epoch 45\n",
      "Epoch 46\n",
      "Epoch 47\n",
      "Epoch 48\n",
      "Epoch 49\n",
      "Epoch 50\n"
     ]
    }
   ],
   "source": [
    "# Set hyper-parameters\n",
    "lmbd = 0.5  # Rmsprop lambda\n",
    "learning_rate = 0.001  # Learning rate\n",
    "momentum_term = 0.80  # Momentum term\n",
    "eps = 1e-6  # Numerical stability term to prevent division by zero\n",
    "mb_size = 20  # Size of the minibatches (number of samples)\n",
    "max_num = 8\n",
    "seq_length = 9\n",
    "hidden_size = 30\n",
    "nb_train = 200\n",
    "\n",
    "x_train, y_train, x_test, y_test = create_sort_dataset(nb_train, seq_length, max_num)\n",
    "\n",
    "input_size = 1\n",
    "output_size = max_num+1\n",
    "\n",
    "# Create the network\n",
    "RNN = RnnBinaryAdder(1, max_num+1, hidden_size, seq_length)\n",
    "#RNN = RnnBinaryAdder(1, output_size, hidden_size, seq_length)\n",
    "# Set the initial parameters\n",
    "# Number of parameters in the network\n",
    "nbParameters =  sum(1 for _ in RNN.get_params_iter())\n",
    "# Rmsprop moving average\n",
    "maSquare = [0.0 for _ in range(nbParameters)]\n",
    "Vs = [0.0 for _ in range(nbParameters)]  # Momentum\n",
    "\n",
    "# Create a list of minibatch losses to be plotted\n",
    "ls_of_loss = [\n",
    "    RNN.loss(RNN.getOutput(x_train[0:mb_size]), y_train[0:mb_size])]\n",
    "\n",
    "# Iterate over some iterations\n",
    "for i in range(50):\n",
    "    print(f'Epoch {i+1}')\n",
    "    # Iterate over all the minibatches\n",
    "    for mb in range(nb_train // mb_size):\n",
    "        X_mb = x_train[mb:mb+mb_size,:,:]  # Input minibatch\n",
    "        T_mb = y_train[mb:mb+mb_size,:,:]  # Target minibatch\n",
    "        V_tmp = [v * momentum_term for v in Vs]\n",
    "        # Update each parameters according to previous gradient\n",
    "        for pIdx, P in enumerate(RNN.get_params_iter()):\n",
    "            P += V_tmp[pIdx]\n",
    "        # Get gradients after following old velocity\n",
    "        # Get the parameter gradients\n",
    "        backprop_grads = RNN.getParamGrads(X_mb, T_mb)    \n",
    "        # Update each parameter seperately\n",
    "        for pIdx, P in enumerate(RNN.get_params_iter()):\n",
    "            #P -= learning_rate * backprop_grads[pIdx]\n",
    "            # Update the Rmsprop moving averages\n",
    "            maSquare[pIdx] = lmbd * maSquare[pIdx] + (\n",
    "                1-lmbd) * backprop_grads[pIdx]**2\n",
    "            # Calculate the Rmsprop normalised gradient\n",
    "            pGradNorm = ((\n",
    "                learning_rate * backprop_grads[pIdx]) / np.sqrt(\n",
    "                maSquare[pIdx]) + eps)\n",
    "            # Update the momentum\n",
    "            Vs[pIdx] = V_tmp[pIdx] - pGradNorm     \n",
    "            P -= pGradNorm   # Update the parameter\n",
    "        # Add loss to list to plot\n",
    "        ls_of_loss.append(RNN.loss(RNN.getOutput(X_mb), T_mb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss over the iterations\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "plt.plot(ls_of_loss, 'b-')\n",
    "plt.xlabel('minibatch iteration')\n",
    "plt.ylabel('Cross entropy', fontsize=15)\n",
    "plt.title('Decrease of loss over backprop iteration')\n",
    "plt.xlim(0, 100)\n",
    "fig.subplots_adjust(bottom=0.2)\n",
    "plt.show()\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, x, y):\n",
    "    predictions = np.argmax(model.getOutput(x), axis=-1)\n",
    "    #print(predictions)\n",
    "    #print(y.squeeze())\n",
    "    print(classification_report(y.squeeze().flatten(), predictions.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.92      0.91        26\n",
      "           1       0.88      0.82      0.85        17\n",
      "           2       0.87      0.65      0.74        20\n",
      "           3       0.80      0.89      0.84        18\n",
      "           4       0.86      0.90      0.88        21\n",
      "           5       0.90      1.00      0.95        18\n",
      "           6       1.00      1.00      1.00        20\n",
      "           7       1.00      1.00      1.00        23\n",
      "           8       1.00      1.00      1.00        17\n",
      "\n",
      "   micro avg       0.91      0.91      0.91       180\n",
      "   macro avg       0.91      0.91      0.91       180\n",
      "weighted avg       0.91      0.91      0.91       180\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_model(RNN, X_mb, T_mb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter id: 0 Numerical gradient of 0.003595 is not close to the backpropagation gradient of 0.359485!\n",
      "Parameter id: 1 Numerical gradient of 0.013432 is not close to the backpropagation gradient of 1.343215!\n",
      "Parameter id: 2 Numerical gradient of 0.006020 is not close to the backpropagation gradient of 0.602016!\n",
      "Parameter id: 3 Numerical gradient of 0.007215 is not close to the backpropagation gradient of 0.721481!\n",
      "Parameter id: 4 Numerical gradient of -0.007427 is not close to the backpropagation gradient of -0.742663!\n",
      "Parameter id: 5 Numerical gradient of -0.019972 is not close to the backpropagation gradient of -1.997228!\n",
      "Parameter id: 6 Numerical gradient of 0.003151 is not close to the backpropagation gradient of 0.315050!\n",
      "Parameter id: 7 Numerical gradient of -0.005780 is not close to the backpropagation gradient of -0.577967!\n",
      "Parameter id: 8 Numerical gradient of 0.011937 is not close to the backpropagation gradient of 1.193744!\n",
      "Parameter id: 9 Numerical gradient of 0.016485 is not close to the backpropagation gradient of 1.648550!\n",
      "Parameter id: 10 Numerical gradient of 0.000556 is not close to the backpropagation gradient of 0.055635!\n",
      "Parameter id: 11 Numerical gradient of 0.003215 is not close to the backpropagation gradient of 0.321520!\n",
      "Parameter id: 12 Numerical gradient of 0.009082 is not close to the backpropagation gradient of 0.908250!\n",
      "Parameter id: 13 Numerical gradient of -0.012110 is not close to the backpropagation gradient of -1.211020!\n",
      "Parameter id: 14 Numerical gradient of -0.018896 is not close to the backpropagation gradient of -1.889561!\n",
      "Parameter id: 15 Numerical gradient of -0.014441 is not close to the backpropagation gradient of -1.444087!\n",
      "Parameter id: 16 Numerical gradient of 0.003845 is not close to the backpropagation gradient of 0.384484!\n",
      "Parameter id: 17 Numerical gradient of -0.016423 is not close to the backpropagation gradient of -1.642342!\n",
      "Parameter id: 18 Numerical gradient of 0.017409 is not close to the backpropagation gradient of 1.740919!\n",
      "Parameter id: 19 Numerical gradient of -0.000071 is not close to the backpropagation gradient of -0.007055!\n",
      "Parameter id: 20 Numerical gradient of 0.024104 is not close to the backpropagation gradient of 2.410411!\n",
      "Parameter id: 21 Numerical gradient of -0.009611 is not close to the backpropagation gradient of -0.961115!\n",
      "Parameter id: 22 Numerical gradient of 0.017347 is not close to the backpropagation gradient of 1.734709!\n",
      "Parameter id: 23 Numerical gradient of -0.011577 is not close to the backpropagation gradient of -1.157699!\n",
      "Parameter id: 24 Numerical gradient of -0.010798 is not close to the backpropagation gradient of -1.079773!\n",
      "Parameter id: 25 Numerical gradient of 0.005345 is not close to the backpropagation gradient of 0.534483!\n",
      "Parameter id: 26 Numerical gradient of -0.003213 is not close to the backpropagation gradient of -0.321341!\n",
      "Parameter id: 27 Numerical gradient of 0.005856 is not close to the backpropagation gradient of 0.585640!\n",
      "Parameter id: 28 Numerical gradient of -0.013024 is not close to the backpropagation gradient of -1.302449!\n",
      "Parameter id: 29 Numerical gradient of 0.011323 is not close to the backpropagation gradient of 1.132300!\n",
      "Parameter id: 30 Numerical gradient of -0.307940 is not close to the backpropagation gradient of -30.794006!\n",
      "Parameter id: 31 Numerical gradient of 0.028826 is not close to the backpropagation gradient of 2.882630!\n",
      "Parameter id: 32 Numerical gradient of 0.075830 is not close to the backpropagation gradient of 7.582961!\n",
      "Parameter id: 33 Numerical gradient of 0.024953 is not close to the backpropagation gradient of 2.495313!\n",
      "Parameter id: 34 Numerical gradient of 0.043090 is not close to the backpropagation gradient of 4.308973!\n",
      "Parameter id: 35 Numerical gradient of 0.011748 is not close to the backpropagation gradient of 1.174778!\n",
      "Parameter id: 36 Numerical gradient of -0.121703 is not close to the backpropagation gradient of -12.170314!\n",
      "Parameter id: 37 Numerical gradient of 0.041137 is not close to the backpropagation gradient of 4.113739!\n",
      "Parameter id: 38 Numerical gradient of 0.092471 is not close to the backpropagation gradient of 9.247100!\n",
      "Parameter id: 39 Numerical gradient of -0.201963 is not close to the backpropagation gradient of -20.196271!\n",
      "Parameter id: 40 Numerical gradient of -0.038877 is not close to the backpropagation gradient of -3.887656!\n",
      "Parameter id: 41 Numerical gradient of 0.015348 is not close to the backpropagation gradient of 1.534796!\n",
      "Parameter id: 42 Numerical gradient of -0.013417 is not close to the backpropagation gradient of -1.341661!\n",
      "Parameter id: 43 Numerical gradient of 0.096070 is not close to the backpropagation gradient of 9.607012!\n",
      "Parameter id: 44 Numerical gradient of -0.029467 is not close to the backpropagation gradient of -2.946663!\n",
      "Parameter id: 45 Numerical gradient of 0.069757 is not close to the backpropagation gradient of 6.975700!\n",
      "Parameter id: 46 Numerical gradient of 0.000042 is not close to the backpropagation gradient of 0.004200!\n",
      "Parameter id: 47 Numerical gradient of 0.003942 is not close to the backpropagation gradient of 0.394246!\n",
      "Parameter id: 48 Numerical gradient of -0.002070 is not close to the backpropagation gradient of -0.207021!\n",
      "Parameter id: 49 Numerical gradient of -0.056830 is not close to the backpropagation gradient of -5.683038!\n",
      "Parameter id: 50 Numerical gradient of -0.133841 is not close to the backpropagation gradient of -13.384098!\n",
      "Parameter id: 51 Numerical gradient of -0.198563 is not close to the backpropagation gradient of -19.856304!\n",
      "Parameter id: 52 Numerical gradient of 0.036353 is not close to the backpropagation gradient of 3.635321!\n",
      "Parameter id: 53 Numerical gradient of 0.130628 is not close to the backpropagation gradient of 13.062784!\n",
      "Parameter id: 54 Numerical gradient of 0.023012 is not close to the backpropagation gradient of 2.301243!\n",
      "Parameter id: 55 Numerical gradient of 0.047239 is not close to the backpropagation gradient of 4.723921!\n",
      "Parameter id: 56 Numerical gradient of 0.164900 is not close to the backpropagation gradient of 16.490004!\n",
      "Parameter id: 57 Numerical gradient of -0.025765 is not close to the backpropagation gradient of -2.576461!\n",
      "Parameter id: 58 Numerical gradient of 0.118150 is not close to the backpropagation gradient of 11.815030!\n",
      "Parameter id: 59 Numerical gradient of -0.286384 is not close to the backpropagation gradient of -28.638367!\n",
      "Parameter id: 60 Numerical gradient of -0.078584 is not close to the backpropagation gradient of -7.858366!\n",
      "Parameter id: 61 Numerical gradient of 0.007404 is not close to the backpropagation gradient of 0.740375!\n",
      "Parameter id: 62 Numerical gradient of 0.019852 is not close to the backpropagation gradient of 1.985166!\n",
      "Parameter id: 63 Numerical gradient of 0.013510 is not close to the backpropagation gradient of 1.351002!\n",
      "Parameter id: 64 Numerical gradient of 0.014211 is not close to the backpropagation gradient of 1.421077!\n",
      "Parameter id: 65 Numerical gradient of -0.001345 is not close to the backpropagation gradient of -0.134503!\n",
      "Parameter id: 66 Numerical gradient of -0.037196 is not close to the backpropagation gradient of -3.719596!\n",
      "Parameter id: 67 Numerical gradient of 0.021602 is not close to the backpropagation gradient of 2.160194!\n",
      "Parameter id: 68 Numerical gradient of 0.031459 is not close to the backpropagation gradient of 3.145926!\n",
      "Parameter id: 69 Numerical gradient of -0.034649 is not close to the backpropagation gradient of -3.464862!\n",
      "Parameter id: 70 Numerical gradient of -0.001599 is not close to the backpropagation gradient of -0.159871!\n",
      "Parameter id: 71 Numerical gradient of 0.001022 is not close to the backpropagation gradient of 0.102232!\n",
      "Parameter id: 72 Numerical gradient of -0.004287 is not close to the backpropagation gradient of -0.428694!\n",
      "Parameter id: 73 Numerical gradient of 0.019012 is not close to the backpropagation gradient of 1.901169!\n",
      "Parameter id: 74 Numerical gradient of -0.018243 is not close to the backpropagation gradient of -1.824313!\n",
      "Parameter id: 75 Numerical gradient of 0.008589 is not close to the backpropagation gradient of 0.858919!\n",
      "Parameter id: 76 Numerical gradient of 0.015694 is not close to the backpropagation gradient of 1.569354!\n",
      "Parameter id: 77 Numerical gradient of 0.003515 is not close to the backpropagation gradient of 0.351481!\n",
      "Parameter id: 78 Numerical gradient of 0.010047 is not close to the backpropagation gradient of 1.004701!\n",
      "Parameter id: 79 Numerical gradient of -0.016948 is not close to the backpropagation gradient of -1.694820!\n",
      "Parameter id: 80 Numerical gradient of -0.042080 is not close to the backpropagation gradient of -4.208025!\n",
      "Parameter id: 81 Numerical gradient of -0.036379 is not close to the backpropagation gradient of -3.637856!\n",
      "Parameter id: 82 Numerical gradient of 0.017549 is not close to the backpropagation gradient of 1.754891!\n",
      "Parameter id: 83 Numerical gradient of 0.065874 is not close to the backpropagation gradient of 6.587373!\n",
      "Parameter id: 84 Numerical gradient of 0.003906 is not close to the backpropagation gradient of 0.390613!\n",
      "Parameter id: 85 Numerical gradient of 0.009937 is not close to the backpropagation gradient of 0.993672!\n",
      "Parameter id: 86 Numerical gradient of 0.026782 is not close to the backpropagation gradient of 2.678186!\n",
      "Parameter id: 87 Numerical gradient of -0.011678 is not close to the backpropagation gradient of -1.167792!\n",
      "Parameter id: 88 Numerical gradient of 0.038659 is not close to the backpropagation gradient of 3.865865!\n",
      "Parameter id: 89 Numerical gradient of -0.056482 is not close to the backpropagation gradient of -5.648161!\n",
      "Parameter id: 90 Numerical gradient of -0.006125 is not close to the backpropagation gradient of -0.612469!\n",
      "Parameter id: 91 Numerical gradient of -0.000107 is not close to the backpropagation gradient of -0.010698!\n",
      "Parameter id: 92 Numerical gradient of 0.007430 is not close to the backpropagation gradient of 0.742976!\n",
      "Parameter id: 93 Numerical gradient of 0.002293 is not close to the backpropagation gradient of 0.229341!\n",
      "Parameter id: 94 Numerical gradient of 0.001101 is not close to the backpropagation gradient of 0.110071!\n",
      "Parameter id: 95 Numerical gradient of -0.000218 is not close to the backpropagation gradient of -0.021840!\n",
      "Parameter id: 96 Numerical gradient of -0.003922 is not close to the backpropagation gradient of -0.392239!\n",
      "Parameter id: 97 Numerical gradient of 0.006616 is not close to the backpropagation gradient of 0.661566!\n",
      "Parameter id: 98 Numerical gradient of 0.014863 is not close to the backpropagation gradient of 1.486326!\n",
      "Parameter id: 99 Numerical gradient of -0.003787 is not close to the backpropagation gradient of -0.378699!\n",
      "Parameter id: 100 Numerical gradient of 0.005698 is not close to the backpropagation gradient of 0.569850!\n",
      "Parameter id: 101 Numerical gradient of -0.002344 is not close to the backpropagation gradient of -0.234355!\n",
      "Parameter id: 102 Numerical gradient of 0.001849 is not close to the backpropagation gradient of 0.184888!\n",
      "Parameter id: 103 Numerical gradient of 0.000277 is not close to the backpropagation gradient of 0.027721!\n",
      "Parameter id: 104 Numerical gradient of -0.001462 is not close to the backpropagation gradient of -0.146154!\n",
      "Parameter id: 105 Numerical gradient of -0.002709 is not close to the backpropagation gradient of -0.270896!\n",
      "Parameter id: 106 Numerical gradient of 0.013623 is not close to the backpropagation gradient of 1.362267!\n",
      "Parameter id: 107 Numerical gradient of -0.004909 is not close to the backpropagation gradient of -0.490875!\n",
      "Parameter id: 108 Numerical gradient of 0.009008 is not close to the backpropagation gradient of 0.900802!\n",
      "Parameter id: 109 Numerical gradient of -0.019115 is not close to the backpropagation gradient of -1.911527!\n",
      "Parameter id: 110 Numerical gradient of -0.008290 is not close to the backpropagation gradient of -0.828950!\n",
      "Parameter id: 111 Numerical gradient of -0.002281 is not close to the backpropagation gradient of -0.228074!\n",
      "Parameter id: 112 Numerical gradient of 0.006455 is not close to the backpropagation gradient of 0.645455!\n",
      "Parameter id: 113 Numerical gradient of 0.014853 is not close to the backpropagation gradient of 1.485292!\n",
      "Parameter id: 114 Numerical gradient of 0.000704 is not close to the backpropagation gradient of 0.070435!\n",
      "Parameter id: 115 Numerical gradient of 0.007526 is not close to the backpropagation gradient of 0.752592!\n",
      "Parameter id: 116 Numerical gradient of 0.003217 is not close to the backpropagation gradient of 0.321661!\n",
      "Parameter id: 117 Numerical gradient of -0.003611 is not close to the backpropagation gradient of -0.361081!\n",
      "Parameter id: 118 Numerical gradient of 0.001034 is not close to the backpropagation gradient of 0.103434!\n",
      "Parameter id: 119 Numerical gradient of -0.013212 is not close to the backpropagation gradient of -1.321200!\n",
      "Parameter id: 120 Numerical gradient of -0.049699 is not close to the backpropagation gradient of -4.969942!\n",
      "Parameter id: 121 Numerical gradient of 0.013292 is not close to the backpropagation gradient of 1.329207!\n",
      "Parameter id: 122 Numerical gradient of 0.011775 is not close to the backpropagation gradient of 1.177535!\n",
      "Parameter id: 123 Numerical gradient of 0.008957 is not close to the backpropagation gradient of 0.895666!\n",
      "Parameter id: 124 Numerical gradient of 0.022548 is not close to the backpropagation gradient of 2.254814!\n",
      "Parameter id: 125 Numerical gradient of 0.002285 is not close to the backpropagation gradient of 0.228455!\n",
      "Parameter id: 126 Numerical gradient of -0.007112 is not close to the backpropagation gradient of -0.711181!\n",
      "Parameter id: 127 Numerical gradient of 0.010055 is not close to the backpropagation gradient of 1.005491!\n",
      "Parameter id: 128 Numerical gradient of 0.009163 is not close to the backpropagation gradient of 0.916258!\n",
      "Parameter id: 129 Numerical gradient of -0.011811 is not close to the backpropagation gradient of -1.181106!\n",
      "Parameter id: 130 Numerical gradient of 0.008348 is not close to the backpropagation gradient of 0.834771!\n",
      "Parameter id: 131 Numerical gradient of -0.003222 is not close to the backpropagation gradient of -0.322220!\n",
      "Parameter id: 132 Numerical gradient of -0.008453 is not close to the backpropagation gradient of -0.845261!\n",
      "Parameter id: 133 Numerical gradient of 0.019266 is not close to the backpropagation gradient of 1.926598!\n",
      "Parameter id: 134 Numerical gradient of -0.025933 is not close to the backpropagation gradient of -2.593293!\n",
      "Parameter id: 135 Numerical gradient of 0.015492 is not close to the backpropagation gradient of 1.549243!\n",
      "Parameter id: 136 Numerical gradient of -0.011582 is not close to the backpropagation gradient of -1.158151!\n",
      "Parameter id: 137 Numerical gradient of -0.005937 is not close to the backpropagation gradient of -0.593657!\n",
      "Parameter id: 138 Numerical gradient of -0.007496 is not close to the backpropagation gradient of -0.749586!\n",
      "Parameter id: 139 Numerical gradient of -0.003615 is not close to the backpropagation gradient of -0.361541!\n",
      "Parameter id: 140 Numerical gradient of -0.011336 is not close to the backpropagation gradient of -1.133576!\n",
      "Parameter id: 141 Numerical gradient of -0.044363 is not close to the backpropagation gradient of -4.436277!\n",
      "Parameter id: 142 Numerical gradient of -0.005365 is not close to the backpropagation gradient of -0.536530!\n",
      "Parameter id: 143 Numerical gradient of 0.038044 is not close to the backpropagation gradient of 3.804367!\n",
      "Parameter id: 144 Numerical gradient of 0.012114 is not close to the backpropagation gradient of 1.211432!\n",
      "Parameter id: 145 Numerical gradient of 0.012396 is not close to the backpropagation gradient of 1.239590!\n",
      "Parameter id: 146 Numerical gradient of 0.035290 is not close to the backpropagation gradient of 3.529046!\n",
      "Parameter id: 147 Numerical gradient of -0.011364 is not close to the backpropagation gradient of -1.136442!\n",
      "Parameter id: 148 Numerical gradient of 0.013037 is not close to the backpropagation gradient of 1.303714!\n",
      "Parameter id: 149 Numerical gradient of -0.030515 is not close to the backpropagation gradient of -3.051498!\n",
      "Parameter id: 150 Numerical gradient of -0.053337 is not close to the backpropagation gradient of -5.333749!\n",
      "Parameter id: 151 Numerical gradient of 0.014840 is not close to the backpropagation gradient of 1.484043!\n",
      "Parameter id: 152 Numerical gradient of 0.012276 is not close to the backpropagation gradient of 1.227579!\n",
      "Parameter id: 153 Numerical gradient of 0.009354 is not close to the backpropagation gradient of 0.935360!\n",
      "Parameter id: 154 Numerical gradient of 0.023534 is not close to the backpropagation gradient of 2.353352!\n",
      "Parameter id: 155 Numerical gradient of 0.000472 is not close to the backpropagation gradient of 0.047220!\n",
      "Parameter id: 156 Numerical gradient of -0.007447 is not close to the backpropagation gradient of -0.744665!\n",
      "Parameter id: 157 Numerical gradient of 0.009999 is not close to the backpropagation gradient of 0.999915!\n",
      "Parameter id: 158 Numerical gradient of 0.009348 is not close to the backpropagation gradient of 0.934788!\n",
      "Parameter id: 159 Numerical gradient of -0.011159 is not close to the backpropagation gradient of -1.115853!\n",
      "Parameter id: 160 Numerical gradient of 0.008489 is not close to the backpropagation gradient of 0.848891!\n",
      "Parameter id: 161 Numerical gradient of -0.002243 is not close to the backpropagation gradient of -0.224350!\n",
      "Parameter id: 162 Numerical gradient of -0.007386 is not close to the backpropagation gradient of -0.738648!\n",
      "Parameter id: 163 Numerical gradient of 0.019789 is not close to the backpropagation gradient of 1.978852!\n",
      "Parameter id: 164 Numerical gradient of -0.028212 is not close to the backpropagation gradient of -2.821228!\n",
      "Parameter id: 165 Numerical gradient of 0.019249 is not close to the backpropagation gradient of 1.924927!\n",
      "Parameter id: 166 Numerical gradient of -0.012575 is not close to the backpropagation gradient of -1.257506!\n",
      "Parameter id: 167 Numerical gradient of -0.006493 is not close to the backpropagation gradient of -0.649263!\n",
      "Parameter id: 168 Numerical gradient of -0.010003 is not close to the backpropagation gradient of -1.000320!\n",
      "Parameter id: 169 Numerical gradient of -0.003029 is not close to the backpropagation gradient of -0.302919!\n",
      "Parameter id: 170 Numerical gradient of -0.011406 is not close to the backpropagation gradient of -1.140605!\n",
      "Parameter id: 171 Numerical gradient of -0.049042 is not close to the backpropagation gradient of -4.904241!\n",
      "Parameter id: 172 Numerical gradient of -0.006091 is not close to the backpropagation gradient of -0.609085!\n",
      "Parameter id: 173 Numerical gradient of 0.039301 is not close to the backpropagation gradient of 3.930135!\n",
      "Parameter id: 174 Numerical gradient of 0.012715 is not close to the backpropagation gradient of 1.271550!\n",
      "Parameter id: 175 Numerical gradient of 0.014448 is not close to the backpropagation gradient of 1.444757!\n",
      "Parameter id: 176 Numerical gradient of 0.037873 is not close to the backpropagation gradient of 3.787302!\n",
      "Parameter id: 177 Numerical gradient of -0.011229 is not close to the backpropagation gradient of -1.122876!\n",
      "Parameter id: 178 Numerical gradient of 0.012912 is not close to the backpropagation gradient of 1.291167!\n",
      "Parameter id: 179 Numerical gradient of -0.032307 is not close to the backpropagation gradient of -3.230690!\n",
      "Parameter id: 180 Numerical gradient of -0.004527 is not close to the backpropagation gradient of -0.452678!\n",
      "Parameter id: 181 Numerical gradient of 0.003207 is not close to the backpropagation gradient of 0.320664!\n",
      "Parameter id: 182 Numerical gradient of -0.004297 is not close to the backpropagation gradient of -0.429727!\n",
      "Parameter id: 183 Numerical gradient of 0.000486 is not close to the backpropagation gradient of 0.048650!\n",
      "Parameter id: 184 Numerical gradient of 0.004463 is not close to the backpropagation gradient of 0.446335!\n",
      "Parameter id: 185 Numerical gradient of 0.000445 is not close to the backpropagation gradient of 0.044490!\n",
      "Parameter id: 186 Numerical gradient of 0.006494 is not close to the backpropagation gradient of 0.649443!\n",
      "Parameter id: 187 Numerical gradient of -0.004359 is not close to the backpropagation gradient of -0.435934!\n",
      "Parameter id: 188 Numerical gradient of -0.008790 is not close to the backpropagation gradient of -0.879000!\n",
      "Parameter id: 189 Numerical gradient of 0.000594 is not close to the backpropagation gradient of 0.059362!\n",
      "Parameter id: 190 Numerical gradient of 0.000681 is not close to the backpropagation gradient of 0.068069!\n",
      "Parameter id: 191 Numerical gradient of 0.000909 is not close to the backpropagation gradient of 0.090923!\n",
      "Parameter id: 192 Numerical gradient of -0.005224 is not close to the backpropagation gradient of -0.522376!\n",
      "Parameter id: 193 Numerical gradient of 0.010529 is not close to the backpropagation gradient of 1.052877!\n",
      "Parameter id: 194 Numerical gradient of -0.006386 is not close to the backpropagation gradient of -0.638649!\n",
      "Parameter id: 195 Numerical gradient of -0.001259 is not close to the backpropagation gradient of -0.125939!\n",
      "Parameter id: 196 Numerical gradient of -0.013879 is not close to the backpropagation gradient of -1.387886!\n",
      "Parameter id: 197 Numerical gradient of 0.002820 is not close to the backpropagation gradient of 0.282015!\n",
      "Parameter id: 198 Numerical gradient of -0.009684 is not close to the backpropagation gradient of -0.968404!\n",
      "Parameter id: 199 Numerical gradient of 0.017039 is not close to the backpropagation gradient of 1.703858!\n",
      "Parameter id: 200 Numerical gradient of 0.004142 is not close to the backpropagation gradient of 0.414152!\n",
      "Parameter id: 201 Numerical gradient of -0.001261 is not close to the backpropagation gradient of -0.126117!\n",
      "Parameter id: 202 Numerical gradient of -0.007092 is not close to the backpropagation gradient of -0.709186!\n",
      "Parameter id: 203 Numerical gradient of -0.004781 is not close to the backpropagation gradient of -0.478129!\n",
      "Parameter id: 204 Numerical gradient of 0.003354 is not close to the backpropagation gradient of 0.335418!\n",
      "Parameter id: 205 Numerical gradient of -0.006223 is not close to the backpropagation gradient of -0.622266!\n",
      "Parameter id: 206 Numerical gradient of 0.004528 is not close to the backpropagation gradient of 0.452786!\n",
      "Parameter id: 207 Numerical gradient of -0.000828 is not close to the backpropagation gradient of -0.082755!\n",
      "Parameter id: 208 Numerical gradient of 0.003420 is not close to the backpropagation gradient of 0.341983!\n",
      "Parameter id: 209 Numerical gradient of 0.006802 is not close to the backpropagation gradient of 0.680153!\n",
      "Parameter id: 210 Numerical gradient of -0.054135 is not close to the backpropagation gradient of -5.413476!\n",
      "Parameter id: 211 Numerical gradient of 0.012617 is not close to the backpropagation gradient of 1.261716!\n",
      "Parameter id: 212 Numerical gradient of 0.020294 is not close to the backpropagation gradient of 2.029405!\n",
      "Parameter id: 213 Numerical gradient of 0.006311 is not close to the backpropagation gradient of 0.631101!\n",
      "Parameter id: 214 Numerical gradient of 0.021318 is not close to the backpropagation gradient of 2.131757!\n",
      "Parameter id: 215 Numerical gradient of 0.001339 is not close to the backpropagation gradient of 0.133888!\n",
      "Parameter id: 216 Numerical gradient of -0.013204 is not close to the backpropagation gradient of -1.320363!\n",
      "Parameter id: 217 Numerical gradient of 0.015782 is not close to the backpropagation gradient of 1.578190!\n",
      "Parameter id: 218 Numerical gradient of 0.018792 is not close to the backpropagation gradient of 1.879203!\n",
      "Parameter id: 219 Numerical gradient of -0.011874 is not close to the backpropagation gradient of -1.187402!\n",
      "Parameter id: 220 Numerical gradient of 0.009789 is not close to the backpropagation gradient of 0.978901!\n",
      "Parameter id: 221 Numerical gradient of -0.005612 is not close to the backpropagation gradient of -0.561241!\n",
      "Parameter id: 222 Numerical gradient of -0.006219 is not close to the backpropagation gradient of -0.621877!\n",
      "Parameter id: 223 Numerical gradient of 0.014883 is not close to the backpropagation gradient of 1.488272!\n",
      "Parameter id: 224 Numerical gradient of -0.025402 is not close to the backpropagation gradient of -2.540178!\n",
      "Parameter id: 225 Numerical gradient of 0.015058 is not close to the backpropagation gradient of 1.505823!\n",
      "Parameter id: 226 Numerical gradient of 0.004345 is not close to the backpropagation gradient of 0.434526!\n",
      "Parameter id: 227 Numerical gradient of -0.007046 is not close to the backpropagation gradient of -0.704621!\n",
      "Parameter id: 228 Numerical gradient of 0.001233 is not close to the backpropagation gradient of 0.123345!\n",
      "Parameter id: 229 Numerical gradient of -0.021544 is not close to the backpropagation gradient of -2.154393!\n",
      "Parameter id: 230 Numerical gradient of -0.016156 is not close to the backpropagation gradient of -1.615648!\n",
      "Parameter id: 231 Numerical gradient of -0.040719 is not close to the backpropagation gradient of -4.071898!\n",
      "Parameter id: 232 Numerical gradient of 0.001149 is not close to the backpropagation gradient of 0.114939!\n",
      "Parameter id: 233 Numerical gradient of 0.048910 is not close to the backpropagation gradient of 4.890963!\n",
      "Parameter id: 234 Numerical gradient of 0.010060 is not close to the backpropagation gradient of 1.005966!\n",
      "Parameter id: 235 Numerical gradient of 0.017690 is not close to the backpropagation gradient of 1.769046!\n",
      "Parameter id: 236 Numerical gradient of 0.034942 is not close to the backpropagation gradient of 3.494177!\n",
      "Parameter id: 237 Numerical gradient of -0.012014 is not close to the backpropagation gradient of -1.201370!\n",
      "Parameter id: 238 Numerical gradient of 0.011103 is not close to the backpropagation gradient of 1.110291!\n",
      "Parameter id: 239 Numerical gradient of -0.038918 is not close to the backpropagation gradient of -3.891821!\n",
      "Parameter id: 240 Numerical gradient of -0.054157 is not close to the backpropagation gradient of -5.415659!\n",
      "Parameter id: 241 Numerical gradient of 0.013722 is not close to the backpropagation gradient of 1.372154!\n",
      "Parameter id: 242 Numerical gradient of 0.019707 is not close to the backpropagation gradient of 1.970651!\n",
      "Parameter id: 243 Numerical gradient of 0.007897 is not close to the backpropagation gradient of 0.789736!\n",
      "Parameter id: 244 Numerical gradient of 0.022738 is not close to the backpropagation gradient of 2.273769!\n",
      "Parameter id: 245 Numerical gradient of 0.000903 is not close to the backpropagation gradient of 0.090280!\n",
      "Parameter id: 246 Numerical gradient of -0.015380 is not close to the backpropagation gradient of -1.538014!\n",
      "Parameter id: 247 Numerical gradient of 0.016670 is not close to the backpropagation gradient of 1.666988!\n",
      "Parameter id: 248 Numerical gradient of 0.019617 is not close to the backpropagation gradient of 1.961684!\n",
      "Parameter id: 249 Numerical gradient of -0.012015 is not close to the backpropagation gradient of -1.201518!\n",
      "Parameter id: 250 Numerical gradient of 0.008783 is not close to the backpropagation gradient of 0.878294!\n",
      "Parameter id: 251 Numerical gradient of -0.004438 is not close to the backpropagation gradient of -0.443820!\n",
      "Parameter id: 252 Numerical gradient of -0.005109 is not close to the backpropagation gradient of -0.510852!\n",
      "Parameter id: 253 Numerical gradient of 0.014420 is not close to the backpropagation gradient of 1.441982!\n",
      "Parameter id: 254 Numerical gradient of -0.024973 is not close to the backpropagation gradient of -2.497331!\n",
      "Parameter id: 255 Numerical gradient of 0.018529 is not close to the backpropagation gradient of 1.852900!\n",
      "Parameter id: 256 Numerical gradient of 0.002921 is not close to the backpropagation gradient of 0.292077!\n",
      "Parameter id: 257 Numerical gradient of -0.008233 is not close to the backpropagation gradient of -0.823287!\n",
      "Parameter id: 258 Numerical gradient of 0.000431 is not close to the backpropagation gradient of 0.043146!\n",
      "Parameter id: 259 Numerical gradient of -0.020142 is not close to the backpropagation gradient of -2.014224!\n",
      "Parameter id: 260 Numerical gradient of -0.016691 is not close to the backpropagation gradient of -1.669055!\n",
      "Parameter id: 261 Numerical gradient of -0.047585 is not close to the backpropagation gradient of -4.758496!\n",
      "Parameter id: 262 Numerical gradient of 0.000992 is not close to the backpropagation gradient of 0.099186!\n",
      "Parameter id: 263 Numerical gradient of 0.049681 is not close to the backpropagation gradient of 4.968115!\n",
      "Parameter id: 264 Numerical gradient of 0.010857 is not close to the backpropagation gradient of 1.085718!\n",
      "Parameter id: 265 Numerical gradient of 0.020089 is not close to the backpropagation gradient of 2.008901!\n",
      "Parameter id: 266 Numerical gradient of 0.036577 is not close to the backpropagation gradient of 3.657716!\n",
      "Parameter id: 267 Numerical gradient of -0.012577 is not close to the backpropagation gradient of -1.257747!\n",
      "Parameter id: 268 Numerical gradient of 0.012367 is not close to the backpropagation gradient of 1.236669!\n",
      "Parameter id: 269 Numerical gradient of -0.042467 is not close to the backpropagation gradient of -4.246748!\n",
      "Parameter id: 270 Numerical gradient of 0.033331 is not close to the backpropagation gradient of 3.333054!\n",
      "Parameter id: 271 Numerical gradient of -0.006071 is not close to the backpropagation gradient of -0.607075!\n",
      "Parameter id: 272 Numerical gradient of -0.015039 is not close to the backpropagation gradient of -1.503922!\n",
      "Parameter id: 273 Numerical gradient of -0.002544 is not close to the backpropagation gradient of -0.254417!\n",
      "Parameter id: 274 Numerical gradient of -0.012933 is not close to the backpropagation gradient of -1.293275!\n",
      "Parameter id: 275 Numerical gradient of -0.001597 is not close to the backpropagation gradient of -0.159697!\n",
      "Parameter id: 276 Numerical gradient of 0.012046 is not close to the backpropagation gradient of 1.204647!\n",
      "Parameter id: 277 Numerical gradient of -0.012849 is not close to the backpropagation gradient of -1.284919!\n",
      "Parameter id: 278 Numerical gradient of -0.014472 is not close to the backpropagation gradient of -1.447167!\n",
      "Parameter id: 279 Numerical gradient of 0.005320 is not close to the backpropagation gradient of 0.531968!\n",
      "Parameter id: 280 Numerical gradient of -0.007220 is not close to the backpropagation gradient of -0.722023!\n",
      "Parameter id: 281 Numerical gradient of 0.005839 is not close to the backpropagation gradient of 0.583928!\n",
      "Parameter id: 282 Numerical gradient of 0.001381 is not close to the backpropagation gradient of 0.138134!\n",
      "Parameter id: 283 Numerical gradient of -0.001290 is not close to the backpropagation gradient of -0.129041!\n",
      "Parameter id: 284 Numerical gradient of 0.014154 is not close to the backpropagation gradient of 1.415377!\n",
      "Parameter id: 285 Numerical gradient of -0.011347 is not close to the backpropagation gradient of -1.134694!\n",
      "Parameter id: 286 Numerical gradient of -0.009410 is not close to the backpropagation gradient of -0.941019!\n",
      "Parameter id: 287 Numerical gradient of 0.007119 is not close to the backpropagation gradient of 0.711892!\n",
      "Parameter id: 288 Numerical gradient of -0.005851 is not close to the backpropagation gradient of -0.585061!\n",
      "Parameter id: 289 Numerical gradient of 0.023108 is not close to the backpropagation gradient of 2.310842!\n",
      "Parameter id: 290 Numerical gradient of 0.011578 is not close to the backpropagation gradient of 1.157766!\n",
      "Parameter id: 291 Numerical gradient of 0.028122 is not close to the backpropagation gradient of 2.812222!\n",
      "Parameter id: 292 Numerical gradient of -0.004594 is not close to the backpropagation gradient of -0.459434!\n",
      "Parameter id: 293 Numerical gradient of -0.034706 is not close to the backpropagation gradient of -3.470620!\n",
      "Parameter id: 294 Numerical gradient of -0.006088 is not close to the backpropagation gradient of -0.608843!\n",
      "Parameter id: 295 Numerical gradient of -0.015004 is not close to the backpropagation gradient of -1.500445!\n",
      "Parameter id: 296 Numerical gradient of -0.021767 is not close to the backpropagation gradient of -2.176673!\n",
      "Parameter id: 297 Numerical gradient of 0.007040 is not close to the backpropagation gradient of 0.703997!\n",
      "Parameter id: 298 Numerical gradient of -0.003862 is not close to the backpropagation gradient of -0.386185!\n",
      "Parameter id: 299 Numerical gradient of 0.027989 is not close to the backpropagation gradient of 2.798919!\n",
      "Parameter id: 300 Numerical gradient of -0.051893 is not close to the backpropagation gradient of -5.189337!\n",
      "Parameter id: 301 Numerical gradient of 0.012949 is not close to the backpropagation gradient of 1.294872!\n",
      "Parameter id: 302 Numerical gradient of 0.019711 is not close to the backpropagation gradient of 1.971082!\n",
      "Parameter id: 303 Numerical gradient of 0.006637 is not close to the backpropagation gradient of 0.663737!\n",
      "Parameter id: 304 Numerical gradient of 0.021462 is not close to the backpropagation gradient of 2.146214!\n",
      "Parameter id: 305 Numerical gradient of 0.000298 is not close to the backpropagation gradient of 0.029761!\n",
      "Parameter id: 306 Numerical gradient of -0.017694 is not close to the backpropagation gradient of -1.769355!\n",
      "Parameter id: 307 Numerical gradient of 0.017077 is not close to the backpropagation gradient of 1.707750!\n",
      "Parameter id: 308 Numerical gradient of 0.020663 is not close to the backpropagation gradient of 2.066254!\n",
      "Parameter id: 309 Numerical gradient of -0.010100 is not close to the backpropagation gradient of -1.010020!\n",
      "Parameter id: 310 Numerical gradient of 0.008126 is not close to the backpropagation gradient of 0.812575!\n",
      "Parameter id: 311 Numerical gradient of -0.004784 is not close to the backpropagation gradient of -0.478388!\n",
      "Parameter id: 312 Numerical gradient of -0.002110 is not close to the backpropagation gradient of -0.211011!\n",
      "Parameter id: 313 Numerical gradient of 0.007602 is not close to the backpropagation gradient of 0.760238!\n",
      "Parameter id: 314 Numerical gradient of -0.023205 is not close to the backpropagation gradient of -2.320481!\n",
      "Parameter id: 315 Numerical gradient of 0.020595 is not close to the backpropagation gradient of 2.059459!\n",
      "Parameter id: 316 Numerical gradient of 0.006347 is not close to the backpropagation gradient of 0.634747!\n",
      "Parameter id: 317 Numerical gradient of -0.010319 is not close to the backpropagation gradient of -1.031911!\n",
      "Parameter id: 318 Numerical gradient of 0.001542 is not close to the backpropagation gradient of 0.154234!\n",
      "Parameter id: 319 Numerical gradient of -0.022478 is not close to the backpropagation gradient of -2.247761!\n",
      "Parameter id: 320 Numerical gradient of -0.017791 is not close to the backpropagation gradient of -1.779078!\n",
      "Parameter id: 321 Numerical gradient of -0.051267 is not close to the backpropagation gradient of -5.126671!\n",
      "Parameter id: 322 Numerical gradient of 0.003286 is not close to the backpropagation gradient of 0.328643!\n",
      "Parameter id: 323 Numerical gradient of 0.049035 is not close to the backpropagation gradient of 4.903491!\n",
      "Parameter id: 324 Numerical gradient of 0.010792 is not close to the backpropagation gradient of 1.079185!\n",
      "Parameter id: 325 Numerical gradient of 0.022714 is not close to the backpropagation gradient of 2.271395!\n",
      "Parameter id: 326 Numerical gradient of 0.036961 is not close to the backpropagation gradient of 3.696111!\n",
      "Parameter id: 327 Numerical gradient of -0.012405 is not close to the backpropagation gradient of -1.240475!\n",
      "Parameter id: 328 Numerical gradient of 0.009627 is not close to the backpropagation gradient of 0.962729!\n",
      "Parameter id: 329 Numerical gradient of -0.042864 is not close to the backpropagation gradient of -4.286391!\n",
      "Parameter id: 330 Numerical gradient of 0.013970 is not close to the backpropagation gradient of 1.397014!\n",
      "Parameter id: 331 Numerical gradient of -0.003734 is not close to the backpropagation gradient of -0.373355!\n",
      "Parameter id: 332 Numerical gradient of -0.005518 is not close to the backpropagation gradient of -0.551767!\n",
      "Parameter id: 333 Numerical gradient of -0.002206 is not close to the backpropagation gradient of -0.220614!\n",
      "Parameter id: 334 Numerical gradient of -0.005335 is not close to the backpropagation gradient of -0.533485!\n",
      "Parameter id: 335 Numerical gradient of 0.002180 is not close to the backpropagation gradient of 0.217975!\n",
      "Parameter id: 336 Numerical gradient of 0.009516 is not close to the backpropagation gradient of 0.951559!\n",
      "Parameter id: 337 Numerical gradient of -0.004551 is not close to the backpropagation gradient of -0.455143!\n",
      "Parameter id: 338 Numerical gradient of -0.005867 is not close to the backpropagation gradient of -0.586696!\n",
      "Parameter id: 339 Numerical gradient of 0.001522 is not close to the backpropagation gradient of 0.152244!\n",
      "Parameter id: 340 Numerical gradient of 0.001119 is not close to the backpropagation gradient of 0.111877!\n",
      "Parameter id: 341 Numerical gradient of -0.001125 is not close to the backpropagation gradient of -0.112498!\n",
      "Parameter id: 342 Numerical gradient of -0.004718 is not close to the backpropagation gradient of -0.471808!\n",
      "Parameter id: 343 Numerical gradient of 0.007138 is not close to the backpropagation gradient of 0.713759!\n",
      "Parameter id: 344 Numerical gradient of 0.004395 is not close to the backpropagation gradient of 0.439540!\n",
      "Parameter id: 345 Numerical gradient of -0.015821 is not close to the backpropagation gradient of -1.582052!\n",
      "Parameter id: 346 Numerical gradient of -0.002150 is not close to the backpropagation gradient of -0.215049!\n",
      "Parameter id: 347 Numerical gradient of 0.005781 is not close to the backpropagation gradient of 0.578065!\n",
      "Parameter id: 348 Numerical gradient of 0.001217 is not close to the backpropagation gradient of 0.121690!\n",
      "Parameter id: 349 Numerical gradient of 0.008403 is not close to the backpropagation gradient of 0.840251!\n",
      "Parameter id: 350 Numerical gradient of 0.005870 is not close to the backpropagation gradient of 0.587001!\n",
      "Parameter id: 351 Numerical gradient of 0.026194 is not close to the backpropagation gradient of 2.619427!\n",
      "Parameter id: 352 Numerical gradient of -0.002693 is not close to the backpropagation gradient of -0.269280!\n",
      "Parameter id: 353 Numerical gradient of -0.013475 is not close to the backpropagation gradient of -1.347483!\n",
      "Parameter id: 354 Numerical gradient of -0.002135 is not close to the backpropagation gradient of -0.213469!\n",
      "Parameter id: 355 Numerical gradient of -0.012739 is not close to the backpropagation gradient of -1.273911!\n",
      "Parameter id: 356 Numerical gradient of -0.010889 is not close to the backpropagation gradient of -1.088936!\n",
      "Parameter id: 357 Numerical gradient of 0.001838 is not close to the backpropagation gradient of 0.183810!\n",
      "Parameter id: 358 Numerical gradient of 0.001558 is not close to the backpropagation gradient of 0.155817!\n",
      "Parameter id: 359 Numerical gradient of 0.016290 is not close to the backpropagation gradient of 1.629043!\n",
      "Parameter id: 360 Numerical gradient of -0.015848 is not close to the backpropagation gradient of -1.584815!\n",
      "Parameter id: 361 Numerical gradient of 0.002861 is not close to the backpropagation gradient of 0.286150!\n",
      "Parameter id: 362 Numerical gradient of 0.006472 is not close to the backpropagation gradient of 0.647236!\n",
      "Parameter id: 363 Numerical gradient of 0.002888 is not close to the backpropagation gradient of 0.288847!\n",
      "Parameter id: 364 Numerical gradient of 0.005725 is not close to the backpropagation gradient of 0.572534!\n",
      "Parameter id: 365 Numerical gradient of 0.001183 is not close to the backpropagation gradient of 0.118287!\n",
      "Parameter id: 366 Numerical gradient of -0.002388 is not close to the backpropagation gradient of -0.238791!\n",
      "Parameter id: 367 Numerical gradient of 0.005711 is not close to the backpropagation gradient of 0.571096!\n",
      "Parameter id: 368 Numerical gradient of 0.008357 is not close to the backpropagation gradient of 0.835681!\n",
      "Parameter id: 369 Numerical gradient of -0.004856 is not close to the backpropagation gradient of -0.485558!\n",
      "Parameter id: 370 Numerical gradient of 0.004731 is not close to the backpropagation gradient of 0.473115!\n",
      "Parameter id: 371 Numerical gradient of -0.002702 is not close to the backpropagation gradient of -0.270186!\n",
      "Parameter id: 372 Numerical gradient of -0.002652 is not close to the backpropagation gradient of -0.265250!\n",
      "Parameter id: 373 Numerical gradient of 0.006819 is not close to the backpropagation gradient of 0.681862!\n",
      "Parameter id: 374 Numerical gradient of -0.007529 is not close to the backpropagation gradient of -0.752859!\n",
      "Parameter id: 375 Numerical gradient of -0.000797 is not close to the backpropagation gradient of -0.079723!\n",
      "Parameter id: 376 Numerical gradient of 0.002926 is not close to the backpropagation gradient of 0.292560!\n",
      "Parameter id: 377 Numerical gradient of -0.002508 is not close to the backpropagation gradient of -0.250811!\n",
      "Parameter id: 378 Numerical gradient of 0.003140 is not close to the backpropagation gradient of 0.313973!\n",
      "Parameter id: 379 Numerical gradient of -0.008497 is not close to the backpropagation gradient of -0.849672!\n",
      "Parameter id: 380 Numerical gradient of -0.006216 is not close to the backpropagation gradient of -0.621584!\n",
      "Parameter id: 381 Numerical gradient of -0.008075 is not close to the backpropagation gradient of -0.807535!\n",
      "Parameter id: 382 Numerical gradient of 0.001272 is not close to the backpropagation gradient of 0.127221!\n",
      "Parameter id: 383 Numerical gradient of 0.016058 is not close to the backpropagation gradient of 1.605835!\n",
      "Parameter id: 384 Numerical gradient of 0.002850 is not close to the backpropagation gradient of 0.284981!\n",
      "Parameter id: 385 Numerical gradient of 0.004068 is not close to the backpropagation gradient of 0.406825!\n",
      "Parameter id: 386 Numerical gradient of 0.009975 is not close to the backpropagation gradient of 0.997536!\n",
      "Parameter id: 387 Numerical gradient of -0.004236 is not close to the backpropagation gradient of -0.423566!\n",
      "Parameter id: 388 Numerical gradient of 0.005117 is not close to the backpropagation gradient of 0.511687!\n",
      "Parameter id: 389 Numerical gradient of -0.011678 is not close to the backpropagation gradient of -1.167839!\n",
      "Parameter id: 390 Numerical gradient of 0.027076 is not close to the backpropagation gradient of 2.707607!\n",
      "Parameter id: 391 Numerical gradient of -0.005099 is not close to the backpropagation gradient of -0.509929!\n",
      "Parameter id: 392 Numerical gradient of -0.011802 is not close to the backpropagation gradient of -1.180235!\n",
      "Parameter id: 393 Numerical gradient of -0.004866 is not close to the backpropagation gradient of -0.486604!\n",
      "Parameter id: 394 Numerical gradient of -0.010934 is not close to the backpropagation gradient of -1.093354!\n",
      "Parameter id: 395 Numerical gradient of -0.000088 is not close to the backpropagation gradient of -0.008760!\n",
      "Parameter id: 396 Numerical gradient of 0.013997 is not close to the backpropagation gradient of 1.399726!\n",
      "Parameter id: 397 Numerical gradient of -0.011863 is not close to the backpropagation gradient of -1.186349!\n",
      "Parameter id: 398 Numerical gradient of -0.015733 is not close to the backpropagation gradient of -1.573297!\n",
      "Parameter id: 399 Numerical gradient of 0.005291 is not close to the backpropagation gradient of 0.529075!\n",
      "Parameter id: 400 Numerical gradient of -0.004174 is not close to the backpropagation gradient of -0.417403!\n",
      "Parameter id: 401 Numerical gradient of 0.002190 is not close to the backpropagation gradient of 0.218968!\n",
      "Parameter id: 402 Numerical gradient of -0.002831 is not close to the backpropagation gradient of -0.283104!\n",
      "Parameter id: 403 Numerical gradient of 0.003228 is not close to the backpropagation gradient of 0.322808!\n",
      "Parameter id: 404 Numerical gradient of 0.010116 is not close to the backpropagation gradient of 1.011588!\n",
      "Parameter id: 405 Numerical gradient of -0.014782 is not close to the backpropagation gradient of -1.478198!\n",
      "Parameter id: 406 Numerical gradient of -0.008664 is not close to the backpropagation gradient of -0.866434!\n",
      "Parameter id: 407 Numerical gradient of 0.009384 is not close to the backpropagation gradient of 0.938354!\n",
      "Parameter id: 408 Numerical gradient of -0.004743 is not close to the backpropagation gradient of -0.474264!\n",
      "Parameter id: 409 Numerical gradient of 0.019793 is not close to the backpropagation gradient of 1.979320!\n",
      "Parameter id: 410 Numerical gradient of 0.013121 is not close to the backpropagation gradient of 1.312085!\n",
      "Parameter id: 411 Numerical gradient of 0.035002 is not close to the backpropagation gradient of 3.500180!\n",
      "Parameter id: 412 Numerical gradient of -0.005708 is not close to the backpropagation gradient of -0.570758!\n",
      "Parameter id: 413 Numerical gradient of -0.030682 is not close to the backpropagation gradient of -3.068211!\n",
      "Parameter id: 414 Numerical gradient of -0.005862 is not close to the backpropagation gradient of -0.586179!\n",
      "Parameter id: 415 Numerical gradient of -0.017980 is not close to the backpropagation gradient of -1.797970!\n",
      "Parameter id: 416 Numerical gradient of -0.019622 is not close to the backpropagation gradient of -1.962194!\n",
      "Parameter id: 417 Numerical gradient of 0.006952 is not close to the backpropagation gradient of 0.695235!\n",
      "Parameter id: 418 Numerical gradient of -0.002845 is not close to the backpropagation gradient of -0.284461!\n",
      "Parameter id: 419 Numerical gradient of 0.030447 is not close to the backpropagation gradient of 3.044654!\n",
      "Parameter id: 420 Numerical gradient of -0.039181 is not close to the backpropagation gradient of -3.918078!\n",
      "Parameter id: 421 Numerical gradient of 0.009219 is not close to the backpropagation gradient of 0.921905!\n",
      "Parameter id: 422 Numerical gradient of 0.014494 is not close to the backpropagation gradient of 1.449392!\n",
      "Parameter id: 423 Numerical gradient of 0.005621 is not close to the backpropagation gradient of 0.562062!\n",
      "Parameter id: 424 Numerical gradient of 0.016819 is not close to the backpropagation gradient of 1.681882!\n",
      "Parameter id: 425 Numerical gradient of -0.001055 is not close to the backpropagation gradient of -0.105502!\n",
      "Parameter id: 426 Numerical gradient of -0.014411 is not close to the backpropagation gradient of -1.441131!\n",
      "Parameter id: 427 Numerical gradient of 0.012554 is not close to the backpropagation gradient of 1.255355!\n",
      "Parameter id: 428 Numerical gradient of 0.015370 is not close to the backpropagation gradient of 1.537017!\n",
      "Parameter id: 429 Numerical gradient of -0.004839 is not close to the backpropagation gradient of -0.483923!\n",
      "Parameter id: 430 Numerical gradient of 0.006106 is not close to the backpropagation gradient of 0.610629!\n",
      "Parameter id: 431 Numerical gradient of -0.003131 is not close to the backpropagation gradient of -0.313100!\n",
      "Parameter id: 432 Numerical gradient of 0.001960 is not close to the backpropagation gradient of 0.196008!\n",
      "Parameter id: 433 Numerical gradient of -0.001317 is not close to the backpropagation gradient of -0.131719!\n",
      "Parameter id: 434 Numerical gradient of -0.017757 is not close to the backpropagation gradient of -1.775653!\n",
      "Parameter id: 435 Numerical gradient of 0.020371 is not close to the backpropagation gradient of 2.037081!\n",
      "Parameter id: 436 Numerical gradient of 0.006853 is not close to the backpropagation gradient of 0.685254!\n",
      "Parameter id: 437 Numerical gradient of -0.012282 is not close to the backpropagation gradient of -1.228204!\n",
      "Parameter id: 438 Numerical gradient of -0.000630 is not close to the backpropagation gradient of -0.063047!\n",
      "Parameter id: 439 Numerical gradient of -0.018338 is not close to the backpropagation gradient of -1.833764!\n",
      "Parameter id: 440 Numerical gradient of -0.015113 is not close to the backpropagation gradient of -1.511299!\n",
      "Parameter id: 441 Numerical gradient of -0.048766 is not close to the backpropagation gradient of -4.876624!\n",
      "Parameter id: 442 Numerical gradient of 0.004221 is not close to the backpropagation gradient of 0.422060!\n",
      "Parameter id: 443 Numerical gradient of 0.037489 is not close to the backpropagation gradient of 3.748899!\n",
      "Parameter id: 444 Numerical gradient of 0.008846 is not close to the backpropagation gradient of 0.884626!\n",
      "Parameter id: 445 Numerical gradient of 0.020973 is not close to the backpropagation gradient of 2.097316!\n",
      "Parameter id: 446 Numerical gradient of 0.029916 is not close to the backpropagation gradient of 2.991630!\n",
      "Parameter id: 447 Numerical gradient of -0.008584 is not close to the backpropagation gradient of -0.858425!\n",
      "Parameter id: 448 Numerical gradient of 0.003315 is not close to the backpropagation gradient of 0.331474!\n",
      "Parameter id: 449 Numerical gradient of -0.034510 is not close to the backpropagation gradient of -3.451013!\n",
      "Parameter id: 450 Numerical gradient of -0.053405 is not close to the backpropagation gradient of -5.340520!\n",
      "Parameter id: 451 Numerical gradient of 0.013005 is not close to the backpropagation gradient of 1.300526!\n",
      "Parameter id: 452 Numerical gradient of 0.018318 is not close to the backpropagation gradient of 1.831784!\n",
      "Parameter id: 453 Numerical gradient of 0.007703 is not close to the backpropagation gradient of 0.770342!\n",
      "Parameter id: 454 Numerical gradient of 0.021639 is not close to the backpropagation gradient of 2.163945!\n",
      "Parameter id: 455 Numerical gradient of 0.000097 is not close to the backpropagation gradient of 0.009655!\n",
      "Parameter id: 456 Numerical gradient of -0.013871 is not close to the backpropagation gradient of -1.387128!\n",
      "Parameter id: 457 Numerical gradient of 0.014813 is not close to the backpropagation gradient of 1.481269!\n",
      "Parameter id: 458 Numerical gradient of 0.018469 is not close to the backpropagation gradient of 1.846903!\n",
      "Parameter id: 459 Numerical gradient of -0.010876 is not close to the backpropagation gradient of -1.087600!\n",
      "Parameter id: 460 Numerical gradient of 0.008755 is not close to the backpropagation gradient of 0.875505!\n",
      "Parameter id: 461 Numerical gradient of -0.003794 is not close to the backpropagation gradient of -0.379375!\n",
      "Parameter id: 462 Numerical gradient of -0.004234 is not close to the backpropagation gradient of -0.423386!\n",
      "Parameter id: 463 Numerical gradient of 0.013323 is not close to the backpropagation gradient of 1.332254!\n",
      "Parameter id: 464 Numerical gradient of -0.024453 is not close to the backpropagation gradient of -2.445308!\n",
      "Parameter id: 465 Numerical gradient of 0.018239 is not close to the backpropagation gradient of 1.823874!\n",
      "Parameter id: 466 Numerical gradient of 0.003080 is not close to the backpropagation gradient of 0.307968!\n",
      "Parameter id: 467 Numerical gradient of -0.008302 is not close to the backpropagation gradient of -0.830165!\n",
      "Parameter id: 468 Numerical gradient of -0.000964 is not close to the backpropagation gradient of -0.096447!\n",
      "Parameter id: 469 Numerical gradient of -0.018268 is not close to the backpropagation gradient of -1.826837!\n",
      "Parameter id: 470 Numerical gradient of -0.016696 is not close to the backpropagation gradient of -1.669627!\n",
      "Parameter id: 471 Numerical gradient of -0.046955 is not close to the backpropagation gradient of -4.695504!\n",
      "Parameter id: 472 Numerical gradient of 0.000519 is not close to the backpropagation gradient of 0.051923!\n",
      "Parameter id: 473 Numerical gradient of 0.046856 is not close to the backpropagation gradient of 4.685592!\n",
      "Parameter id: 474 Numerical gradient of 0.010614 is not close to the backpropagation gradient of 1.061417!\n",
      "Parameter id: 475 Numerical gradient of 0.019201 is not close to the backpropagation gradient of 1.920106!\n",
      "Parameter id: 476 Numerical gradient of 0.035957 is not close to the backpropagation gradient of 3.595706!\n",
      "Parameter id: 477 Numerical gradient of -0.011316 is not close to the backpropagation gradient of -1.131627!\n",
      "Parameter id: 478 Numerical gradient of 0.011340 is not close to the backpropagation gradient of 1.134009!\n",
      "Parameter id: 479 Numerical gradient of -0.039632 is not close to the backpropagation gradient of -3.963155!\n",
      "Parameter id: 480 Numerical gradient of 0.028175 is not close to the backpropagation gradient of 2.817493!\n",
      "Parameter id: 481 Numerical gradient of -0.006250 is not close to the backpropagation gradient of -0.624971!\n",
      "Parameter id: 482 Numerical gradient of -0.009695 is not close to the backpropagation gradient of -0.969513!\n",
      "Parameter id: 483 Numerical gradient of -0.002601 is not close to the backpropagation gradient of -0.260109!\n",
      "Parameter id: 484 Numerical gradient of -0.010173 is not close to the backpropagation gradient of -1.017296!\n",
      "Parameter id: 485 Numerical gradient of -0.001109 is not close to the backpropagation gradient of -0.110916!\n",
      "Parameter id: 486 Numerical gradient of 0.007609 is not close to the backpropagation gradient of 0.760894!\n",
      "Parameter id: 487 Numerical gradient of -0.009247 is not close to the backpropagation gradient of -0.924668!\n",
      "Parameter id: 488 Numerical gradient of -0.010378 is not close to the backpropagation gradient of -1.037786!\n",
      "Parameter id: 489 Numerical gradient of 0.005479 is not close to the backpropagation gradient of 0.547860!\n",
      "Parameter id: 490 Numerical gradient of -0.004763 is not close to the backpropagation gradient of -0.476283!\n",
      "Parameter id: 491 Numerical gradient of 0.003720 is not close to the backpropagation gradient of 0.372007!\n",
      "Parameter id: 492 Numerical gradient of 0.002969 is not close to the backpropagation gradient of 0.296879!\n",
      "Parameter id: 493 Numerical gradient of -0.006895 is not close to the backpropagation gradient of -0.689454!\n",
      "Parameter id: 494 Numerical gradient of 0.012111 is not close to the backpropagation gradient of 1.211110!\n",
      "Parameter id: 495 Numerical gradient of -0.007044 is not close to the backpropagation gradient of -0.704445!\n",
      "Parameter id: 496 Numerical gradient of -0.002254 is not close to the backpropagation gradient of -0.225356!\n",
      "Parameter id: 497 Numerical gradient of 0.003190 is not close to the backpropagation gradient of 0.318997!\n",
      "Parameter id: 498 Numerical gradient of -0.002623 is not close to the backpropagation gradient of -0.262340!\n",
      "Parameter id: 499 Numerical gradient of 0.012723 is not close to the backpropagation gradient of 1.272259!\n",
      "Parameter id: 500 Numerical gradient of 0.007704 is not close to the backpropagation gradient of 0.770408!\n",
      "Parameter id: 501 Numerical gradient of 0.021468 is not close to the backpropagation gradient of 2.146798!\n",
      "Parameter id: 502 Numerical gradient of -0.000540 is not close to the backpropagation gradient of -0.054026!\n",
      "Parameter id: 503 Numerical gradient of -0.025091 is not close to the backpropagation gradient of -2.509090!\n",
      "Parameter id: 504 Numerical gradient of -0.004520 is not close to the backpropagation gradient of -0.452032!\n",
      "Parameter id: 505 Numerical gradient of -0.010671 is not close to the backpropagation gradient of -1.067053!\n",
      "Parameter id: 506 Numerical gradient of -0.018365 is not close to the backpropagation gradient of -1.836467!\n",
      "Parameter id: 507 Numerical gradient of 0.005604 is not close to the backpropagation gradient of 0.560367!\n",
      "Parameter id: 508 Numerical gradient of -0.005720 is not close to the backpropagation gradient of -0.571994!\n",
      "Parameter id: 509 Numerical gradient of 0.020806 is not close to the backpropagation gradient of 2.080636!\n",
      "Parameter id: 510 Numerical gradient of -0.044832 is not close to the backpropagation gradient of -4.483225!\n",
      "Parameter id: 511 Numerical gradient of 0.010875 is not close to the backpropagation gradient of 1.087494!\n",
      "Parameter id: 512 Numerical gradient of 0.016642 is not close to the backpropagation gradient of 1.664192!\n",
      "Parameter id: 513 Numerical gradient of 0.005292 is not close to the backpropagation gradient of 0.529234!\n",
      "Parameter id: 514 Numerical gradient of 0.017559 is not close to the backpropagation gradient of 1.755946!\n",
      "Parameter id: 515 Numerical gradient of 0.000029 is not close to the backpropagation gradient of 0.002880!\n",
      "Parameter id: 516 Numerical gradient of -0.015234 is not close to the backpropagation gradient of -1.523430!\n",
      "Parameter id: 517 Numerical gradient of 0.015019 is not close to the backpropagation gradient of 1.501946!\n",
      "Parameter id: 518 Numerical gradient of 0.018462 is not close to the backpropagation gradient of 1.846201!\n",
      "Parameter id: 519 Numerical gradient of -0.007959 is not close to the backpropagation gradient of -0.795876!\n",
      "Parameter id: 520 Numerical gradient of 0.007270 is not close to the backpropagation gradient of 0.727040!\n",
      "Parameter id: 521 Numerical gradient of -0.003980 is not close to the backpropagation gradient of -0.397964!\n",
      "Parameter id: 522 Numerical gradient of -0.001310 is not close to the backpropagation gradient of -0.131037!\n",
      "Parameter id: 523 Numerical gradient of 0.006832 is not close to the backpropagation gradient of 0.683173!\n",
      "Parameter id: 524 Numerical gradient of -0.019753 is not close to the backpropagation gradient of -1.975325!\n",
      "Parameter id: 525 Numerical gradient of 0.017708 is not close to the backpropagation gradient of 1.770781!\n",
      "Parameter id: 526 Numerical gradient of 0.005539 is not close to the backpropagation gradient of 0.553868!\n",
      "Parameter id: 527 Numerical gradient of -0.008444 is not close to the backpropagation gradient of -0.844378!\n",
      "Parameter id: 528 Numerical gradient of 0.002234 is not close to the backpropagation gradient of 0.223361!\n",
      "Parameter id: 529 Numerical gradient of -0.021448 is not close to the backpropagation gradient of -2.144801!\n",
      "Parameter id: 530 Numerical gradient of -0.014589 is not close to the backpropagation gradient of -1.458890!\n",
      "Parameter id: 531 Numerical gradient of -0.042863 is not close to the backpropagation gradient of -4.286298!\n",
      "Parameter id: 532 Numerical gradient of 0.002767 is not close to the backpropagation gradient of 0.276701!\n",
      "Parameter id: 533 Numerical gradient of 0.042535 is not close to the backpropagation gradient of 4.253480!\n",
      "Parameter id: 534 Numerical gradient of 0.008864 is not close to the backpropagation gradient of 0.886425!\n",
      "Parameter id: 535 Numerical gradient of 0.020592 is not close to the backpropagation gradient of 2.059172!\n",
      "Parameter id: 536 Numerical gradient of 0.030969 is not close to the backpropagation gradient of 3.096896!\n",
      "Parameter id: 537 Numerical gradient of -0.010087 is not close to the backpropagation gradient of -1.008690!\n",
      "Parameter id: 538 Numerical gradient of 0.007668 is not close to the backpropagation gradient of 0.766763!\n",
      "Parameter id: 539 Numerical gradient of -0.037559 is not close to the backpropagation gradient of -3.755900!\n",
      "Parameter id: 540 Numerical gradient of 0.040266 is not close to the backpropagation gradient of 4.026573!\n",
      "Parameter id: 541 Numerical gradient of -0.010378 is not close to the backpropagation gradient of -1.037842!\n",
      "Parameter id: 542 Numerical gradient of -0.010565 is not close to the backpropagation gradient of -1.056525!\n",
      "Parameter id: 543 Numerical gradient of -0.005380 is not close to the backpropagation gradient of -0.538045!\n",
      "Parameter id: 544 Numerical gradient of -0.017182 is not close to the backpropagation gradient of -1.718159!\n",
      "Parameter id: 545 Numerical gradient of 0.000126 is not close to the backpropagation gradient of 0.012640!\n",
      "Parameter id: 546 Numerical gradient of 0.010422 is not close to the backpropagation gradient of 1.042193!\n",
      "Parameter id: 547 Numerical gradient of -0.008484 is not close to the backpropagation gradient of -0.848422!\n",
      "Parameter id: 548 Numerical gradient of -0.007258 is not close to the backpropagation gradient of -0.725842!\n",
      "Parameter id: 549 Numerical gradient of 0.006562 is not close to the backpropagation gradient of 0.656201!\n",
      "Parameter id: 550 Numerical gradient of -0.003732 is not close to the backpropagation gradient of -0.373198!\n",
      "Parameter id: 551 Numerical gradient of 0.001831 is not close to the backpropagation gradient of 0.183085!\n",
      "Parameter id: 552 Numerical gradient of 0.002830 is not close to the backpropagation gradient of 0.282985!\n",
      "Parameter id: 553 Numerical gradient of -0.005412 is not close to the backpropagation gradient of -0.541179!\n",
      "Parameter id: 554 Numerical gradient of 0.018786 is not close to the backpropagation gradient of 1.878615!\n",
      "Parameter id: 555 Numerical gradient of -0.020545 is not close to the backpropagation gradient of -2.054525!\n",
      "Parameter id: 556 Numerical gradient of 0.004177 is not close to the backpropagation gradient of 0.417698!\n",
      "Parameter id: 557 Numerical gradient of 0.006749 is not close to the backpropagation gradient of 0.674943!\n",
      "Parameter id: 558 Numerical gradient of 0.005686 is not close to the backpropagation gradient of 0.568555!\n",
      "Parameter id: 559 Numerical gradient of 0.007859 is not close to the backpropagation gradient of 0.785942!\n",
      "Parameter id: 560 Numerical gradient of 0.009347 is not close to the backpropagation gradient of 0.934674!\n",
      "Parameter id: 561 Numerical gradient of 0.043040 is not close to the backpropagation gradient of 4.304050!\n",
      "Parameter id: 562 Numerical gradient of 0.002114 is not close to the backpropagation gradient of 0.211357!\n",
      "Parameter id: 563 Numerical gradient of -0.031087 is not close to the backpropagation gradient of -3.108710!\n",
      "Parameter id: 564 Numerical gradient of -0.007727 is not close to the backpropagation gradient of -0.772656!\n",
      "Parameter id: 565 Numerical gradient of -0.014809 is not close to the backpropagation gradient of -1.480884!\n",
      "Parameter id: 566 Numerical gradient of -0.028294 is not close to the backpropagation gradient of -2.829396!\n",
      "Parameter id: 567 Numerical gradient of 0.006677 is not close to the backpropagation gradient of 0.667669!\n",
      "Parameter id: 568 Numerical gradient of -0.005754 is not close to the backpropagation gradient of -0.575407!\n",
      "Parameter id: 569 Numerical gradient of 0.027622 is not close to the backpropagation gradient of 2.762151!\n",
      "Parameter id: 570 Numerical gradient of 0.003430 is not close to the backpropagation gradient of 0.342995!\n",
      "Parameter id: 571 Numerical gradient of 0.000146 is not close to the backpropagation gradient of 0.014631!\n",
      "Parameter id: 572 Numerical gradient of -0.004293 is not close to the backpropagation gradient of -0.429257!\n",
      "Parameter id: 573 Numerical gradient of -0.004174 is not close to the backpropagation gradient of -0.417398!\n",
      "Parameter id: 574 Numerical gradient of -0.001955 is not close to the backpropagation gradient of -0.195490!\n",
      "Parameter id: 575 Numerical gradient of -0.000044 is not close to the backpropagation gradient of -0.004442!\n",
      "Parameter id: 576 Numerical gradient of 0.008500 is not close to the backpropagation gradient of 0.849991!\n",
      "Parameter id: 577 Numerical gradient of -0.004999 is not close to the backpropagation gradient of -0.499904!\n",
      "Parameter id: 578 Numerical gradient of -0.010651 is not close to the backpropagation gradient of -1.065108!\n",
      "Parameter id: 579 Numerical gradient of 0.004492 is not close to the backpropagation gradient of 0.449224!\n",
      "Parameter id: 580 Numerical gradient of -0.000687 is not close to the backpropagation gradient of -0.068690!\n",
      "Parameter id: 581 Numerical gradient of -0.001649 is not close to the backpropagation gradient of -0.164902!\n",
      "Parameter id: 582 Numerical gradient of -0.003793 is not close to the backpropagation gradient of -0.379311!\n",
      "Parameter id: 583 Numerical gradient of 0.003890 is not close to the backpropagation gradient of 0.388961!\n",
      "Parameter id: 584 Numerical gradient of -0.001594 is not close to the backpropagation gradient of -0.159425!\n",
      "Parameter id: 585 Numerical gradient of -0.005326 is not close to the backpropagation gradient of -0.532590!\n",
      "Parameter id: 586 Numerical gradient of -0.008265 is not close to the backpropagation gradient of -0.826494!\n",
      "Parameter id: 587 Numerical gradient of 0.005118 is not close to the backpropagation gradient of 0.511802!\n",
      "Parameter id: 588 Numerical gradient of -0.005594 is not close to the backpropagation gradient of -0.559427!\n",
      "Parameter id: 589 Numerical gradient of 0.010958 is not close to the backpropagation gradient of 1.095845!\n",
      "Parameter id: 590 Numerical gradient of 0.007832 is not close to the backpropagation gradient of 0.783196!\n",
      "Parameter id: 591 Numerical gradient of 0.012251 is not close to the backpropagation gradient of 1.225131!\n",
      "Parameter id: 592 Numerical gradient of -0.005054 is not close to the backpropagation gradient of -0.505408!\n",
      "Parameter id: 593 Numerical gradient of -0.011094 is not close to the backpropagation gradient of -1.109406!\n",
      "Parameter id: 594 Numerical gradient of -0.000375 is not close to the backpropagation gradient of -0.037456!\n",
      "Parameter id: 595 Numerical gradient of -0.008045 is not close to the backpropagation gradient of -0.804506!\n",
      "Parameter id: 596 Numerical gradient of -0.002566 is not close to the backpropagation gradient of -0.256590!\n",
      "Parameter id: 597 Numerical gradient of 0.002991 is not close to the backpropagation gradient of 0.299144!\n",
      "Parameter id: 598 Numerical gradient of -0.001282 is not close to the backpropagation gradient of -0.128209!\n",
      "Parameter id: 599 Numerical gradient of 0.014584 is not close to the backpropagation gradient of 1.458442!\n",
      "Parameter id: 600 Numerical gradient of -0.057155 is not close to the backpropagation gradient of -5.715549!\n",
      "Parameter id: 601 Numerical gradient of 0.014633 is not close to the backpropagation gradient of 1.463281!\n",
      "Parameter id: 602 Numerical gradient of 0.019227 is not close to the backpropagation gradient of 1.922655!\n",
      "Parameter id: 603 Numerical gradient of 0.008068 is not close to the backpropagation gradient of 0.806790!\n",
      "Parameter id: 604 Numerical gradient of 0.022786 is not close to the backpropagation gradient of 2.278571!\n",
      "Parameter id: 605 Numerical gradient of 0.000099 is not close to the backpropagation gradient of 0.009939!\n",
      "Parameter id: 606 Numerical gradient of -0.015415 is not close to the backpropagation gradient of -1.541455!\n",
      "Parameter id: 607 Numerical gradient of 0.016176 is not close to the backpropagation gradient of 1.617641!\n",
      "Parameter id: 608 Numerical gradient of 0.019830 is not close to the backpropagation gradient of 1.982992!\n",
      "Parameter id: 609 Numerical gradient of -0.012179 is not close to the backpropagation gradient of -1.217853!\n",
      "Parameter id: 610 Numerical gradient of 0.008428 is not close to the backpropagation gradient of 0.842808!\n",
      "Parameter id: 611 Numerical gradient of -0.003784 is not close to the backpropagation gradient of -0.378370!\n",
      "Parameter id: 612 Numerical gradient of -0.003926 is not close to the backpropagation gradient of -0.392614!\n",
      "Parameter id: 613 Numerical gradient of 0.013938 is not close to the backpropagation gradient of 1.393804!\n",
      "Parameter id: 614 Numerical gradient of -0.026228 is not close to the backpropagation gradient of -2.622831!\n",
      "Parameter id: 615 Numerical gradient of 0.020817 is not close to the backpropagation gradient of 2.081691!\n",
      "Parameter id: 616 Numerical gradient of 0.002379 is not close to the backpropagation gradient of 0.237850!\n",
      "Parameter id: 617 Numerical gradient of -0.009339 is not close to the backpropagation gradient of -0.933896!\n",
      "Parameter id: 618 Numerical gradient of -0.001699 is not close to the backpropagation gradient of -0.169855!\n",
      "Parameter id: 619 Numerical gradient of -0.018122 is not close to the backpropagation gradient of -1.812211!\n",
      "Parameter id: 620 Numerical gradient of -0.018374 is not close to the backpropagation gradient of -1.837355!\n",
      "Parameter id: 621 Numerical gradient of -0.053636 is not close to the backpropagation gradient of -5.363564!\n",
      "Parameter id: 622 Numerical gradient of 0.000410 is not close to the backpropagation gradient of 0.041042!\n",
      "Parameter id: 623 Numerical gradient of 0.049979 is not close to the backpropagation gradient of 4.997888!\n",
      "Parameter id: 624 Numerical gradient of 0.011446 is not close to the backpropagation gradient of 1.144612!\n",
      "Parameter id: 625 Numerical gradient of 0.020911 is not close to the backpropagation gradient of 2.091143!\n",
      "Parameter id: 626 Numerical gradient of 0.039466 is not close to the backpropagation gradient of 3.946564!\n",
      "Parameter id: 627 Numerical gradient of -0.012727 is not close to the backpropagation gradient of -1.272707!\n",
      "Parameter id: 628 Numerical gradient of 0.012081 is not close to the backpropagation gradient of 1.208131!\n",
      "Parameter id: 629 Numerical gradient of -0.043866 is not close to the backpropagation gradient of -4.386585!\n",
      "Parameter id: 630 Numerical gradient of 0.040222 is not close to the backpropagation gradient of 4.022153!\n",
      "Parameter id: 631 Numerical gradient of -0.009775 is not close to the backpropagation gradient of -0.977516!\n",
      "Parameter id: 632 Numerical gradient of -0.014122 is not close to the backpropagation gradient of -1.412228!\n",
      "Parameter id: 633 Numerical gradient of -0.001884 is not close to the backpropagation gradient of -0.188358!\n",
      "Parameter id: 634 Numerical gradient of -0.016366 is not close to the backpropagation gradient of -1.636649!\n",
      "Parameter id: 635 Numerical gradient of 0.001015 is not close to the backpropagation gradient of 0.101470!\n",
      "Parameter id: 636 Numerical gradient of 0.013019 is not close to the backpropagation gradient of 1.301935!\n",
      "Parameter id: 637 Numerical gradient of -0.011189 is not close to the backpropagation gradient of -1.118905!\n",
      "Parameter id: 638 Numerical gradient of -0.012778 is not close to the backpropagation gradient of -1.277763!\n",
      "Parameter id: 639 Numerical gradient of 0.001633 is not close to the backpropagation gradient of 0.163327!\n",
      "Parameter id: 640 Numerical gradient of -0.006344 is not close to the backpropagation gradient of -0.634396!\n",
      "Parameter id: 641 Numerical gradient of 0.003867 is not close to the backpropagation gradient of 0.386657!\n",
      "Parameter id: 642 Numerical gradient of -0.001950 is not close to the backpropagation gradient of -0.194963!\n",
      "Parameter id: 643 Numerical gradient of 0.002136 is not close to the backpropagation gradient of 0.213599!\n",
      "Parameter id: 644 Numerical gradient of 0.018874 is not close to the backpropagation gradient of 1.887403!\n",
      "Parameter id: 645 Numerical gradient of -0.021045 is not close to the backpropagation gradient of -2.104477!\n",
      "Parameter id: 646 Numerical gradient of -0.007024 is not close to the backpropagation gradient of -0.702424!\n",
      "Parameter id: 647 Numerical gradient of 0.011764 is not close to the backpropagation gradient of 1.176375!\n",
      "Parameter id: 648 Numerical gradient of 0.002363 is not close to the backpropagation gradient of 0.236332!\n",
      "Parameter id: 649 Numerical gradient of 0.017134 is not close to the backpropagation gradient of 1.713392!\n",
      "Parameter id: 650 Numerical gradient of 0.013889 is not close to the backpropagation gradient of 1.388945!\n",
      "Parameter id: 651 Numerical gradient of 0.048839 is not close to the backpropagation gradient of 4.883904!\n",
      "Parameter id: 652 Numerical gradient of -0.002965 is not close to the backpropagation gradient of -0.296486!\n",
      "Parameter id: 653 Numerical gradient of -0.035798 is not close to the backpropagation gradient of -3.579818!\n",
      "Parameter id: 654 Numerical gradient of -0.008663 is not close to the backpropagation gradient of -0.866269!\n",
      "Parameter id: 655 Numerical gradient of -0.020390 is not close to the backpropagation gradient of -2.038995!\n",
      "Parameter id: 656 Numerical gradient of -0.029720 is not close to the backpropagation gradient of -2.972034!\n",
      "Parameter id: 657 Numerical gradient of 0.006735 is not close to the backpropagation gradient of 0.673504!\n",
      "Parameter id: 658 Numerical gradient of -0.000427 is not close to the backpropagation gradient of -0.042747!\n",
      "Parameter id: 659 Numerical gradient of 0.031863 is not close to the backpropagation gradient of 3.186278!\n",
      "Parameter id: 660 Numerical gradient of 0.023155 is not close to the backpropagation gradient of 2.315535!\n",
      "Parameter id: 661 Numerical gradient of -0.003803 is not close to the backpropagation gradient of -0.380265!\n",
      "Parameter id: 662 Numerical gradient of -0.011481 is not close to the backpropagation gradient of -1.148094!\n",
      "Parameter id: 663 Numerical gradient of -0.003356 is not close to the backpropagation gradient of -0.335597!\n",
      "Parameter id: 664 Numerical gradient of -0.009258 is not close to the backpropagation gradient of -0.925838!\n",
      "Parameter id: 665 Numerical gradient of -0.001705 is not close to the backpropagation gradient of -0.170516!\n",
      "Parameter id: 666 Numerical gradient of 0.012208 is not close to the backpropagation gradient of 1.220791!\n",
      "Parameter id: 667 Numerical gradient of -0.010295 is not close to the backpropagation gradient of -1.029464!\n",
      "Parameter id: 668 Numerical gradient of -0.012743 is not close to the backpropagation gradient of -1.274312!\n",
      "Parameter id: 669 Numerical gradient of 0.006317 is not close to the backpropagation gradient of 0.631671!\n",
      "Parameter id: 670 Numerical gradient of -0.004285 is not close to the backpropagation gradient of -0.428506!\n",
      "Parameter id: 671 Numerical gradient of 0.003301 is not close to the backpropagation gradient of 0.330142!\n",
      "Parameter id: 672 Numerical gradient of -0.000902 is not close to the backpropagation gradient of -0.090190!\n",
      "Parameter id: 673 Numerical gradient of 0.002211 is not close to the backpropagation gradient of 0.221132!\n",
      "Parameter id: 674 Numerical gradient of 0.008234 is not close to the backpropagation gradient of 0.823418!\n",
      "Parameter id: 675 Numerical gradient of -0.011503 is not close to the backpropagation gradient of -1.150306!\n",
      "Parameter id: 676 Numerical gradient of -0.008981 is not close to the backpropagation gradient of -0.898147!\n",
      "Parameter id: 677 Numerical gradient of 0.007781 is not close to the backpropagation gradient of 0.778083!\n",
      "Parameter id: 678 Numerical gradient of -0.005788 is not close to the backpropagation gradient of -0.578788!\n",
      "Parameter id: 679 Numerical gradient of 0.019344 is not close to the backpropagation gradient of 1.934379!\n",
      "Parameter id: 680 Numerical gradient of 0.011086 is not close to the backpropagation gradient of 1.108555!\n",
      "Parameter id: 681 Numerical gradient of 0.026805 is not close to the backpropagation gradient of 2.680493!\n",
      "Parameter id: 682 Numerical gradient of -0.005262 is not close to the backpropagation gradient of -0.526183!\n",
      "Parameter id: 683 Numerical gradient of -0.027546 is not close to the backpropagation gradient of -2.754551!\n",
      "Parameter id: 684 Numerical gradient of -0.004690 is not close to the backpropagation gradient of -0.468985!\n",
      "Parameter id: 685 Numerical gradient of -0.013184 is not close to the backpropagation gradient of -1.318414!\n",
      "Parameter id: 686 Numerical gradient of -0.015813 is not close to the backpropagation gradient of -1.581293!\n",
      "Parameter id: 687 Numerical gradient of 0.006056 is not close to the backpropagation gradient of 0.605587!\n",
      "Parameter id: 688 Numerical gradient of -0.002172 is not close to the backpropagation gradient of -0.217203!\n",
      "Parameter id: 689 Numerical gradient of 0.025802 is not close to the backpropagation gradient of 2.580212!\n",
      "Parameter id: 690 Numerical gradient of 0.047241 is not close to the backpropagation gradient of 4.724108!\n",
      "Parameter id: 691 Numerical gradient of -0.012607 is not close to the backpropagation gradient of -1.260744!\n",
      "Parameter id: 692 Numerical gradient of -0.012051 is not close to the backpropagation gradient of -1.205068!\n",
      "Parameter id: 693 Numerical gradient of -0.007613 is not close to the backpropagation gradient of -0.761305!\n",
      "Parameter id: 694 Numerical gradient of -0.019990 is not close to the backpropagation gradient of -1.998999!\n",
      "Parameter id: 695 Numerical gradient of -0.000300 is not close to the backpropagation gradient of -0.029995!\n",
      "Parameter id: 696 Numerical gradient of 0.008503 is not close to the backpropagation gradient of 0.850252!\n",
      "Parameter id: 697 Numerical gradient of -0.009769 is not close to the backpropagation gradient of -0.976873!\n",
      "Parameter id: 698 Numerical gradient of -0.009775 is not close to the backpropagation gradient of -0.977548!\n",
      "Parameter id: 699 Numerical gradient of 0.009802 is not close to the backpropagation gradient of 0.980247!\n",
      "Parameter id: 700 Numerical gradient of -0.006921 is not close to the backpropagation gradient of -0.692086!\n",
      "Parameter id: 701 Numerical gradient of 0.002347 is not close to the backpropagation gradient of 0.234722!\n",
      "Parameter id: 702 Numerical gradient of 0.005696 is not close to the backpropagation gradient of 0.569610!\n",
      "Parameter id: 703 Numerical gradient of -0.015185 is not close to the backpropagation gradient of -1.518532!\n",
      "Parameter id: 704 Numerical gradient of 0.023542 is not close to the backpropagation gradient of 2.354203!\n",
      "Parameter id: 705 Numerical gradient of -0.017261 is not close to the backpropagation gradient of -1.726060!\n",
      "Parameter id: 706 Numerical gradient of 0.007450 is not close to the backpropagation gradient of 0.744998!\n",
      "Parameter id: 707 Numerical gradient of 0.006051 is not close to the backpropagation gradient of 0.605063!\n",
      "Parameter id: 708 Numerical gradient of 0.006458 is not close to the backpropagation gradient of 0.645779!\n",
      "Parameter id: 709 Numerical gradient of 0.006727 is not close to the backpropagation gradient of 0.672688!\n",
      "Parameter id: 710 Numerical gradient of 0.010687 is not close to the backpropagation gradient of 1.068690!\n",
      "Parameter id: 711 Numerical gradient of 0.042670 is not close to the backpropagation gradient of 4.266991!\n",
      "Parameter id: 712 Numerical gradient of 0.003970 is not close to the backpropagation gradient of 0.396985!\n",
      "Parameter id: 713 Numerical gradient of -0.036025 is not close to the backpropagation gradient of -3.602520!\n",
      "Parameter id: 714 Numerical gradient of -0.009833 is not close to the backpropagation gradient of -0.983335!\n",
      "Parameter id: 715 Numerical gradient of -0.014128 is not close to the backpropagation gradient of -1.412823!\n",
      "Parameter id: 716 Numerical gradient of -0.032481 is not close to the backpropagation gradient of -3.248132!\n",
      "Parameter id: 717 Numerical gradient of 0.009356 is not close to the backpropagation gradient of 0.935618!\n",
      "Parameter id: 718 Numerical gradient of -0.010493 is not close to the backpropagation gradient of -1.049303!\n",
      "Parameter id: 719 Numerical gradient of 0.030025 is not close to the backpropagation gradient of 3.002489!\n",
      "Parameter id: 720 Numerical gradient of 0.019130 is not close to the backpropagation gradient of 1.913010!\n",
      "Parameter id: 721 Numerical gradient of -0.005039 is not close to the backpropagation gradient of -0.503858!\n",
      "Parameter id: 722 Numerical gradient of -0.003119 is not close to the backpropagation gradient of -0.311912!\n",
      "Parameter id: 723 Numerical gradient of -0.001187 is not close to the backpropagation gradient of -0.118740!\n",
      "Parameter id: 724 Numerical gradient of -0.007254 is not close to the backpropagation gradient of -0.725394!\n",
      "Parameter id: 725 Numerical gradient of -0.001058 is not close to the backpropagation gradient of -0.105842!\n",
      "Parameter id: 726 Numerical gradient of -0.000401 is not close to the backpropagation gradient of -0.040133!\n",
      "Parameter id: 727 Numerical gradient of -0.002447 is not close to the backpropagation gradient of -0.244688!\n",
      "Parameter id: 728 Numerical gradient of 0.000133 is not close to the backpropagation gradient of 0.013274!\n",
      "Parameter id: 729 Numerical gradient of 0.002682 is not close to the backpropagation gradient of 0.268240!\n",
      "Parameter id: 730 Numerical gradient of -0.002904 is not close to the backpropagation gradient of -0.290359!\n",
      "Parameter id: 731 Numerical gradient of 0.001998 is not close to the backpropagation gradient of 0.199759!\n",
      "Parameter id: 732 Numerical gradient of 0.004811 is not close to the backpropagation gradient of 0.481145!\n",
      "Parameter id: 733 Numerical gradient of -0.010134 is not close to the backpropagation gradient of -1.013358!\n",
      "Parameter id: 734 Numerical gradient of 0.011179 is not close to the backpropagation gradient of 1.117894!\n",
      "Parameter id: 735 Numerical gradient of -0.002239 is not close to the backpropagation gradient of -0.223898!\n",
      "Parameter id: 736 Numerical gradient of 0.007564 is not close to the backpropagation gradient of 0.756366!\n",
      "Parameter id: 737 Numerical gradient of -0.000026 is not close to the backpropagation gradient of -0.002577!\n",
      "Parameter id: 738 Numerical gradient of 0.004395 is not close to the backpropagation gradient of 0.439490!\n",
      "Parameter id: 739 Numerical gradient of -0.002941 is not close to the backpropagation gradient of -0.294140!\n",
      "Parameter id: 740 Numerical gradient of 0.001986 is not close to the backpropagation gradient of 0.198613!\n",
      "Parameter id: 741 Numerical gradient of 0.011661 is not close to the backpropagation gradient of 1.166066!\n",
      "Parameter id: 742 Numerical gradient of 0.003888 is not close to the backpropagation gradient of 0.388840!\n",
      "Parameter id: 743 Numerical gradient of -0.011256 is not close to the backpropagation gradient of -1.125634!\n",
      "Parameter id: 744 Numerical gradient of -0.004472 is not close to the backpropagation gradient of -0.447167!\n",
      "Parameter id: 745 Numerical gradient of -0.001023 is not close to the backpropagation gradient of -0.102330!\n",
      "Parameter id: 746 Numerical gradient of -0.013171 is not close to the backpropagation gradient of -1.317141!\n",
      "Parameter id: 747 Numerical gradient of 0.003148 is not close to the backpropagation gradient of 0.314779!\n",
      "Parameter id: 748 Numerical gradient of -0.005136 is not close to the backpropagation gradient of -0.513630!\n",
      "Parameter id: 749 Numerical gradient of 0.006751 is not close to the backpropagation gradient of 0.675083!\n",
      "Parameter id: 750 Numerical gradient of -0.061394 is not close to the backpropagation gradient of -6.139422!\n",
      "Parameter id: 751 Numerical gradient of 0.016737 is not close to the backpropagation gradient of 1.673744!\n",
      "Parameter id: 752 Numerical gradient of 0.018090 is not close to the backpropagation gradient of 1.809026!\n",
      "Parameter id: 753 Numerical gradient of 0.010235 is not close to the backpropagation gradient of 1.023495!\n",
      "Parameter id: 754 Numerical gradient of 0.025045 is not close to the backpropagation gradient of 2.504503!\n",
      "Parameter id: 755 Numerical gradient of 0.000295 is not close to the backpropagation gradient of 0.029483!\n",
      "Parameter id: 756 Numerical gradient of -0.013756 is not close to the backpropagation gradient of -1.375588!\n",
      "Parameter id: 757 Numerical gradient of 0.014907 is not close to the backpropagation gradient of 1.490717!\n",
      "Parameter id: 758 Numerical gradient of 0.017292 is not close to the backpropagation gradient of 1.729247!\n",
      "Parameter id: 759 Numerical gradient of -0.014929 is not close to the backpropagation gradient of -1.492889!\n",
      "Parameter id: 760 Numerical gradient of 0.008136 is not close to the backpropagation gradient of 0.813639!\n",
      "Parameter id: 761 Numerical gradient of -0.002745 is not close to the backpropagation gradient of -0.274497!\n",
      "Parameter id: 762 Numerical gradient of -0.006678 is not close to the backpropagation gradient of -0.667820!\n",
      "Parameter id: 763 Numerical gradient of 0.020280 is not close to the backpropagation gradient of 2.028015!\n",
      "Parameter id: 764 Numerical gradient of -0.029078 is not close to the backpropagation gradient of -2.907835!\n",
      "Parameter id: 765 Numerical gradient of 0.021694 is not close to the backpropagation gradient of 2.169399!\n",
      "Parameter id: 766 Numerical gradient of -0.004806 is not close to the backpropagation gradient of -0.480598!\n",
      "Parameter id: 767 Numerical gradient of -0.007741 is not close to the backpropagation gradient of -0.774097!\n",
      "Parameter id: 768 Numerical gradient of -0.005235 is not close to the backpropagation gradient of -0.523502!\n",
      "Parameter id: 769 Numerical gradient of -0.011834 is not close to the backpropagation gradient of -1.183371!\n",
      "Parameter id: 770 Numerical gradient of -0.017031 is not close to the backpropagation gradient of -1.703110!\n",
      "Parameter id: 771 Numerical gradient of -0.055258 is not close to the backpropagation gradient of -5.525811!\n",
      "Parameter id: 772 Numerical gradient of -0.003237 is not close to the backpropagation gradient of -0.323650!\n",
      "Parameter id: 773 Numerical gradient of 0.049956 is not close to the backpropagation gradient of 4.995571!\n",
      "Parameter id: 774 Numerical gradient of 0.011794 is not close to the backpropagation gradient of 1.179388!\n",
      "Parameter id: 775 Numerical gradient of 0.018809 is not close to the backpropagation gradient of 1.880868!\n",
      "Parameter id: 776 Numerical gradient of 0.041765 is not close to the backpropagation gradient of 4.176493!\n",
      "Parameter id: 777 Numerical gradient of -0.013061 is not close to the backpropagation gradient of -1.306061!\n",
      "Parameter id: 778 Numerical gradient of 0.015461 is not close to the backpropagation gradient of 1.546121!\n",
      "Parameter id: 779 Numerical gradient of -0.042749 is not close to the backpropagation gradient of -4.274875!\n",
      "Parameter id: 780 Numerical gradient of -0.051423 is not close to the backpropagation gradient of -5.142282!\n",
      "Parameter id: 781 Numerical gradient of 0.012317 is not close to the backpropagation gradient of 1.231744!\n",
      "Parameter id: 782 Numerical gradient of 0.018534 is not close to the backpropagation gradient of 1.853420!\n",
      "Parameter id: 783 Numerical gradient of 0.006513 is not close to the backpropagation gradient of 0.651348!\n",
      "Parameter id: 784 Numerical gradient of 0.020745 is not close to the backpropagation gradient of 2.074475!\n",
      "Parameter id: 785 Numerical gradient of -0.001113 is not close to the backpropagation gradient of -0.111257!\n",
      "Parameter id: 786 Numerical gradient of -0.014454 is not close to the backpropagation gradient of -1.445416!\n",
      "Parameter id: 787 Numerical gradient of 0.015164 is not close to the backpropagation gradient of 1.516435!\n",
      "Parameter id: 788 Numerical gradient of 0.019969 is not close to the backpropagation gradient of 1.996916!\n",
      "Parameter id: 789 Numerical gradient of -0.007940 is not close to the backpropagation gradient of -0.794044!\n",
      "Parameter id: 790 Numerical gradient of 0.009195 is not close to the backpropagation gradient of 0.919462!\n",
      "Parameter id: 791 Numerical gradient of -0.004194 is not close to the backpropagation gradient of -0.419422!\n",
      "Parameter id: 792 Numerical gradient of -0.001308 is not close to the backpropagation gradient of -0.130788!\n",
      "Parameter id: 793 Numerical gradient of 0.007054 is not close to the backpropagation gradient of 0.705368!\n",
      "Parameter id: 794 Numerical gradient of -0.024003 is not close to the backpropagation gradient of -2.400313!\n",
      "Parameter id: 795 Numerical gradient of 0.020070 is not close to the backpropagation gradient of 2.006971!\n",
      "Parameter id: 796 Numerical gradient of 0.006896 is not close to the backpropagation gradient of 0.689592!\n",
      "Parameter id: 797 Numerical gradient of -0.010996 is not close to the backpropagation gradient of -1.099606!\n",
      "Parameter id: 798 Numerical gradient of -0.000195 is not close to the backpropagation gradient of -0.019532!\n",
      "Parameter id: 799 Numerical gradient of -0.021884 is not close to the backpropagation gradient of -2.188383!\n",
      "Parameter id: 800 Numerical gradient of -0.017027 is not close to the backpropagation gradient of -1.702682!\n",
      "Parameter id: 801 Numerical gradient of -0.050276 is not close to the backpropagation gradient of -5.027610!\n",
      "Parameter id: 802 Numerical gradient of 0.002680 is not close to the backpropagation gradient of 0.267982!\n",
      "Parameter id: 803 Numerical gradient of 0.046589 is not close to the backpropagation gradient of 4.658943!\n",
      "Parameter id: 804 Numerical gradient of 0.010818 is not close to the backpropagation gradient of 1.081823!\n",
      "Parameter id: 805 Numerical gradient of 0.022741 is not close to the backpropagation gradient of 2.274109!\n",
      "Parameter id: 806 Numerical gradient of 0.035883 is not close to the backpropagation gradient of 3.588278!\n",
      "Parameter id: 807 Numerical gradient of -0.011391 is not close to the backpropagation gradient of -1.139077!\n",
      "Parameter id: 808 Numerical gradient of 0.007126 is not close to the backpropagation gradient of 0.712628!\n",
      "Parameter id: 809 Numerical gradient of -0.040400 is not close to the backpropagation gradient of -4.040007!\n",
      "Parameter id: 810 Numerical gradient of 0.044947 is not close to the backpropagation gradient of 4.494689!\n",
      "Parameter id: 811 Numerical gradient of -0.010321 is not close to the backpropagation gradient of -1.032073!\n",
      "Parameter id: 812 Numerical gradient of -0.015984 is not close to the backpropagation gradient of -1.598369!\n",
      "Parameter id: 813 Numerical gradient of -0.002153 is not close to the backpropagation gradient of -0.215284!\n",
      "Parameter id: 814 Numerical gradient of -0.016235 is not close to the backpropagation gradient of -1.623469!\n",
      "Parameter id: 815 Numerical gradient of 0.000513 is not close to the backpropagation gradient of 0.051327!\n",
      "Parameter id: 816 Numerical gradient of 0.012608 is not close to the backpropagation gradient of 1.260775!\n",
      "Parameter id: 817 Numerical gradient of -0.013728 is not close to the backpropagation gradient of -1.372764!\n",
      "Parameter id: 818 Numerical gradient of -0.016014 is not close to the backpropagation gradient of -1.601353!\n",
      "Parameter id: 819 Numerical gradient of 0.004448 is not close to the backpropagation gradient of 0.444782!\n",
      "Parameter id: 820 Numerical gradient of -0.008248 is not close to the backpropagation gradient of -0.824849!\n",
      "Parameter id: 821 Numerical gradient of 0.004851 is not close to the backpropagation gradient of 0.485084!\n",
      "Parameter id: 822 Numerical gradient of 0.001309 is not close to the backpropagation gradient of 0.130874!\n",
      "Parameter id: 823 Numerical gradient of -0.004777 is not close to the backpropagation gradient of -0.477688!\n",
      "Parameter id: 824 Numerical gradient of 0.020317 is not close to the backpropagation gradient of 2.031701!\n",
      "Parameter id: 825 Numerical gradient of -0.017031 is not close to the backpropagation gradient of -1.703148!\n",
      "Parameter id: 826 Numerical gradient of -0.006700 is not close to the backpropagation gradient of -0.669958!\n",
      "Parameter id: 827 Numerical gradient of 0.007261 is not close to the backpropagation gradient of 0.726098!\n",
      "Parameter id: 828 Numerical gradient of -0.001572 is not close to the backpropagation gradient of -0.157226!\n",
      "Parameter id: 829 Numerical gradient of 0.021666 is not close to the backpropagation gradient of 2.166550!\n",
      "Parameter id: 830 Numerical gradient of 0.012913 is not close to the backpropagation gradient of 1.291329!\n",
      "Parameter id: 831 Numerical gradient of 0.039532 is not close to the backpropagation gradient of 3.953183!\n",
      "Parameter id: 832 Numerical gradient of -0.001825 is not close to the backpropagation gradient of -0.182471!\n",
      "Parameter id: 833 Numerical gradient of -0.040086 is not close to the backpropagation gradient of -4.008610!\n",
      "Parameter id: 834 Numerical gradient of -0.008317 is not close to the backpropagation gradient of -0.831717!\n",
      "Parameter id: 835 Numerical gradient of -0.019653 is not close to the backpropagation gradient of -1.965261!\n",
      "Parameter id: 836 Numerical gradient of -0.030316 is not close to the backpropagation gradient of -3.031572!\n",
      "Parameter id: 837 Numerical gradient of 0.008134 is not close to the backpropagation gradient of 0.813426!\n",
      "Parameter id: 838 Numerical gradient of -0.004942 is not close to the backpropagation gradient of -0.494198!\n",
      "Parameter id: 839 Numerical gradient of 0.033291 is not close to the backpropagation gradient of 3.329140!\n",
      "Parameter id: 840 Numerical gradient of -0.039579 is not close to the backpropagation gradient of -3.957868!\n",
      "Parameter id: 841 Numerical gradient of 0.008872 is not close to the backpropagation gradient of 0.887199!\n",
      "Parameter id: 842 Numerical gradient of 0.013176 is not close to the backpropagation gradient of 1.317584!\n",
      "Parameter id: 843 Numerical gradient of 0.003769 is not close to the backpropagation gradient of 0.376900!\n",
      "Parameter id: 844 Numerical gradient of 0.015792 is not close to the backpropagation gradient of 1.579173!\n",
      "Parameter id: 845 Numerical gradient of -0.000093 is not close to the backpropagation gradient of -0.009311!\n",
      "Parameter id: 846 Numerical gradient of -0.011394 is not close to the backpropagation gradient of -1.139367!\n",
      "Parameter id: 847 Numerical gradient of 0.011126 is not close to the backpropagation gradient of 1.112587!\n",
      "Parameter id: 848 Numerical gradient of 0.013067 is not close to the backpropagation gradient of 1.306698!\n",
      "Parameter id: 849 Numerical gradient of -0.004965 is not close to the backpropagation gradient of -0.496492!\n",
      "Parameter id: 850 Numerical gradient of 0.007208 is not close to the backpropagation gradient of 0.720755!\n",
      "Parameter id: 851 Numerical gradient of -0.004042 is not close to the backpropagation gradient of -0.404163!\n",
      "Parameter id: 852 Numerical gradient of -0.000848 is not close to the backpropagation gradient of -0.084845!\n",
      "Parameter id: 853 Numerical gradient of 0.001760 is not close to the backpropagation gradient of 0.176040!\n",
      "Parameter id: 854 Numerical gradient of -0.017552 is not close to the backpropagation gradient of -1.755230!\n",
      "Parameter id: 855 Numerical gradient of 0.018655 is not close to the backpropagation gradient of 1.865502!\n",
      "Parameter id: 856 Numerical gradient of 0.004449 is not close to the backpropagation gradient of 0.444864!\n",
      "Parameter id: 857 Numerical gradient of -0.008117 is not close to the backpropagation gradient of -0.811720!\n",
      "Parameter id: 858 Numerical gradient of -0.000247 is not close to the backpropagation gradient of -0.024656!\n",
      "Parameter id: 859 Numerical gradient of -0.017667 is not close to the backpropagation gradient of -1.766659!\n",
      "Parameter id: 860 Numerical gradient of -0.011707 is not close to the backpropagation gradient of -1.170688!\n",
      "Parameter id: 861 Numerical gradient of -0.040949 is not close to the backpropagation gradient of -4.094932!\n",
      "Parameter id: 862 Numerical gradient of 0.001275 is not close to the backpropagation gradient of 0.127522!\n",
      "Parameter id: 863 Numerical gradient of 0.034438 is not close to the backpropagation gradient of 3.443824!\n",
      "Parameter id: 864 Numerical gradient of 0.008265 is not close to the backpropagation gradient of 0.826549!\n",
      "Parameter id: 865 Numerical gradient of 0.018766 is not close to the backpropagation gradient of 1.876572!\n",
      "Parameter id: 866 Numerical gradient of 0.028038 is not close to the backpropagation gradient of 2.803750!\n",
      "Parameter id: 867 Numerical gradient of -0.007059 is not close to the backpropagation gradient of -0.705852!\n",
      "Parameter id: 868 Numerical gradient of 0.002918 is not close to the backpropagation gradient of 0.291805!\n",
      "Parameter id: 869 Numerical gradient of -0.030038 is not close to the backpropagation gradient of -3.003799!\n",
      "Parameter id: 870 Numerical gradient of -0.025480 is not close to the backpropagation gradient of -2.547962!\n",
      "Parameter id: 871 Numerical gradient of 0.005269 is not close to the backpropagation gradient of 0.526877!\n",
      "Parameter id: 872 Numerical gradient of 0.009378 is not close to the backpropagation gradient of 0.937815!\n",
      "Parameter id: 873 Numerical gradient of 0.001708 is not close to the backpropagation gradient of 0.170751!\n",
      "Parameter id: 874 Numerical gradient of 0.007042 is not close to the backpropagation gradient of 0.704208!\n",
      "Parameter id: 875 Numerical gradient of 0.001225 is not close to the backpropagation gradient of 0.122458!\n",
      "Parameter id: 876 Numerical gradient of -0.000632 is not close to the backpropagation gradient of -0.063174!\n",
      "Parameter id: 877 Numerical gradient of 0.007957 is not close to the backpropagation gradient of 0.795664!\n",
      "Parameter id: 878 Numerical gradient of 0.011013 is not close to the backpropagation gradient of 1.101273!\n",
      "Parameter id: 879 Numerical gradient of -0.003510 is not close to the backpropagation gradient of -0.350988!\n",
      "Parameter id: 880 Numerical gradient of 0.007912 is not close to the backpropagation gradient of 0.791208!\n",
      "Parameter id: 881 Numerical gradient of -0.006779 is not close to the backpropagation gradient of -0.677919!\n",
      "Parameter id: 882 Numerical gradient of -0.005681 is not close to the backpropagation gradient of -0.568072!\n",
      "Parameter id: 883 Numerical gradient of 0.010779 is not close to the backpropagation gradient of 1.077884!\n",
      "Parameter id: 884 Numerical gradient of -0.012722 is not close to the backpropagation gradient of -1.272248!\n",
      "Parameter id: 885 Numerical gradient of -0.003162 is not close to the backpropagation gradient of -0.316240!\n",
      "Parameter id: 886 Numerical gradient of 0.004345 is not close to the backpropagation gradient of 0.434538!\n",
      "Parameter id: 887 Numerical gradient of -0.000908 is not close to the backpropagation gradient of -0.090803!\n",
      "Parameter id: 888 Numerical gradient of 0.003878 is not close to the backpropagation gradient of 0.387828!\n",
      "Parameter id: 889 Numerical gradient of -0.013428 is not close to the backpropagation gradient of -1.342793!\n",
      "Parameter id: 890 Numerical gradient of -0.005842 is not close to the backpropagation gradient of -0.584190!\n",
      "Parameter id: 891 Numerical gradient of -0.006655 is not close to the backpropagation gradient of -0.665507!\n",
      "Parameter id: 892 Numerical gradient of 0.000371 is not close to the backpropagation gradient of 0.037055!\n",
      "Parameter id: 893 Numerical gradient of 0.021396 is not close to the backpropagation gradient of 2.139601!\n",
      "Parameter id: 894 Numerical gradient of 0.004117 is not close to the backpropagation gradient of 0.411702!\n",
      "Parameter id: 895 Numerical gradient of 0.005686 is not close to the backpropagation gradient of 0.568633!\n",
      "Parameter id: 896 Numerical gradient of 0.016066 is not close to the backpropagation gradient of 1.606590!\n",
      "Parameter id: 897 Numerical gradient of -0.004753 is not close to the backpropagation gradient of -0.475302!\n",
      "Parameter id: 898 Numerical gradient of 0.005477 is not close to the backpropagation gradient of 0.547692!\n",
      "Parameter id: 899 Numerical gradient of -0.011490 is not close to the backpropagation gradient of -1.148981!\n",
      "Parameter id: 900 Numerical gradient of 0.064189 is not close to the backpropagation gradient of 6.418850!\n",
      "Parameter id: 901 Numerical gradient of -0.016906 is not close to the backpropagation gradient of -1.690557!\n",
      "Parameter id: 902 Numerical gradient of -0.022108 is not close to the backpropagation gradient of -2.210846!\n",
      "Parameter id: 903 Numerical gradient of -0.008561 is not close to the backpropagation gradient of -0.856105!\n",
      "Parameter id: 904 Numerical gradient of -0.025211 is not close to the backpropagation gradient of -2.521101!\n",
      "Parameter id: 905 Numerical gradient of -0.000157 is not close to the backpropagation gradient of -0.015660!\n",
      "Parameter id: 906 Numerical gradient of 0.017069 is not close to the backpropagation gradient of 1.706878!\n",
      "Parameter id: 907 Numerical gradient of -0.018042 is not close to the backpropagation gradient of -1.804180!\n",
      "Parameter id: 908 Numerical gradient of -0.022341 is not close to the backpropagation gradient of -2.234141!\n",
      "Parameter id: 909 Numerical gradient of 0.014384 is not close to the backpropagation gradient of 1.438367!\n",
      "Parameter id: 910 Numerical gradient of -0.009021 is not close to the backpropagation gradient of -0.902135!\n",
      "Parameter id: 911 Numerical gradient of 0.003966 is not close to the backpropagation gradient of 0.396608!\n",
      "Parameter id: 912 Numerical gradient of 0.005564 is not close to the backpropagation gradient of 0.556386!\n",
      "Parameter id: 913 Numerical gradient of -0.018004 is not close to the backpropagation gradient of -1.800445!\n",
      "Parameter id: 914 Numerical gradient of 0.029270 is not close to the backpropagation gradient of 2.926978!\n",
      "Parameter id: 915 Numerical gradient of -0.021395 is not close to the backpropagation gradient of -2.139515!\n",
      "Parameter id: 916 Numerical gradient of -0.002180 is not close to the backpropagation gradient of -0.218035!\n",
      "Parameter id: 917 Numerical gradient of 0.008826 is not close to the backpropagation gradient of 0.882612!\n",
      "Parameter id: 918 Numerical gradient of 0.001460 is not close to the backpropagation gradient of 0.146004!\n",
      "Parameter id: 919 Numerical gradient of 0.018393 is not close to the backpropagation gradient of 1.839284!\n",
      "Parameter id: 920 Numerical gradient of 0.019816 is not close to the backpropagation gradient of 1.981571!\n",
      "Parameter id: 921 Numerical gradient of 0.056366 is not close to the backpropagation gradient of 5.636601!\n",
      "Parameter id: 922 Numerical gradient of 0.000336 is not close to the backpropagation gradient of 0.033565!\n",
      "Parameter id: 923 Numerical gradient of -0.055468 is not close to the backpropagation gradient of -5.546820!\n",
      "Parameter id: 924 Numerical gradient of -0.012229 is not close to the backpropagation gradient of -1.222888!\n",
      "Parameter id: 925 Numerical gradient of -0.021725 is not close to the backpropagation gradient of -2.172545!\n",
      "Parameter id: 926 Numerical gradient of -0.042514 is not close to the backpropagation gradient of -4.251407!\n",
      "Parameter id: 927 Numerical gradient of 0.013979 is not close to the backpropagation gradient of 1.397910!\n",
      "Parameter id: 928 Numerical gradient of -0.014746 is not close to the backpropagation gradient of -1.474634!\n",
      "Parameter id: 929 Numerical gradient of 0.047627 is not close to the backpropagation gradient of 4.762656!\n",
      "Parameter id: 930 Numerical gradient of 0.048753 is not close to the backpropagation gradient of 4.875308!\n",
      "Parameter id: 931 Numerical gradient of -0.011281 is not close to the backpropagation gradient of -1.128067!\n",
      "Parameter id: 932 Numerical gradient of -0.020118 is not close to the backpropagation gradient of -2.011784!\n",
      "Parameter id: 933 Numerical gradient of -0.005774 is not close to the backpropagation gradient of -0.577393!\n",
      "Parameter id: 934 Numerical gradient of -0.019596 is not close to the backpropagation gradient of -1.959563!\n",
      "Parameter id: 935 Numerical gradient of -0.001626 is not close to the backpropagation gradient of -0.162572!\n",
      "Parameter id: 936 Numerical gradient of 0.013928 is not close to the backpropagation gradient of 1.392795!\n",
      "Parameter id: 937 Numerical gradient of -0.016382 is not close to the backpropagation gradient of -1.638221!\n",
      "Parameter id: 938 Numerical gradient of -0.019995 is not close to the backpropagation gradient of -1.999451!\n",
      "Parameter id: 939 Numerical gradient of 0.010834 is not close to the backpropagation gradient of 1.083399!\n",
      "Parameter id: 940 Numerical gradient of -0.009840 is not close to the backpropagation gradient of -0.983968!\n",
      "Parameter id: 941 Numerical gradient of 0.005970 is not close to the backpropagation gradient of 0.596958!\n",
      "Parameter id: 942 Numerical gradient of 0.005255 is not close to the backpropagation gradient of 0.525475!\n",
      "Parameter id: 943 Numerical gradient of -0.013103 is not close to the backpropagation gradient of -1.310274!\n",
      "Parameter id: 944 Numerical gradient of 0.022595 is not close to the backpropagation gradient of 2.259492!\n",
      "Parameter id: 945 Numerical gradient of -0.013349 is not close to the backpropagation gradient of -1.334947!\n",
      "Parameter id: 946 Numerical gradient of -0.006990 is not close to the backpropagation gradient of -0.699045!\n",
      "Parameter id: 947 Numerical gradient of 0.007116 is not close to the backpropagation gradient of 0.711587!\n",
      "Parameter id: 948 Numerical gradient of -0.003706 is not close to the backpropagation gradient of -0.370596!\n",
      "Parameter id: 949 Numerical gradient of 0.023973 is not close to the backpropagation gradient of 2.397267!\n",
      "Parameter id: 950 Numerical gradient of 0.015806 is not close to the backpropagation gradient of 1.580649!\n",
      "Parameter id: 951 Numerical gradient of 0.037485 is not close to the backpropagation gradient of 3.748528!\n",
      "Parameter id: 952 Numerical gradient of -0.002780 is not close to the backpropagation gradient of -0.278013!\n",
      "Parameter id: 953 Numerical gradient of -0.047481 is not close to the backpropagation gradient of -4.748084!\n",
      "Parameter id: 954 Numerical gradient of -0.009956 is not close to the backpropagation gradient of -0.995612!\n",
      "Parameter id: 955 Numerical gradient of -0.017503 is not close to the backpropagation gradient of -1.750269!\n",
      "Parameter id: 956 Numerical gradient of -0.032259 is not close to the backpropagation gradient of -3.225873!\n",
      "Parameter id: 957 Numerical gradient of 0.011731 is not close to the backpropagation gradient of 1.173125!\n",
      "Parameter id: 958 Numerical gradient of -0.010527 is not close to the backpropagation gradient of -1.052680!\n",
      "Parameter id: 959 Numerical gradient of 0.038724 is not close to the backpropagation gradient of 3.872426!\n",
      "Parameter id: 960 Numerical gradient of 0.022964 is not close to the backpropagation gradient of 2.296391!\n",
      "Parameter id: 961 Numerical gradient of -0.005413 is not close to the backpropagation gradient of -0.541252!\n",
      "Parameter id: 962 Numerical gradient of -0.008321 is not close to the backpropagation gradient of -0.832088!\n",
      "Parameter id: 963 Numerical gradient of -0.004592 is not close to the backpropagation gradient of -0.459164!\n",
      "Parameter id: 964 Numerical gradient of -0.008758 is not close to the backpropagation gradient of -0.875837!\n",
      "Parameter id: 965 Numerical gradient of 0.001071 is not close to the backpropagation gradient of 0.107106!\n",
      "Parameter id: 966 Numerical gradient of 0.006544 is not close to the backpropagation gradient of 0.654353!\n",
      "Parameter id: 967 Numerical gradient of -0.007116 is not close to the backpropagation gradient of -0.711596!\n",
      "Parameter id: 968 Numerical gradient of -0.011059 is not close to the backpropagation gradient of -1.105915!\n",
      "Parameter id: 969 Numerical gradient of 0.004679 is not close to the backpropagation gradient of 0.467883!\n",
      "Parameter id: 970 Numerical gradient of -0.004609 is not close to the backpropagation gradient of -0.460947!\n",
      "Parameter id: 971 Numerical gradient of 0.001000 is not close to the backpropagation gradient of 0.099998!\n",
      "Parameter id: 972 Numerical gradient of -0.000102 is not close to the backpropagation gradient of -0.010151!\n",
      "Parameter id: 973 Numerical gradient of -0.005123 is not close to the backpropagation gradient of -0.512311!\n",
      "Parameter id: 974 Numerical gradient of 0.010688 is not close to the backpropagation gradient of 1.068753!\n",
      "Parameter id: 975 Numerical gradient of -0.008895 is not close to the backpropagation gradient of -0.889548!\n",
      "Parameter id: 976 Numerical gradient of -0.002699 is not close to the backpropagation gradient of -0.269860!\n",
      "Parameter id: 977 Numerical gradient of 0.005325 is not close to the backpropagation gradient of 0.532520!\n",
      "Parameter id: 978 Numerical gradient of -0.000307 is not close to the backpropagation gradient of -0.030696!\n",
      "Parameter id: 979 Numerical gradient of 0.011414 is not close to the backpropagation gradient of 1.141418!\n",
      "Parameter id: 980 Numerical gradient of 0.008850 is not close to the backpropagation gradient of 0.884953!\n",
      "Parameter id: 981 Numerical gradient of 0.023063 is not close to the backpropagation gradient of 2.306299!\n",
      "Parameter id: 982 Numerical gradient of -0.001606 is not close to the backpropagation gradient of -0.160574!\n",
      "Parameter id: 983 Numerical gradient of -0.022086 is not close to the backpropagation gradient of -2.208592!\n",
      "Parameter id: 984 Numerical gradient of -0.004976 is not close to the backpropagation gradient of -0.497578!\n",
      "Parameter id: 985 Numerical gradient of -0.010956 is not close to the backpropagation gradient of -1.095558!\n",
      "Parameter id: 986 Numerical gradient of -0.016508 is not close to the backpropagation gradient of -1.650758!\n",
      "Parameter id: 987 Numerical gradient of 0.005336 is not close to the backpropagation gradient of 0.533638!\n",
      "Parameter id: 988 Numerical gradient of -0.004348 is not close to the backpropagation gradient of -0.434779!\n",
      "Parameter id: 989 Numerical gradient of 0.020879 is not close to the backpropagation gradient of 2.087938!\n",
      "Parameter id: 990 Numerical gradient of -0.078584 is not close to the backpropagation gradient of -7.858366!\n",
      "Parameter id: 991 Numerical gradient of 0.007404 is not close to the backpropagation gradient of 0.740375!\n",
      "Parameter id: 992 Numerical gradient of 0.019852 is not close to the backpropagation gradient of 1.985166!\n",
      "Parameter id: 993 Numerical gradient of 0.013510 is not close to the backpropagation gradient of 1.351002!\n",
      "Parameter id: 994 Numerical gradient of 0.014211 is not close to the backpropagation gradient of 1.421077!\n",
      "Parameter id: 995 Numerical gradient of -0.001345 is not close to the backpropagation gradient of -0.134503!\n",
      "Parameter id: 996 Numerical gradient of -0.037196 is not close to the backpropagation gradient of -3.719596!\n",
      "Parameter id: 997 Numerical gradient of 0.021602 is not close to the backpropagation gradient of 2.160194!\n",
      "Parameter id: 998 Numerical gradient of 0.031459 is not close to the backpropagation gradient of 3.145926!\n",
      "Parameter id: 999 Numerical gradient of -0.034649 is not close to the backpropagation gradient of -3.464862!\n",
      "Parameter id: 1000 Numerical gradient of -0.001599 is not close to the backpropagation gradient of -0.159871!\n",
      "Parameter id: 1001 Numerical gradient of 0.001022 is not close to the backpropagation gradient of 0.102232!\n",
      "Parameter id: 1002 Numerical gradient of -0.004287 is not close to the backpropagation gradient of -0.428694!\n",
      "Parameter id: 1003 Numerical gradient of 0.019012 is not close to the backpropagation gradient of 1.901169!\n",
      "Parameter id: 1004 Numerical gradient of -0.018243 is not close to the backpropagation gradient of -1.824313!\n",
      "Parameter id: 1005 Numerical gradient of 0.008589 is not close to the backpropagation gradient of 0.858919!\n",
      "Parameter id: 1006 Numerical gradient of 0.015694 is not close to the backpropagation gradient of 1.569354!\n",
      "Parameter id: 1007 Numerical gradient of 0.003515 is not close to the backpropagation gradient of 0.351481!\n",
      "Parameter id: 1008 Numerical gradient of 0.010047 is not close to the backpropagation gradient of 1.004701!\n",
      "Parameter id: 1009 Numerical gradient of -0.016948 is not close to the backpropagation gradient of -1.694820!\n",
      "Parameter id: 1010 Numerical gradient of -0.042080 is not close to the backpropagation gradient of -4.208025!\n",
      "Parameter id: 1011 Numerical gradient of -0.036379 is not close to the backpropagation gradient of -3.637856!\n",
      "Parameter id: 1012 Numerical gradient of 0.017549 is not close to the backpropagation gradient of 1.754891!\n",
      "Parameter id: 1013 Numerical gradient of 0.065874 is not close to the backpropagation gradient of 6.587373!\n",
      "Parameter id: 1014 Numerical gradient of 0.003906 is not close to the backpropagation gradient of 0.390613!\n",
      "Parameter id: 1015 Numerical gradient of 0.009937 is not close to the backpropagation gradient of 0.993672!\n",
      "Parameter id: 1016 Numerical gradient of 0.026782 is not close to the backpropagation gradient of 2.678186!\n",
      "Parameter id: 1017 Numerical gradient of -0.011678 is not close to the backpropagation gradient of -1.167792!\n",
      "Parameter id: 1018 Numerical gradient of 0.038659 is not close to the backpropagation gradient of 3.865865!\n",
      "Parameter id: 1019 Numerical gradient of -0.056482 is not close to the backpropagation gradient of -5.648161!\n",
      "Parameter id: 1020 Numerical gradient of -0.034165 is not close to the backpropagation gradient of -3.416546!\n",
      "Parameter id: 1021 Numerical gradient of -0.033169 is not close to the backpropagation gradient of -3.316865!\n",
      "Parameter id: 1022 Numerical gradient of -0.007887 is not close to the backpropagation gradient of -0.788673!\n",
      "Parameter id: 1023 Numerical gradient of 0.001661 is not close to the backpropagation gradient of 0.166086!\n",
      "Parameter id: 1024 Numerical gradient of 0.001426 is not close to the backpropagation gradient of 0.142592!\n",
      "Parameter id: 1025 Numerical gradient of 0.032437 is not close to the backpropagation gradient of 3.243686!\n",
      "Parameter id: 1026 Numerical gradient of 0.012005 is not close to the backpropagation gradient of 1.200545!\n",
      "Parameter id: 1027 Numerical gradient of 0.013731 is not close to the backpropagation gradient of 1.373136!\n",
      "Parameter id: 1028 Numerical gradient of 0.013960 is not close to the backpropagation gradient of 1.396038!\n",
      "Parameter id: 1029 Numerical gradient of 0.078593 is not close to the backpropagation gradient of 7.859328!\n",
      "Parameter id: 1030 Numerical gradient of -0.026341 is not close to the backpropagation gradient of -2.634123!\n",
      "Parameter id: 1031 Numerical gradient of -0.042924 is not close to the backpropagation gradient of -4.292406!\n",
      "Parameter id: 1032 Numerical gradient of -0.052507 is not close to the backpropagation gradient of -5.250744!\n",
      "Parameter id: 1033 Numerical gradient of 0.024485 is not close to the backpropagation gradient of 2.448458!\n",
      "Parameter id: 1034 Numerical gradient of 0.009825 is not close to the backpropagation gradient of 0.982461!\n",
      "Parameter id: 1035 Numerical gradient of 0.052687 is not close to the backpropagation gradient of 5.268713!\n",
      "Parameter id: 1036 Numerical gradient of -0.029890 is not close to the backpropagation gradient of -2.989016!\n",
      "Parameter id: 1037 Numerical gradient of -0.013927 is not close to the backpropagation gradient of -1.392670!\n",
      "Parameter id: 1038 Numerical gradient of 0.084286 is not close to the backpropagation gradient of 8.428589!\n",
      "Parameter id: 1039 Numerical gradient of -0.022000 is not close to the backpropagation gradient of -2.199988!\n",
      "Parameter id: 1040 Numerical gradient of -0.044512 is not close to the backpropagation gradient of -4.451174!\n",
      "Parameter id: 1041 Numerical gradient of -0.057135 is not close to the backpropagation gradient of -5.713451!\n",
      "Parameter id: 1042 Numerical gradient of 0.023095 is not close to the backpropagation gradient of 2.309530!\n",
      "Parameter id: 1043 Numerical gradient of 0.012344 is not close to the backpropagation gradient of 1.234352!\n",
      "Parameter id: 1044 Numerical gradient of 0.054447 is not close to the backpropagation gradient of 5.444709!\n",
      "Parameter id: 1045 Numerical gradient of -0.035508 is not close to the backpropagation gradient of -3.550823!\n",
      "Parameter id: 1046 Numerical gradient of -0.015017 is not close to the backpropagation gradient of -1.501743!\n",
      "Parameter id: 1047 Numerical gradient of 0.058256 is not close to the backpropagation gradient of 5.825612!\n",
      "Parameter id: 1048 Numerical gradient of 0.017069 is not close to the backpropagation gradient of 1.706938!\n",
      "Parameter id: 1049 Numerical gradient of -0.008412 is not close to the backpropagation gradient of -0.841164!\n",
      "Parameter id: 1050 Numerical gradient of -0.022861 is not close to the backpropagation gradient of -2.286124!\n",
      "Parameter id: 1051 Numerical gradient of -0.005205 is not close to the backpropagation gradient of -0.520501!\n",
      "Parameter id: 1052 Numerical gradient of -0.035796 is not close to the backpropagation gradient of -3.579626!\n",
      "Parameter id: 1053 Numerical gradient of 0.009975 is not close to the backpropagation gradient of 0.997452!\n",
      "Parameter id: 1054 Numerical gradient of -0.008536 is not close to the backpropagation gradient of -0.853646!\n",
      "Parameter id: 1055 Numerical gradient of -0.004489 is not close to the backpropagation gradient of -0.448939!\n",
      "Parameter id: 1056 Numerical gradient of 0.039201 is not close to the backpropagation gradient of 3.920079!\n",
      "Parameter id: 1057 Numerical gradient of -0.052322 is not close to the backpropagation gradient of -5.232231!\n",
      "Parameter id: 1058 Numerical gradient of -0.036254 is not close to the backpropagation gradient of -3.625396!\n",
      "Parameter id: 1059 Numerical gradient of -0.041626 is not close to the backpropagation gradient of -4.162571!\n",
      "Parameter id: 1060 Numerical gradient of 0.030002 is not close to the backpropagation gradient of 3.000186!\n",
      "Parameter id: 1061 Numerical gradient of 0.037824 is not close to the backpropagation gradient of 3.782381!\n",
      "Parameter id: 1062 Numerical gradient of 0.061810 is not close to the backpropagation gradient of 6.180976!\n",
      "Parameter id: 1063 Numerical gradient of -0.027515 is not close to the backpropagation gradient of -2.751503!\n",
      "Parameter id: 1064 Numerical gradient of -0.011119 is not close to the backpropagation gradient of -1.111921!\n",
      "Parameter id: 1065 Numerical gradient of 0.036128 is not close to the backpropagation gradient of 3.612792!\n",
      "Parameter id: 1066 Numerical gradient of -0.048874 is not close to the backpropagation gradient of -4.887434!\n",
      "Parameter id: 1067 Numerical gradient of -0.041045 is not close to the backpropagation gradient of -4.104513!\n",
      "Parameter id: 1068 Numerical gradient of -0.041703 is not close to the backpropagation gradient of -4.170265!\n",
      "Parameter id: 1069 Numerical gradient of 0.033884 is not close to the backpropagation gradient of 3.388423!\n",
      "Parameter id: 1070 Numerical gradient of 0.041819 is not close to the backpropagation gradient of 4.181877!\n",
      "Parameter id: 1071 Numerical gradient of 0.055168 is not close to the backpropagation gradient of 5.516839!\n",
      "Parameter id: 1072 Numerical gradient of -0.025133 is not close to the backpropagation gradient of -2.513292!\n",
      "Parameter id: 1073 Numerical gradient of -0.010244 is not close to the backpropagation gradient of -1.024427!\n",
      "Parameter id: 1074 Numerical gradient of -0.001939 is not close to the backpropagation gradient of -0.193940!\n",
      "Parameter id: 1075 Numerical gradient of 0.043186 is not close to the backpropagation gradient of 4.318598!\n",
      "Parameter id: 1076 Numerical gradient of 0.016675 is not close to the backpropagation gradient of 1.667475!\n",
      "Parameter id: 1077 Numerical gradient of 0.013350 is not close to the backpropagation gradient of 1.334967!\n",
      "Parameter id: 1078 Numerical gradient of -0.022447 is not close to the backpropagation gradient of -2.244659!\n",
      "Parameter id: 1079 Numerical gradient of -0.044306 is not close to the backpropagation gradient of -4.430561!\n",
      "Parameter id: 1080 Numerical gradient of -0.032898 is not close to the backpropagation gradient of -3.289754!\n",
      "Parameter id: 1081 Numerical gradient of 0.018818 is not close to the backpropagation gradient of 1.881755!\n",
      "Parameter id: 1082 Numerical gradient of 0.009561 is not close to the backpropagation gradient of 0.956120!\n",
      "Parameter id: 1083 Numerical gradient of 0.023231 is not close to the backpropagation gradient of 2.323135!\n",
      "Parameter id: 1084 Numerical gradient of -0.044178 is not close to the backpropagation gradient of -4.417756!\n",
      "Parameter id: 1085 Numerical gradient of -0.037720 is not close to the backpropagation gradient of -3.771954!\n",
      "Parameter id: 1086 Numerical gradient of -0.028188 is not close to the backpropagation gradient of -2.818824!\n",
      "Parameter id: 1087 Numerical gradient of 0.030172 is not close to the backpropagation gradient of 3.017151!\n",
      "Parameter id: 1088 Numerical gradient of 0.049484 is not close to the backpropagation gradient of 4.948443!\n",
      "Parameter id: 1089 Numerical gradient of 0.049342 is not close to the backpropagation gradient of 4.934232!\n",
      "Parameter id: 1090 Numerical gradient of -0.029794 is not close to the backpropagation gradient of -2.979375!\n",
      "Parameter id: 1091 Numerical gradient of -0.012351 is not close to the backpropagation gradient of -1.235053!\n",
      "Parameter id: 1092 Numerical gradient of 0.018713 is not close to the backpropagation gradient of 1.871281!\n",
      "Parameter id: 1093 Numerical gradient of 0.000320 is not close to the backpropagation gradient of 0.031988!\n",
      "Parameter id: 1094 Numerical gradient of 0.005805 is not close to the backpropagation gradient of 0.580477!\n",
      "Parameter id: 1095 Numerical gradient of -0.005605 is not close to the backpropagation gradient of -0.560490!\n",
      "Parameter id: 1096 Numerical gradient of -0.012938 is not close to the backpropagation gradient of -1.293800!\n",
      "Parameter id: 1097 Numerical gradient of -0.030376 is not close to the backpropagation gradient of -3.037623!\n",
      "Parameter id: 1098 Numerical gradient of 0.000117 is not close to the backpropagation gradient of 0.011738!\n",
      "Parameter id: 1099 Numerical gradient of 0.015865 is not close to the backpropagation gradient of 1.586507!\n",
      "Parameter id: 1100 Numerical gradient of 0.008099 is not close to the backpropagation gradient of 0.809922!\n",
      "Parameter id: 1101 Numerical gradient of 0.012145 is not close to the backpropagation gradient of 1.214472!\n",
      "Parameter id: 1102 Numerical gradient of -0.025499 is not close to the backpropagation gradient of -2.549906!\n",
      "Parameter id: 1103 Numerical gradient of -0.011457 is not close to the backpropagation gradient of -1.145689!\n",
      "Parameter id: 1104 Numerical gradient of -0.015324 is not close to the backpropagation gradient of -1.532433!\n",
      "Parameter id: 1105 Numerical gradient of 0.005805 is not close to the backpropagation gradient of 0.580506!\n",
      "Parameter id: 1106 Numerical gradient of 0.012415 is not close to the backpropagation gradient of 1.241455!\n",
      "Parameter id: 1107 Numerical gradient of 0.021620 is not close to the backpropagation gradient of 2.162021!\n",
      "Parameter id: 1108 Numerical gradient of -0.001014 is not close to the backpropagation gradient of -0.101445!\n",
      "Parameter id: 1109 Numerical gradient of 0.001310 is not close to the backpropagation gradient of 0.131019!\n",
      "Parameter id: 1110 Numerical gradient of 0.018821 is not close to the backpropagation gradient of 1.882099!\n",
      "Parameter id: 1111 Numerical gradient of 0.029934 is not close to the backpropagation gradient of 2.993409!\n",
      "Parameter id: 1112 Numerical gradient of 0.019993 is not close to the backpropagation gradient of 1.999286!\n",
      "Parameter id: 1113 Numerical gradient of 0.003544 is not close to the backpropagation gradient of 0.354430!\n",
      "Parameter id: 1114 Numerical gradient of -0.021720 is not close to the backpropagation gradient of -2.172031!\n",
      "Parameter id: 1115 Numerical gradient of -0.051426 is not close to the backpropagation gradient of -5.142577!\n",
      "Parameter id: 1116 Numerical gradient of -0.018455 is not close to the backpropagation gradient of -1.845471!\n",
      "Parameter id: 1117 Numerical gradient of 0.014246 is not close to the backpropagation gradient of 1.424586!\n",
      "Parameter id: 1118 Numerical gradient of 0.005063 is not close to the backpropagation gradient of 0.506269!\n",
      "Parameter id: 1119 Numerical gradient of 0.005941 is not close to the backpropagation gradient of 0.594123!\n",
      "Parameter id: 1120 Numerical gradient of -0.023423 is not close to the backpropagation gradient of -2.342274!\n",
      "Parameter id: 1121 Numerical gradient of -0.024519 is not close to the backpropagation gradient of -2.451870!\n",
      "Parameter id: 1122 Numerical gradient of -0.014981 is not close to the backpropagation gradient of -1.498113!\n",
      "Parameter id: 1123 Numerical gradient of 0.018497 is not close to the backpropagation gradient of 1.849716!\n",
      "Parameter id: 1124 Numerical gradient of 0.048481 is not close to the backpropagation gradient of 4.848068!\n",
      "Parameter id: 1125 Numerical gradient of 0.029624 is not close to the backpropagation gradient of 2.962434!\n",
      "Parameter id: 1126 Numerical gradient of -0.027809 is not close to the backpropagation gradient of -2.780918!\n",
      "Parameter id: 1127 Numerical gradient of -0.011812 is not close to the backpropagation gradient of -1.181166!\n",
      "Parameter id: 1128 Numerical gradient of 0.039712 is not close to the backpropagation gradient of 3.971224!\n",
      "Parameter id: 1129 Numerical gradient of -0.044204 is not close to the backpropagation gradient of -4.420424!\n",
      "Parameter id: 1130 Numerical gradient of -0.039487 is not close to the backpropagation gradient of -3.948663!\n",
      "Parameter id: 1131 Numerical gradient of -0.041586 is not close to the backpropagation gradient of -4.158630!\n",
      "Parameter id: 1132 Numerical gradient of 0.029435 is not close to the backpropagation gradient of 2.943467!\n",
      "Parameter id: 1133 Numerical gradient of 0.039254 is not close to the backpropagation gradient of 3.925423!\n",
      "Parameter id: 1134 Numerical gradient of 0.056190 is not close to the backpropagation gradient of 5.619023!\n",
      "Parameter id: 1135 Numerical gradient of -0.027640 is not close to the backpropagation gradient of -2.763977!\n",
      "Parameter id: 1136 Numerical gradient of -0.011674 is not close to the backpropagation gradient of -1.167443!\n",
      "Parameter id: 1137 Numerical gradient of -0.016656 is not close to the backpropagation gradient of -1.665632!\n",
      "Parameter id: 1138 Numerical gradient of 0.028544 is not close to the backpropagation gradient of 2.854376!\n",
      "Parameter id: 1139 Numerical gradient of 0.016279 is not close to the backpropagation gradient of 1.627881!\n",
      "Parameter id: 1140 Numerical gradient of 0.019443 is not close to the backpropagation gradient of 1.944315!\n",
      "Parameter id: 1141 Numerical gradient of -0.015620 is not close to the backpropagation gradient of -1.561969!\n",
      "Parameter id: 1142 Numerical gradient of -0.023743 is not close to the backpropagation gradient of -2.374319!\n",
      "Parameter id: 1143 Numerical gradient of -0.029389 is not close to the backpropagation gradient of -2.938866!\n",
      "Parameter id: 1144 Numerical gradient of 0.014154 is not close to the backpropagation gradient of 1.415443!\n",
      "Parameter id: 1145 Numerical gradient of 0.006988 is not close to the backpropagation gradient of 0.698772!\n",
      "Parameter id: 1146 Numerical gradient of 0.016821 is not close to the backpropagation gradient of 1.682061!\n",
      "Parameter id: 1147 Numerical gradient of -0.039123 is not close to the backpropagation gradient of -3.912279!\n",
      "Parameter id: 1148 Numerical gradient of -0.031488 is not close to the backpropagation gradient of -3.148765!\n",
      "Parameter id: 1149 Numerical gradient of -0.026306 is not close to the backpropagation gradient of -2.630614!\n",
      "Parameter id: 1150 Numerical gradient of 0.026633 is not close to the backpropagation gradient of 2.663257!\n",
      "Parameter id: 1151 Numerical gradient of 0.048022 is not close to the backpropagation gradient of 4.802237!\n",
      "Parameter id: 1152 Numerical gradient of 0.041217 is not close to the backpropagation gradient of 4.121664!\n",
      "Parameter id: 1153 Numerical gradient of -0.025924 is not close to the backpropagation gradient of -2.592407!\n",
      "Parameter id: 1154 Numerical gradient of -0.009852 is not close to the backpropagation gradient of -0.985154!\n",
      "Parameter id: 1155 Numerical gradient of -0.038452 is not close to the backpropagation gradient of -3.845233!\n",
      "Parameter id: 1156 Numerical gradient of 0.013616 is not close to the backpropagation gradient of 1.361609!\n",
      "Parameter id: 1157 Numerical gradient of 0.024732 is not close to the backpropagation gradient of 2.473185!\n",
      "Parameter id: 1158 Numerical gradient of 0.028181 is not close to the backpropagation gradient of 2.818144!\n",
      "Parameter id: 1159 Numerical gradient of -0.022906 is not close to the backpropagation gradient of -2.290590!\n",
      "Parameter id: 1160 Numerical gradient of -0.024897 is not close to the backpropagation gradient of -2.489667!\n",
      "Parameter id: 1161 Numerical gradient of -0.032697 is not close to the backpropagation gradient of -3.269661!\n",
      "Parameter id: 1162 Numerical gradient of 0.033079 is not close to the backpropagation gradient of 3.307902!\n",
      "Parameter id: 1163 Numerical gradient of 0.019343 is not close to the backpropagation gradient of 1.934312!\n",
      "Parameter id: 1164 Numerical gradient of 0.041325 is not close to the backpropagation gradient of 4.132523!\n",
      "Parameter id: 1165 Numerical gradient of 0.015934 is not close to the backpropagation gradient of 1.593439!\n",
      "Parameter id: 1166 Numerical gradient of 0.013876 is not close to the backpropagation gradient of 1.387552!\n",
      "Parameter id: 1167 Numerical gradient of -0.012062 is not close to the backpropagation gradient of -1.206166!\n",
      "Parameter id: 1168 Numerical gradient of -0.012940 is not close to the backpropagation gradient of -1.293985!\n",
      "Parameter id: 1169 Numerical gradient of -0.031448 is not close to the backpropagation gradient of -3.144832!\n",
      "Parameter id: 1170 Numerical gradient of 0.001022 is not close to the backpropagation gradient of 0.102247!\n",
      "Parameter id: 1171 Numerical gradient of -0.009689 is not close to the backpropagation gradient of -0.968895!\n",
      "Parameter id: 1172 Numerical gradient of -0.006019 is not close to the backpropagation gradient of -0.601882!\n",
      "Parameter id: 1173 Numerical gradient of 0.041362 is not close to the backpropagation gradient of 4.136201!\n",
      "Parameter id: 1174 Numerical gradient of -0.040365 is not close to the backpropagation gradient of -4.036463!\n",
      "Parameter id: 1175 Numerical gradient of -0.043253 is not close to the backpropagation gradient of -4.325252!\n",
      "Parameter id: 1176 Numerical gradient of -0.041796 is not close to the backpropagation gradient of -4.179609!\n",
      "Parameter id: 1177 Numerical gradient of 0.029943 is not close to the backpropagation gradient of 2.994251!\n",
      "Parameter id: 1178 Numerical gradient of 0.041242 is not close to the backpropagation gradient of 4.124216!\n",
      "Parameter id: 1179 Numerical gradient of 0.057336 is not close to the backpropagation gradient of 5.733579!\n",
      "Parameter id: 1180 Numerical gradient of -0.031975 is not close to the backpropagation gradient of -3.197497!\n",
      "Parameter id: 1181 Numerical gradient of -0.012494 is not close to the backpropagation gradient of -1.249424!\n",
      "Parameter id: 1182 Numerical gradient of -0.015452 is not close to the backpropagation gradient of -1.545198!\n",
      "Parameter id: 1183 Numerical gradient of 0.015705 is not close to the backpropagation gradient of 1.570532!\n",
      "Parameter id: 1184 Numerical gradient of 0.018864 is not close to the backpropagation gradient of 1.886421!\n",
      "Parameter id: 1185 Numerical gradient of 0.017266 is not close to the backpropagation gradient of 1.726623!\n",
      "Parameter id: 1186 Numerical gradient of -0.013530 is not close to the backpropagation gradient of -1.353021!\n",
      "Parameter id: 1187 Numerical gradient of -0.044156 is not close to the backpropagation gradient of -4.415602!\n",
      "Parameter id: 1188 Numerical gradient of -0.033731 is not close to the backpropagation gradient of -3.373055!\n",
      "Parameter id: 1189 Numerical gradient of 0.035592 is not close to the backpropagation gradient of 3.559178!\n",
      "Parameter id: 1190 Numerical gradient of 0.019441 is not close to the backpropagation gradient of 1.944123!\n",
      "Parameter id: 1191 Numerical gradient of 0.018277 is not close to the backpropagation gradient of 1.827741!\n",
      "Parameter id: 1192 Numerical gradient of 0.029963 is not close to the backpropagation gradient of 2.996255!\n",
      "Parameter id: 1193 Numerical gradient of 0.016174 is not close to the backpropagation gradient of 1.617396!\n",
      "Parameter id: 1194 Numerical gradient of -0.000139 is not close to the backpropagation gradient of -0.013910!\n",
      "Parameter id: 1195 Numerical gradient of -0.021698 is not close to the backpropagation gradient of -2.169753!\n",
      "Parameter id: 1196 Numerical gradient of -0.043439 is not close to the backpropagation gradient of -4.343921!\n",
      "Parameter id: 1197 Numerical gradient of -0.018579 is not close to the backpropagation gradient of -1.857851!\n",
      "Parameter id: 1198 Numerical gradient of 0.011868 is not close to the backpropagation gradient of 1.186840!\n",
      "Parameter id: 1199 Numerical gradient of 0.007572 is not close to the backpropagation gradient of 0.757203!\n",
      "Parameter id: 1200 Numerical gradient of -0.060474 is not close to the backpropagation gradient of -6.047428!\n",
      "Parameter id: 1201 Numerical gradient of 0.023274 is not close to the backpropagation gradient of 2.327408!\n",
      "Parameter id: 1202 Numerical gradient of 0.035922 is not close to the backpropagation gradient of 3.592177!\n",
      "Parameter id: 1203 Numerical gradient of 0.044365 is not close to the backpropagation gradient of 4.436486!\n",
      "Parameter id: 1204 Numerical gradient of -0.022673 is not close to the backpropagation gradient of -2.267318!\n",
      "Parameter id: 1205 Numerical gradient of -0.017838 is not close to the backpropagation gradient of -1.783839!\n",
      "Parameter id: 1206 Numerical gradient of -0.047288 is not close to the backpropagation gradient of -4.728808!\n",
      "Parameter id: 1207 Numerical gradient of 0.030157 is not close to the backpropagation gradient of 3.015710!\n",
      "Parameter id: 1208 Numerical gradient of 0.014556 is not close to the backpropagation gradient of 1.455612!\n",
      "Parameter id: 1209 Numerical gradient of -0.049399 is not close to the backpropagation gradient of -4.939890!\n",
      "Parameter id: 1210 Numerical gradient of 0.005520 is not close to the backpropagation gradient of 0.551964!\n",
      "Parameter id: 1211 Numerical gradient of 0.010368 is not close to the backpropagation gradient of 1.036756!\n",
      "Parameter id: 1212 Numerical gradient of 0.026321 is not close to the backpropagation gradient of 2.632126!\n",
      "Parameter id: 1213 Numerical gradient of -0.004601 is not close to the backpropagation gradient of -0.460068!\n",
      "Parameter id: 1214 Numerical gradient of 0.008916 is not close to the backpropagation gradient of 0.891568!\n",
      "Parameter id: 1215 Numerical gradient of -0.022048 is not close to the backpropagation gradient of -2.204850!\n",
      "Parameter id: 1216 Numerical gradient of 0.014928 is not close to the backpropagation gradient of 1.492764!\n",
      "Parameter id: 1217 Numerical gradient of 0.009996 is not close to the backpropagation gradient of 0.999630!\n",
      "Parameter id: 1218 Numerical gradient of 0.062455 is not close to the backpropagation gradient of 6.245540!\n",
      "Parameter id: 1219 Numerical gradient of -0.036518 is not close to the backpropagation gradient of -3.651764!\n",
      "Parameter id: 1220 Numerical gradient of -0.048065 is not close to the backpropagation gradient of -4.806518!\n",
      "Parameter id: 1221 Numerical gradient of -0.053509 is not close to the backpropagation gradient of -5.350925!\n",
      "Parameter id: 1222 Numerical gradient of 0.032304 is not close to the backpropagation gradient of 3.230404!\n",
      "Parameter id: 1223 Numerical gradient of 0.030011 is not close to the backpropagation gradient of 3.001064!\n",
      "Parameter id: 1224 Numerical gradient of 0.061321 is not close to the backpropagation gradient of 6.132075!\n",
      "Parameter id: 1225 Numerical gradient of -0.033633 is not close to the backpropagation gradient of -3.363266!\n",
      "Parameter id: 1226 Numerical gradient of -0.014366 is not close to the backpropagation gradient of -1.436609!\n",
      "Parameter id: 1227 Numerical gradient of 0.028819 is not close to the backpropagation gradient of 2.881921!\n",
      "Parameter id: 1228 Numerical gradient of -0.038263 is not close to the backpropagation gradient of -3.826253!\n",
      "Parameter id: 1229 Numerical gradient of -0.034769 is not close to the backpropagation gradient of -3.476918!\n",
      "Parameter id: 1230 Numerical gradient of -0.034172 is not close to the backpropagation gradient of -3.417197!\n",
      "Parameter id: 1231 Numerical gradient of 0.023267 is not close to the backpropagation gradient of 2.326721!\n",
      "Parameter id: 1232 Numerical gradient of 0.048195 is not close to the backpropagation gradient of 4.819505!\n",
      "Parameter id: 1233 Numerical gradient of 0.051504 is not close to the backpropagation gradient of 5.150410!\n",
      "Parameter id: 1234 Numerical gradient of -0.031700 is not close to the backpropagation gradient of -3.169969!\n",
      "Parameter id: 1235 Numerical gradient of -0.012882 is not close to the backpropagation gradient of -1.288221!\n",
      "Parameter id: 1236 Numerical gradient of -0.025963 is not close to the backpropagation gradient of -2.596340!\n",
      "Parameter id: 1237 Numerical gradient of 0.035316 is not close to the backpropagation gradient of 3.531606!\n",
      "Parameter id: 1238 Numerical gradient of 0.022153 is not close to the backpropagation gradient of 2.215307!\n",
      "Parameter id: 1239 Numerical gradient of 0.029959 is not close to the backpropagation gradient of 2.995941!\n",
      "Parameter id: 1240 Numerical gradient of -0.020932 is not close to the backpropagation gradient of -2.093197!\n",
      "Parameter id: 1241 Numerical gradient of -0.044056 is not close to the backpropagation gradient of -4.405646!\n",
      "Parameter id: 1242 Numerical gradient of -0.045403 is not close to the backpropagation gradient of -4.540341!\n",
      "Parameter id: 1243 Numerical gradient of 0.032720 is not close to the backpropagation gradient of 3.272024!\n",
      "Parameter id: 1244 Numerical gradient of 0.016206 is not close to the backpropagation gradient of 1.620645!\n",
      "Parameter id: 1245 Numerical gradient of 0.021786 is not close to the backpropagation gradient of 2.178553!\n",
      "Parameter id: 1246 Numerical gradient of -0.024391 is not close to the backpropagation gradient of -2.439064!\n",
      "Parameter id: 1247 Numerical gradient of -0.023342 is not close to the backpropagation gradient of -2.334173!\n",
      "Parameter id: 1248 Numerical gradient of -0.023116 is not close to the backpropagation gradient of -2.311642!\n",
      "Parameter id: 1249 Numerical gradient of 0.017093 is not close to the backpropagation gradient of 1.709254!\n",
      "Parameter id: 1250 Numerical gradient of 0.040964 is not close to the backpropagation gradient of 4.096388!\n",
      "Parameter id: 1251 Numerical gradient of 0.037041 is not close to the backpropagation gradient of 3.704068!\n",
      "Parameter id: 1252 Numerical gradient of -0.031129 is not close to the backpropagation gradient of -3.112915!\n",
      "Parameter id: 1253 Numerical gradient of -0.014905 is not close to the backpropagation gradient of -1.490470!\n",
      "Parameter id: 1254 Numerical gradient of 0.033164 is not close to the backpropagation gradient of 3.316411!\n",
      "Parameter id: 1255 Numerical gradient of -0.035089 is not close to the backpropagation gradient of -3.508925!\n",
      "Parameter id: 1256 Numerical gradient of -0.005490 is not close to the backpropagation gradient of -0.548979!\n",
      "Parameter id: 1257 Numerical gradient of -0.029453 is not close to the backpropagation gradient of -2.945284!\n",
      "Parameter id: 1258 Numerical gradient of -0.002483 is not close to the backpropagation gradient of -0.248349!\n",
      "Parameter id: 1259 Numerical gradient of 0.015520 is not close to the backpropagation gradient of 1.551977!\n",
      "Parameter id: 1260 Numerical gradient of 0.035662 is not close to the backpropagation gradient of 3.566248!\n",
      "Parameter id: 1261 Numerical gradient of -0.012978 is not close to the backpropagation gradient of -1.297804!\n",
      "Parameter id: 1262 Numerical gradient of 0.001147 is not close to the backpropagation gradient of 0.114705!\n",
      "Parameter id: 1263 Numerical gradient of -0.048057 is not close to the backpropagation gradient of -4.805663!\n",
      "Parameter id: 1264 Numerical gradient of 0.047045 is not close to the backpropagation gradient of 4.704536!\n",
      "Parameter id: 1265 Numerical gradient of 0.046055 is not close to the backpropagation gradient of 4.605527!\n",
      "Parameter id: 1266 Numerical gradient of 0.050591 is not close to the backpropagation gradient of 5.059065!\n",
      "Parameter id: 1267 Numerical gradient of -0.035058 is not close to the backpropagation gradient of -3.505822!\n",
      "Parameter id: 1268 Numerical gradient of -0.041576 is not close to the backpropagation gradient of -4.157617!\n",
      "Parameter id: 1269 Numerical gradient of -0.065486 is not close to the backpropagation gradient of -6.548595!\n",
      "Parameter id: 1270 Numerical gradient of 0.033323 is not close to the backpropagation gradient of 3.332278!\n",
      "Parameter id: 1271 Numerical gradient of 0.013163 is not close to the backpropagation gradient of 1.316290!\n",
      "Parameter id: 1272 Numerical gradient of -0.027968 is not close to the backpropagation gradient of -2.796807!\n",
      "Parameter id: 1273 Numerical gradient of 0.056090 is not close to the backpropagation gradient of 5.609022!\n",
      "Parameter id: 1274 Numerical gradient of 0.034696 is not close to the backpropagation gradient of 3.469635!\n",
      "Parameter id: 1275 Numerical gradient of 0.036529 is not close to the backpropagation gradient of 3.652944!\n",
      "Parameter id: 1276 Numerical gradient of -0.029948 is not close to the backpropagation gradient of -2.994817!\n",
      "Parameter id: 1277 Numerical gradient of -0.042676 is not close to the backpropagation gradient of -4.267564!\n",
      "Parameter id: 1278 Numerical gradient of -0.056149 is not close to the backpropagation gradient of -5.614928!\n",
      "Parameter id: 1279 Numerical gradient of 0.021706 is not close to the backpropagation gradient of 2.170621!\n",
      "Parameter id: 1280 Numerical gradient of 0.007719 is not close to the backpropagation gradient of 0.771893!\n",
      "Parameter id: 1281 Numerical gradient of -0.009682 is not close to the backpropagation gradient of -0.968188!\n",
      "Parameter id: 1282 Numerical gradient of 0.021847 is not close to the backpropagation gradient of 2.184699!\n",
      "Parameter id: 1283 Numerical gradient of 0.020403 is not close to the backpropagation gradient of 2.040330!\n",
      "Parameter id: 1284 Numerical gradient of 0.018268 is not close to the backpropagation gradient of 1.826849!\n",
      "Parameter id: 1285 Numerical gradient of -0.011851 is not close to the backpropagation gradient of -1.185122!\n",
      "Parameter id: 1286 Numerical gradient of -0.026491 is not close to the backpropagation gradient of -2.649130!\n",
      "Parameter id: 1287 Numerical gradient of -0.023455 is not close to the backpropagation gradient of -2.345546!\n",
      "Parameter id: 1288 Numerical gradient of 0.009139 is not close to the backpropagation gradient of 0.913936!\n",
      "Parameter id: 1289 Numerical gradient of 0.001822 is not close to the backpropagation gradient of 0.182171!\n",
      "Parameter id: 1290 Numerical gradient of 0.041044 is not close to the backpropagation gradient of 4.104440!\n",
      "Parameter id: 1291 Numerical gradient of -0.048657 is not close to the backpropagation gradient of -4.865693!\n",
      "Parameter id: 1292 Numerical gradient of -0.056955 is not close to the backpropagation gradient of -5.695455!\n",
      "Parameter id: 1293 Numerical gradient of -0.059562 is not close to the backpropagation gradient of -5.956219!\n",
      "Parameter id: 1294 Numerical gradient of 0.041967 is not close to the backpropagation gradient of 4.196716!\n",
      "Parameter id: 1295 Numerical gradient of 0.041413 is not close to the backpropagation gradient of 4.141348!\n",
      "Parameter id: 1296 Numerical gradient of 0.080904 is not close to the backpropagation gradient of 8.090388!\n",
      "Parameter id: 1297 Numerical gradient of -0.031769 is not close to the backpropagation gradient of -3.176910!\n",
      "Parameter id: 1298 Numerical gradient of -0.008386 is not close to the backpropagation gradient of -0.838615!\n"
     ]
    }
   ],
   "source": [
    "# Do gradient checking\n",
    "# Define an RNN to test\n",
    "RNN = RnnBinaryAdder(1, output_size, hidden_size, seq_length)\n",
    "# Get the gradients of the parameters from a subset of the data\n",
    "backprop_grads = RNN.getParamGrads(\n",
    "    x_train[:100], y_train[:100])\n",
    "\n",
    "eps = 1e-7  # Set the small change to compute the numerical gradient\n",
    "# Compute the numerical gradients of the parameters in all layers.\n",
    "for p_idx, param in enumerate(RNN.get_params_iter()):\n",
    "    grad_backprop = backprop_grads[p_idx]\n",
    "    # + eps\n",
    "    param += eps\n",
    "    plus_loss = RNN.loss(\n",
    "        RNN.getOutput(x_train[0:100]), y_train[0:100])\n",
    "    # - eps\n",
    "    param -= 2 * eps\n",
    "    min_loss = RNN.loss(\n",
    "        RNN.getOutput(x_train[0:100]), y_train[0:100])\n",
    "    # reset param value\n",
    "    param += eps\n",
    "    # calculate numerical gradient\n",
    "    grad_num = (plus_loss - min_loss) / (2*eps)\n",
    "    # Raise error if the numerical grade is not close to the \n",
    "    #  backprop gradient\n",
    "    if not np.isclose(grad_num, grad_backprop):\n",
    "        print((\n",
    "            f'Parameter id: {p_idx} '\n",
    "            f'Numerical gradient of {grad_num:.6f} is not close '\n",
    "            f'to the backpropagation gradient of {grad_backprop:.6f}!'\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: read article till end\n",
    "# TODO: gradient of loss w.r.t to softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All network is good; error somewhere inside LOgisticSOftmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
