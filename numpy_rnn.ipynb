{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "import itertools\n",
    "import numpy as np  # Matrix and vector computation package\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt  # Plotting library\n",
    "import seaborn as sns  # Fancier plots\n",
    "\n",
    "# Set seaborn plotting style\n",
    "sns.set_style('darkgrid')\n",
    "# Set the seed for reproducability\n",
    "np.random.seed(seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train tensor shape: (2000, 7, 2)\n",
      "T_train tensor shape: (2000, 7, 1)\n"
     ]
    }
   ],
   "source": [
    "# Create dataset\n",
    "nb_train = 2000  # Number of training samples\n",
    "# Addition of 2 n-bit numbers can result in a n+1 bit number\n",
    "sequence_len = 7  # Length of the binary sequence\n",
    "\n",
    "def create_dataset(nb_samples, sequence_len):\n",
    "    \"\"\"Create a dataset for binary addition and \n",
    "    return as input, targets.\"\"\"\n",
    "    max_int = 2**(sequence_len-1) # Maximum integer that can be added\n",
    "     # Transform integer in binary format\n",
    "    format_str = '{:0' + str(sequence_len) + 'b}'\n",
    "    nb_inputs = 2  # Add 2 binary numbers\n",
    "    nb_outputs = 1  # Result is 1 binary number\n",
    "    # Input samples\n",
    "    X = np.zeros((nb_samples, sequence_len, nb_inputs))\n",
    "    # Target samples\n",
    "    T = np.zeros((nb_samples, sequence_len, nb_outputs))\n",
    "    # Fill up the input and target matrix\n",
    "    for i in range(nb_samples):\n",
    "        # Generate random numbers to add\n",
    "        nb1 = np.random.randint(0, max_int)\n",
    "        nb2 = np.random.randint(0, max_int)\n",
    "        # Fill current input and target row.\n",
    "        # Note that binary numbers are added from right to left, \n",
    "        #  but our RNN reads from left to right, so reverse the sequence.\n",
    "        X[i,:,0] = list(\n",
    "            reversed([int(b) for b in format_str.format(nb1)]))\n",
    "        X[i,:,1] = list(\n",
    "            reversed([int(b) for b in format_str.format(nb2)]))\n",
    "        T[i,:,0] = list(\n",
    "            reversed([int(b) for b in format_str.format(nb1+nb2)]))\n",
    "    return X, T\n",
    "\n",
    "# Create training samples\n",
    "X_train, T_train = create_dataset(nb_train, sequence_len)\n",
    "print(f'X_train tensor shape: {X_train.shape}')\n",
    "print(f'T_train tensor shape: {T_train.shape}')\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1:   1010010   37\n",
      "x2: + 1101010   43\n",
      "      -------   --\n",
      "t:  = 0000101   80\n"
     ]
    }
   ],
   "source": [
    "# Show an example input and target\n",
    "def printSample(x1, x2, t, y=None):\n",
    "    \"\"\"Print a sample in a more visual way.\"\"\"\n",
    "    x1 = ''.join([str(int(d)) for d in x1])\n",
    "    x1_r = int(''.join(reversed(x1)), 2)\n",
    "    x2 = ''.join([str(int(d)) for d in x2])\n",
    "    x2_r = int(''.join(reversed(x2)), 2)\n",
    "    t = ''.join([str(int(d[0])) for d in t])\n",
    "    t_r = int(''.join(reversed(t)), 2)\n",
    "    if not y is None:\n",
    "        y = ''.join([str(int(d[0])) for d in y])\n",
    "    print(f'x1:   {x1:s}   {x1_r:2d}')\n",
    "    print(f'x2: + {x2:s}   {x2_r:2d}')\n",
    "    print(f'      -------   --')\n",
    "    print(f't:  = {t:s}   {t_r:2d}')\n",
    "    if not y is None:\n",
    "        print(f'y:  = {y:s}')\n",
    "    \n",
    "# Print the first sample\n",
    "printSample(X_train[0,:,0], X_train[0,:,1], T_train[0,:,:])\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the linear tensor transformation layer\n",
    "class TensorLinear(object):\n",
    "    \"\"\"The linear tensor layer applies a linear tensor dot product \n",
    "    and a bias to its input.\"\"\"\n",
    "    def __init__(self, n_in, n_out, tensor_order, W=None, b=None):\n",
    "        \"\"\"Initialse the weight W and bias b parameters.\"\"\"\n",
    "        a = np.sqrt(6.0 / (n_in + n_out))\n",
    "        self.W = (np.random.uniform(-a, a, (n_in, n_out)) \n",
    "                  if W is None else W)\n",
    "        self.b = (np.zeros((n_out)) if b is None else b)\n",
    "        # Axes summed over in backprop\n",
    "        self.bpAxes = tuple(range(tensor_order-1))\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"Perform forward step transformation with the help \n",
    "        of a tensor product.\"\"\"\n",
    "        # Same as: Y[i,j,:] = np.dot(X[i,j,:], self.W) + self.b \n",
    "        #          (for i,j in X.shape[0:1])\n",
    "        # Same as: Y = np.einsum('ijk,kl->ijl', X, self.W) + self.b\n",
    "        return np.tensordot(X, self.W, axes=((-1),(0))) + self.b\n",
    "\n",
    "    def backward(self, X, gY):\n",
    "        \"\"\"Return the gradient of the parmeters and the inputs of \n",
    "        this layer.\"\"\"\n",
    "        # Same as: gW = np.einsum('ijk,ijl->kl', X, gY)\n",
    "        # Same as: gW += np.dot(X[:,j,:].T, gY[:,j,:]) \n",
    "        #          (for i,j in X.shape[0:1])\n",
    "        gW = np.tensordot(X, gY, axes=(self.bpAxes, self.bpAxes))\n",
    "        gB = np.sum(gY, axis=self.bpAxes)\n",
    "        # Same as: gX = np.einsum('ijk,kl->ijl', gY, self.W.T)\n",
    "        # Same as: gX[i,j,:] = np.dot(gY[i,j,:], self.W.T) \n",
    "        #          (for i,j in gY.shape[0:1])\n",
    "        gX = np.tensordot(gY, self.W.T, axes=((-1),(0)))  \n",
    "        return gX, gW, gB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the logistic classifier layer\n",
    "class LogisticClassifier(object):\n",
    "    \"\"\"The logistic layer applies the logistic function to its \n",
    "    inputs.\"\"\"\n",
    "   \n",
    "    def forward(self, X):\n",
    "        \"\"\"Perform the forward step transformation.\"\"\"\n",
    "        return 1. / (1. + np.exp(-X))\n",
    "    \n",
    "    def backward(self, Y, T):\n",
    "        \"\"\"Return the gradient with respect to the loss function \n",
    "        at the inputs of this layer.\"\"\"\n",
    "        # Average by the number of samples and sequence length.\n",
    "        return (Y - T) / (Y.shape[0] * Y.shape[1])\n",
    "    \n",
    "    def loss(self, Y, T):\n",
    "        \"\"\"Compute the loss at the output.\"\"\"\n",
    "        return -np.mean((T * np.log(Y)) + ((1-T) * np.log(1-Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tanh layer\n",
    "class TanH(object):\n",
    "    \"\"\"TanH applies the tanh function to its inputs.\"\"\"\n",
    "    \n",
    "    def forward(self, X):\n",
    "        \"\"\"Perform the forward step transformation.\"\"\"\n",
    "        return np.tanh(X) \n",
    "    \n",
    "    def backward(self, Y, output_grad):\n",
    "        \"\"\"Return the gradient at the inputs of this layer.\"\"\"\n",
    "        gTanh = 1.0 - (Y**2)\n",
    "        return (gTanh * output_grad)\n",
    "\n",
    "# Define internal state update layer\n",
    "class RecurrentStateUpdate(object):\n",
    "    \"\"\"Update a given state.\"\"\"\n",
    "    def __init__(self, nbStates, W, b):\n",
    "        \"\"\"Initialse the linear transformation and tanh transfer \n",
    "        function.\"\"\"\n",
    "        self.linear = TensorLinear(nbStates, nbStates, 2, W, b)\n",
    "        self.tanh = TanH()\n",
    "\n",
    "    def forward(self, Xk, Sk):\n",
    "        \"\"\"Return state k+1 from input and state k.\"\"\"\n",
    "        return self.tanh.forward(Xk + self.linear.forward(Sk))\n",
    "    \n",
    "    def backward(self, Sk0, Sk1, output_grad):\n",
    "        \"\"\"Return the gradient of the parmeters and the inputs of \n",
    "        this layer.\"\"\"\n",
    "        gZ = self.tanh.backward(Sk1, output_grad)\n",
    "        gSk0, gW, gB = self.linear.backward(Sk0, gZ)\n",
    "        return gZ, gSk0, gW, gB\n",
    "\n",
    "# Define layer that unfolds the states over time\n",
    "class RecurrentStateUnfold(object):\n",
    "    \"\"\"Unfold the recurrent states.\"\"\"\n",
    "    def __init__(self, nbStates, nbTimesteps):\n",
    "        \"\"\"Initialse the shared parameters, the inital state and \n",
    "        state update function.\"\"\"\n",
    "        a = np.sqrt(6. / (nbStates * 2))\n",
    "        self.W = np.random.uniform(-a, a, (nbStates, nbStates))\n",
    "        self.b = np.zeros((self.W.shape[0]))  # Shared bias\n",
    "        self.S0 = np.zeros(nbStates)  # Initial state\n",
    "        self.nbTimesteps = nbTimesteps  # Timesteps to unfold\n",
    "        self.stateUpdate = RecurrentStateUpdate(\n",
    "            nbStates, self.W, self.b)  # State update function\n",
    "        \n",
    "    def forward(self, X):\n",
    "        \"\"\"Iteratively apply forward step to all states.\"\"\"\n",
    "        # State tensor\n",
    "        S = np.zeros((X.shape[0], X.shape[1]+1, self.W.shape[0]))\n",
    "        S[:,0,:] = self.S0  # Set initial state\n",
    "        for k in range(self.nbTimesteps):\n",
    "            # Update the states iteratively\n",
    "            S[:,k+1,:] = self.stateUpdate.forward(X[:,k,:], S[:,k,:])\n",
    "        return S\n",
    "    \n",
    "    def backward(self, X, S, gY):\n",
    "        \"\"\"Return the gradient of the parmeters and the inputs of \n",
    "        this layer.\"\"\"\n",
    "        # Initialise gradient of state outputs\n",
    "        gSk = np.zeros_like(gY[:,self.nbTimesteps-1,:])\n",
    "        # Initialse gradient tensor for state inputs\n",
    "        gZ = np.zeros_like(X)\n",
    "        gWSum = np.zeros_like(self.W)  # Initialise weight gradients\n",
    "        gBSum = np.zeros_like(self.b)  # Initialse bias gradients\n",
    "        # Propagate the gradients iteratively\n",
    "        for k in range(self.nbTimesteps-1, -1, -1):\n",
    "            # Gradient at state output is gradient from previous state \n",
    "            #  plus gradient from output\n",
    "            gSk += gY[:,k,:]\n",
    "            # Propgate the gradient back through one state\n",
    "            gZ[:,k,:], gSk, gW, gB = self.stateUpdate.backward(\n",
    "                S[:,k,:], S[:,k+1,:], gSk)\n",
    "            gWSum += gW  # Update total weight gradient\n",
    "            gBSum += gB  # Update total bias gradient\n",
    "        # Get gradient of initial state over all samples\n",
    "        gS0 = np.sum(gSk, axis=0)\n",
    "        return gZ, gWSum, gBSum, gS0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the full network\n",
    "class RnnBinaryAdder(object):\n",
    "    \"\"\"RNN to perform binary addition of 2 numbers.\"\"\"\n",
    "    def __init__(self, nb_of_inputs, nb_of_outputs, nb_of_states, \n",
    "                 sequence_len):\n",
    "        \"\"\"Initialse the network layers.\"\"\"\n",
    "        # Input layer\n",
    "        self.tensorInput = TensorLinear(nb_of_inputs, nb_of_states, 3)\n",
    "        # Recurrent layer\n",
    "        self.rnnUnfold = RecurrentStateUnfold(nb_of_states, sequence_len)\n",
    "        # Linear output transform\n",
    "        self.tensorOutput = TensorLinear(nb_of_states, nb_of_outputs, 3)\n",
    "        self.classifier = LogisticClassifier()  # Classification output\n",
    "        \n",
    "    def forward(self, X):\n",
    "        \"\"\"Perform the forward propagation of input X through all \n",
    "        layers.\"\"\"\n",
    "        # Linear input transformation\n",
    "        recIn = self.tensorInput.forward(X)\n",
    "        # Forward propagate through time and return states\n",
    "        S = self.rnnUnfold.forward(recIn)\n",
    "        # Linear output transformation\n",
    "        Z = self.tensorOutput.forward(S[:,1:sequence_len+1,:])\n",
    "        Y = self.classifier.forward(Z)  # Classification probabilities\n",
    "        # Return: input to recurrent layer, states, input to classifier, \n",
    "        #  output\n",
    "        return recIn, S, Z, Y\n",
    "    \n",
    "    def backward(self, X, Y, recIn, S, T):\n",
    "        \"\"\"Perform the backward propagation through all layers.\n",
    "        Input: input samples, network output, intput to recurrent \n",
    "        layer, states, targets.\"\"\"\n",
    "        gZ = self.classifier.backward(Y, T)  # Get output gradient\n",
    "        gRecOut, gWout, gBout = self.tensorOutput.backward(\n",
    "            S[:,1:sequence_len+1,:], gZ)\n",
    "        # Propagate gradient backwards through time\n",
    "        gRnnIn, gWrec, gBrec, gS0 = self.rnnUnfold.backward(\n",
    "            recIn, S, gRecOut)\n",
    "        gX, gWin, gBin = self.tensorInput.backward(X, gRnnIn)\n",
    "        # Return the parameter gradients of: linear output weights, \n",
    "        #  linear output bias, recursive weights, recursive bias, #\n",
    "        #  linear input weights, linear input bias, initial state.\n",
    "        return gWout, gBout, gWrec, gBrec, gWin, gBin, gS0\n",
    "    \n",
    "    def getOutput(self, X):\n",
    "        \"\"\"Get the output probabilities of input X.\"\"\"\n",
    "        recIn, S, Z, Y = self.forward(X)\n",
    "        return Y\n",
    "    \n",
    "    def getBinaryOutput(self, X):\n",
    "        \"\"\"Get the binary output of input X.\"\"\"\n",
    "        return np.around(self.getOutput(X))\n",
    "    \n",
    "    def getParamGrads(self, X, T):\n",
    "        \"\"\"Return the gradients with respect to input X and \n",
    "        target T as a list. The list has the same order as the \n",
    "        get_params_iter iterator.\"\"\"\n",
    "        recIn, S, Z, Y = self.forward(X)\n",
    "        gWout, gBout, gWrec, gBrec, gWin, gBin, gS0 = self.backward(\n",
    "            X, Y, recIn, S, T)\n",
    "        return [g for g in itertools.chain(\n",
    "                np.nditer(gS0),\n",
    "                np.nditer(gWin),\n",
    "                np.nditer(gBin),\n",
    "                np.nditer(gWrec),\n",
    "                np.nditer(gBrec),\n",
    "                np.nditer(gWout),\n",
    "                np.nditer(gBout))]\n",
    "    \n",
    "    def loss(self, Y, T):\n",
    "        \"\"\"Return the loss of input X w.r.t. targets T.\"\"\"\n",
    "        return self.classifier.loss(Y, T)\n",
    "    \n",
    "    def get_params_iter(self):\n",
    "        \"\"\"Return an iterator over the parameters.\n",
    "        The iterator has the same order as get_params_grad.\n",
    "        The elements returned by the iterator are editable in-place.\"\"\"\n",
    "        return itertools.chain(\n",
    "            np.nditer(self.rnnUnfold.S0, op_flags=['readwrite']),\n",
    "            np.nditer(self.tensorInput.W, op_flags=['readwrite']),\n",
    "            np.nditer(self.tensorInput.b, op_flags=['readwrite']),\n",
    "            np.nditer(self.rnnUnfold.W, op_flags=['readwrite']),\n",
    "            np.nditer(self.rnnUnfold.b, op_flags=['readwrite']),\n",
    "            np.nditer(self.tensorOutput.W, op_flags=['readwrite']), \n",
    "            np.nditer(self.tensorOutput.b, op_flags=['readwrite']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyper-parameters\n",
    "lmbd = 0.5  # Rmsprop lambda\n",
    "learning_rate = 0.05  # Learning rate\n",
    "momentum_term = 0.80  # Momentum term\n",
    "eps = 1e-6  # Numerical stability term to prevent division by zero\n",
    "mb_size = 100  # Size of the minibatches (number of samples)\n",
    "\n",
    "# Create the network\n",
    "nb_of_states = 3  # Number of states in the recurrent layer\n",
    "RNN = RnnBinaryAdder(2, 1, nb_of_states, sequence_len)\n",
    "# Set the initial parameters\n",
    "# Number of parameters in the network\n",
    "nbParameters =  sum(1 for _ in RNN.get_params_iter())\n",
    "# Rmsprop moving average\n",
    "maSquare = [0.0 for _ in range(nbParameters)]\n",
    "Vs = [0.0 for _ in range(nbParameters)]  # Momentum\n",
    "\n",
    "# Create a list of minibatch losses to be plotted\n",
    "ls_of_loss = [\n",
    "    RNN.loss(RNN.getOutput(X_train[0:100,:,:]), T_train[0:100,:,:])]\n",
    "\n",
    "# Iterate over some iterations\n",
    "for i in range(5):\n",
    "    # Iterate over all the minibatches\n",
    "    for mb in range(nb_train // mb_size):\n",
    "        X_mb = X_train[mb:mb+mb_size,:,:]  # Input minibatch\n",
    "        T_mb = T_train[mb:mb+mb_size,:,:]  # Target minibatch\n",
    "        V_tmp = [v * momentum_term for v in Vs]\n",
    "        # Update each parameters according to previous gradient\n",
    "        for pIdx, P in enumerate(RNN.get_params_iter()):\n",
    "            P += V_tmp[pIdx]\n",
    "        # Get gradients after following old velocity\n",
    "        # Get the parameter gradients\n",
    "        backprop_grads = RNN.getParamGrads(X_mb, T_mb)    \n",
    "        # Update each parameter seperately\n",
    "        for pIdx, P in enumerate(RNN.get_params_iter()):\n",
    "            # Update the Rmsprop moving averages\n",
    "            maSquare[pIdx] = lmbd * maSquare[pIdx] + (\n",
    "                1-lmbd) * backprop_grads[pIdx]**2\n",
    "            # Calculate the Rmsprop normalised gradient\n",
    "            pGradNorm = ((\n",
    "                learning_rate * backprop_grads[pIdx]) / np.sqrt(\n",
    "                maSquare[pIdx]) + eps)\n",
    "            # Update the momentum\n",
    "            Vs[pIdx] = V_tmp[pIdx] - pGradNorm     \n",
    "            P -= pGradNorm   # Update the parameter\n",
    "        # Add loss to list to plot\n",
    "        ls_of_loss.append(RNN.loss(RNN.getOutput(X_mb), T_mb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss over the iterations\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "plt.plot(ls_of_loss, 'b-')\n",
    "plt.xlabel('minibatch iteration')\n",
    "plt.ylabel('$\\\\xi$', fontsize=15)\n",
    "plt.title('Decrease of loss over backprop iteration')\n",
    "plt.xlim(0, 100)\n",
    "fig.subplots_adjust(bottom=0.2)\n",
    "plt.show()\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No gradient errors found\n"
     ]
    }
   ],
   "source": [
    "# Do gradient checking\n",
    "# Define an RNN to test\n",
    "RNN = RnnBinaryAdder(2, 1, 3, sequence_len)\n",
    "# Get the gradients of the parameters from a subset of the data\n",
    "backprop_grads = RNN.getParamGrads(\n",
    "    X_train[0:100,:,:], T_train[0:100,:,:])\n",
    "\n",
    "eps = 1e-7  # Set the small change to compute the numerical gradient\n",
    "# Compute the numerical gradients of the parameters in all layers.\n",
    "for p_idx, param in enumerate(RNN.get_params_iter()):\n",
    "    grad_backprop = backprop_grads[p_idx]\n",
    "    # + eps\n",
    "    param += eps\n",
    "    plus_loss = RNN.loss(\n",
    "        RNN.getOutput(X_train[0:100,:,:]), T_train[0:100,:,:])\n",
    "    # - eps\n",
    "    param -= 2 * eps\n",
    "    min_loss = RNN.loss(\n",
    "        RNN.getOutput(X_train[0:100,:,:]), T_train[0:100,:,:])\n",
    "    # reset param value\n",
    "    param += eps\n",
    "    # calculate numerical gradient\n",
    "    grad_num = (plus_loss - min_loss) / (2*eps)\n",
    "    # Raise error if the numerical grade is not close to the \n",
    "    #  backprop gradient\n",
    "    if not np.isclose(grad_num, grad_backprop):\n",
    "        raise ValueError((\n",
    "            f'Numerical gradient of {grad_num:.6f} is not close '\n",
    "            f'to the backpropagation gradient of {grad_backprop:.6f}!'\n",
    "        ))\n",
    "print('No gradient errors found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1:   0100010   34\n",
      "x2: + 1100100   19\n",
      "      -------   --\n",
      "t:  = 1010110   53\n",
      "y:  = 0001000\n",
      "\n",
      "x1:   1010100   21\n",
      "x2: + 1110100   23\n",
      "      -------   --\n",
      "t:  = 0011010   44\n",
      "y:  = 0000001\n",
      "\n",
      "x1:   1111010   47\n",
      "x2: + 0000000    0\n",
      "      -------   --\n",
      "t:  = 1111010   47\n",
      "y:  = 0000010\n",
      "\n",
      "x1:   1000000    1\n",
      "x2: + 1111110   63\n",
      "      -------   --\n",
      "t:  = 0000001   64\n",
      "y:  = 0000000\n",
      "\n",
      "x1:   1010100   21\n",
      "x2: + 1010100   21\n",
      "      -------   --\n",
      "t:  = 0101010   42\n",
      "y:  = 0000001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create test samples\n",
    "nb_test = 5\n",
    "Xtest, Ttest = create_dataset(nb_test, sequence_len)\n",
    "# Push test data through network\n",
    "Y = RNN.getBinaryOutput(Xtest)\n",
    "Yf = RNN.getOutput(Xtest)\n",
    "\n",
    "# Print out all test examples\n",
    "for i in range(Xtest.shape[0]):\n",
    "    printSample(Xtest[i,:,0], Xtest[i,:,1], Ttest[i,:,:], Y[i,:,:])\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
