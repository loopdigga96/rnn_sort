{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import *\n",
    "import sys\n",
    "import itertools\n",
    "import numpy as np  # Matrix and vector computation package\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt  # Plotting library\n",
    "import seaborn as sns  # Fancier plots\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Set seaborn plotting style\n",
    "sns.set_style('darkgrid')\n",
    "# Set the seed for reproducability\n",
    "np.random.seed(seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sort_dataset(dataset_length, seq_length, max_number=999, fraction=0.8):\n",
    "    x_train = np.random.randint(low=0, high=max_number+1, size=(int(dataset_length*fraction),\n",
    "                                                                seq_length,\n",
    "                                                                1))\n",
    "    y_train = np.sort(x_train, axis=1)\n",
    "    \n",
    "    x_test = np.random.randint(low=0, high=max_number+1, size=(int(dataset_length*(1-fraction)),\n",
    "                                                               seq_length,\n",
    "                                                               1))\n",
    "    y_test = np.sort(x_test, axis=1)\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "def create_dummy_dataset(dataset_length, seq_length, max_number):\n",
    "    lower_bound = -1 * max_number\n",
    "    x_train = np.random.randint(low=lower_bound, high=max_number+1, size=(dataset_length, seq_length, 1))\n",
    "    y_train = np.where(x_train.sum(axis=2) > 0, 1, 0).reshape(x_train.shape)\n",
    "    \n",
    "    x_test = np.random.randint(low=lower_bound, high=max_number+1, size=(dataset_length, seq_length, 1))\n",
    "    y_test = np.where(x_test.sum(axis=2) > 0, 1, 0).reshape(x_train.shape)\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "def evaluate(y_test, x_test, model):\n",
    "    y_pred = model.predict(x_test)\n",
    "    loss = model.loss(model.predict_proba(x_test), y_test)\n",
    "    \n",
    "    print(f'Cross entropy loss {loss}')\n",
    "    print('-'*100)\n",
    "    print(classification_report(y_test.flatten(), y_pred.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyper-parameters\n",
    "batch_size = 20  # Size of the minibatches (number of samples)\n",
    "max_num = 10 \n",
    "seq_length = 5\n",
    "hidden_size = 10 \n",
    "dataset_size = 200\n",
    "epoch = 4\n",
    "\n",
    "x_train, y_train, x_test, y_test = create_sort_dataset(dataset_size, seq_length, max_num)\n",
    "\n",
    "input_size = 1\n",
    "output_size = max_num+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "TRAIN: Cross entropy loss:  2.5307617353409277\n",
      "VALIDATION: Cross entropy loss:  2.5718785329512475\n",
      "Epoch 2/4\n",
      "TRAIN: Cross entropy loss:  2.4151134963712866\n",
      "VALIDATION: Cross entropy loss:  2.510408643324758\n",
      "Epoch 3/4\n",
      "TRAIN: Cross entropy loss:  2.362500060425506\n",
      "VALIDATION: Cross entropy loss:  2.466518959123873\n",
      "Epoch 4/4\n",
      "TRAIN: Cross entropy loss:  2.3237591749080555\n",
      "VALIDATION: Cross entropy loss:  2.431801727443801\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the network\n",
    "model = ModelSort(input_size, output_size, hidden_size, seq_length)\n",
    "\n",
    "train_loss = []\n",
    "validation_loss = []\n",
    "\n",
    "for i in range(epoch):\n",
    "    print(f'Epoch {i+1}/{epoch}')\n",
    "    epoch_train_loss = []\n",
    "    \n",
    "    for mb in range(dataset_size // batch_size):\n",
    "        x_batch = x_train[mb:mb + batch_size]  # Input minibatch\n",
    "        y_batch = y_train[mb:mb + batch_size]  # Target minibatch\n",
    "        model.train_on_batch(x_batch, y_batch)\n",
    "        \n",
    "        loss = model.loss(model.predict_proba(x_batch), y_batch)\n",
    "        epoch_train_loss.append(loss)\n",
    "        \n",
    "\n",
    "    train_loss.append(np.mean(epoch_train_loss))\n",
    "    validation_loss.append(model.loss(model.predict_proba(x_test), y_test))\n",
    "\n",
    "\n",
    "    print(\"TRAIN: Cross entropy loss: \", train_loss[-1])\n",
    "    print(\"VALIDATION: Cross entropy loss: \", validation_loss[-1])\n",
    "\n",
    "\n",
    "\n",
    "# Plot the loss over the iterations\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "plt.plot(train_loss, 'b-')\n",
    "plt.plot(validation_loss, 'r')\n",
    "plt.xlabel('minibatch iteration')\n",
    "plt.ylabel('Cross entropy loss', fontsize=15)\n",
    "plt.xlim(0, 100)\n",
    "fig.subplots_adjust(bottom=0.2)\n",
    "plt.show()\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross entropy loss 2.431801727443801\n",
      "----------------------------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.74      0.58        31\n",
      "           1       0.00      0.00      0.00        35\n",
      "           2       0.00      0.00      0.00        42\n",
      "           3       0.12      0.21      0.15        39\n",
      "           4       0.17      0.22      0.19        37\n",
      "           5       0.00      0.00      0.00        39\n",
      "           6       0.17      0.05      0.07        42\n",
      "           7       0.06      0.08      0.07        25\n",
      "           8       0.00      0.00      0.00        43\n",
      "           9       0.06      0.22      0.09        27\n",
      "          10       0.09      0.20      0.12        30\n",
      "\n",
      "   micro avg       0.14      0.14      0.14       390\n",
      "   macro avg       0.10      0.16      0.12       390\n",
      "weighted avg       0.10      0.14      0.11       390\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/loopdigga/Documents/python3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/loopdigga/Documents/python3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/loopdigga/Documents/python3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_test, x_test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter id: 0 Numerical gradient of 0.014847 is not close to the backpropagation gradient of 1.123312!\n",
      "Parameter id: 1 Numerical gradient of 0.037006 is not close to the backpropagation gradient of 3.747619!\n",
      "Parameter id: 2 Numerical gradient of 0.038063 is not close to the backpropagation gradient of 3.867195!\n",
      "Parameter id: 3 Numerical gradient of 0.022023 is not close to the backpropagation gradient of 1.857961!\n",
      "Parameter id: 4 Numerical gradient of -0.007457 is not close to the backpropagation gradient of -1.274286!\n",
      "Parameter id: 5 Numerical gradient of -0.006492 is not close to the backpropagation gradient of -0.569035!\n",
      "Parameter id: 6 Numerical gradient of -0.008934 is not close to the backpropagation gradient of -0.809759!\n",
      "Parameter id: 7 Numerical gradient of -0.009676 is not close to the backpropagation gradient of -1.126236!\n",
      "Parameter id: 8 Numerical gradient of -0.041648 is not close to the backpropagation gradient of -4.039855!\n",
      "Parameter id: 9 Numerical gradient of 0.025313 is not close to the backpropagation gradient of 2.638829!\n",
      "Parameter id: 10 Numerical gradient of 0.564999 is not close to the backpropagation gradient of 48.476061!\n",
      "Parameter id: 11 Numerical gradient of 0.024594 is not close to the backpropagation gradient of 2.836811!\n",
      "Parameter id: 12 Numerical gradient of 0.169927 is not close to the backpropagation gradient of 30.204978!\n",
      "Parameter id: 13 Numerical gradient of 0.204694 is not close to the backpropagation gradient of 27.672508!\n",
      "Parameter id: 14 Numerical gradient of -0.008740 is not close to the backpropagation gradient of -1.086044!\n",
      "Parameter id: 15 Numerical gradient of -0.011028 is not close to the backpropagation gradient of -1.095959!\n",
      "Parameter id: 16 Numerical gradient of 0.008336 is not close to the backpropagation gradient of 1.928046!\n",
      "Parameter id: 17 Numerical gradient of -0.001919 is not close to the backpropagation gradient of -0.216312!\n",
      "Parameter id: 18 Numerical gradient of -0.310178 is not close to the backpropagation gradient of -24.657820!\n",
      "Parameter id: 19 Numerical gradient of 0.038037 is not close to the backpropagation gradient of 4.441726!\n",
      "Parameter id: 20 Numerical gradient of 0.101446 is not close to the backpropagation gradient of 8.985188!\n",
      "Parameter id: 21 Numerical gradient of -0.004511 is not close to the backpropagation gradient of -0.150702!\n",
      "Parameter id: 22 Numerical gradient of 0.059509 is not close to the backpropagation gradient of 8.051425!\n",
      "Parameter id: 23 Numerical gradient of 0.065415 is not close to the backpropagation gradient of 7.544316!\n",
      "Parameter id: 24 Numerical gradient of -0.003875 is not close to the backpropagation gradient of -0.707036!\n",
      "Parameter id: 25 Numerical gradient of -0.016017 is not close to the backpropagation gradient of -1.493858!\n",
      "Parameter id: 26 Numerical gradient of -0.018941 is not close to the backpropagation gradient of -1.625132!\n",
      "Parameter id: 27 Numerical gradient of -0.014011 is not close to the backpropagation gradient of -1.562471!\n",
      "Parameter id: 28 Numerical gradient of -0.106926 is not close to the backpropagation gradient of -9.545490!\n",
      "Parameter id: 29 Numerical gradient of 0.016853 is not close to the backpropagation gradient of 2.155370!\n",
      "Parameter id: 30 Numerical gradient of 0.029824 is not close to the backpropagation gradient of 3.907493!\n",
      "Parameter id: 31 Numerical gradient of 0.003010 is not close to the backpropagation gradient of 0.747267!\n",
      "Parameter id: 32 Numerical gradient of -0.002415 is not close to the backpropagation gradient of 1.275479!\n",
      "Parameter id: 33 Numerical gradient of -0.013585 is not close to the backpropagation gradient of -0.175111!\n",
      "Parameter id: 34 Numerical gradient of -0.000961 is not close to the backpropagation gradient of -0.158210!\n",
      "Parameter id: 35 Numerical gradient of -0.000383 is not close to the backpropagation gradient of -0.067988!\n",
      "Parameter id: 36 Numerical gradient of 0.000426 is not close to the backpropagation gradient of 0.207196!\n",
      "Parameter id: 37 Numerical gradient of 0.001444 is not close to the backpropagation gradient of 0.218159!\n",
      "Parameter id: 38 Numerical gradient of 0.006744 is not close to the backpropagation gradient of 0.048356!\n",
      "Parameter id: 39 Numerical gradient of -0.000582 is not close to the backpropagation gradient of 0.374657!\n",
      "Parameter id: 40 Numerical gradient of 0.083012 is not close to the backpropagation gradient of 6.365610!\n",
      "Parameter id: 41 Numerical gradient of 0.010772 is not close to the backpropagation gradient of 1.380095!\n",
      "Parameter id: 42 Numerical gradient of 0.022333 is not close to the backpropagation gradient of 3.486037!\n",
      "Parameter id: 43 Numerical gradient of 0.015193 is not close to the backpropagation gradient of 2.739775!\n",
      "Parameter id: 44 Numerical gradient of 0.001843 is not close to the backpropagation gradient of -0.058662!\n",
      "Parameter id: 45 Numerical gradient of -0.001479 is not close to the backpropagation gradient of -0.142093!\n",
      "Parameter id: 46 Numerical gradient of 0.001175 is not close to the backpropagation gradient of 0.234653!\n",
      "Parameter id: 47 Numerical gradient of 0.003199 is not close to the backpropagation gradient of 0.280530!\n",
      "Parameter id: 48 Numerical gradient of -0.018122 is not close to the backpropagation gradient of -1.325729!\n",
      "Parameter id: 49 Numerical gradient of 0.010215 is not close to the backpropagation gradient of 1.354373!\n",
      "Parameter id: 50 Numerical gradient of 0.022587 is not close to the backpropagation gradient of 2.354352!\n",
      "Parameter id: 51 Numerical gradient of 0.003818 is not close to the backpropagation gradient of 0.523320!\n",
      "Parameter id: 52 Numerical gradient of -0.001039 is not close to the backpropagation gradient of 0.676710!\n",
      "Parameter id: 53 Numerical gradient of -0.007132 is not close to the backpropagation gradient of -0.198635!\n",
      "Parameter id: 54 Numerical gradient of -0.003265 is not close to the backpropagation gradient of -0.327755!\n",
      "Parameter id: 55 Numerical gradient of -0.000430 is not close to the backpropagation gradient of -0.058110!\n",
      "Parameter id: 56 Numerical gradient of 0.001906 is not close to the backpropagation gradient of 0.225850!\n",
      "Parameter id: 57 Numerical gradient of 0.001672 is not close to the backpropagation gradient of 0.166193!\n",
      "Parameter id: 58 Numerical gradient of 0.004992 is not close to the backpropagation gradient of 0.055751!\n",
      "Parameter id: 59 Numerical gradient of -0.000031 is not close to the backpropagation gradient of 0.171344!\n",
      "Parameter id: 60 Numerical gradient of -0.000641 is not close to the backpropagation gradient of 1.074110!\n",
      "Parameter id: 61 Numerical gradient of -0.001971 is not close to the backpropagation gradient of 0.076954!\n",
      "Parameter id: 62 Numerical gradient of -0.002810 is not close to the backpropagation gradient of 0.402458!\n",
      "Parameter id: 63 Numerical gradient of -0.009067 is not close to the backpropagation gradient of -0.264300!\n",
      "Parameter id: 64 Numerical gradient of 0.003913 is not close to the backpropagation gradient of 0.348982!\n",
      "Parameter id: 65 Numerical gradient of 0.000285 is not close to the backpropagation gradient of 0.000875!\n",
      "Parameter id: 66 Numerical gradient of -0.001056 is not close to the backpropagation gradient of -0.029806!\n",
      "Parameter id: 67 Numerical gradient of -0.000574 is not close to the backpropagation gradient of 0.016583!\n",
      "Parameter id: 68 Numerical gradient of 0.003996 is not close to the backpropagation gradient of 0.076516!\n",
      "Parameter id: 69 Numerical gradient of 0.000156 is not close to the backpropagation gradient of 0.255874!\n",
      "Parameter id: 70 Numerical gradient of -0.076224 is not close to the backpropagation gradient of -5.387527!\n",
      "Parameter id: 71 Numerical gradient of -0.009941 is not close to the backpropagation gradient of -1.268626!\n",
      "Parameter id: 72 Numerical gradient of -0.019515 is not close to the backpropagation gradient of -2.989159!\n",
      "Parameter id: 73 Numerical gradient of -0.011929 is not close to the backpropagation gradient of -2.340050!\n",
      "Parameter id: 74 Numerical gradient of -0.000643 is not close to the backpropagation gradient of 0.176852!\n",
      "Parameter id: 75 Numerical gradient of 0.001169 is not close to the backpropagation gradient of 0.110724!\n",
      "Parameter id: 76 Numerical gradient of 0.000021 is not close to the backpropagation gradient of -0.097902!\n",
      "Parameter id: 77 Numerical gradient of -0.002961 is not close to the backpropagation gradient of -0.252461!\n",
      "Parameter id: 78 Numerical gradient of 0.016238 is not close to the backpropagation gradient of 1.164070!\n",
      "Parameter id: 79 Numerical gradient of -0.009048 is not close to the backpropagation gradient of -1.206270!\n",
      "Parameter id: 80 Numerical gradient of -0.093100 is not close to the backpropagation gradient of -7.658498!\n",
      "Parameter id: 81 Numerical gradient of -0.011228 is not close to the backpropagation gradient of -1.435945!\n",
      "Parameter id: 82 Numerical gradient of -0.027254 is not close to the backpropagation gradient of -4.179064!\n",
      "Parameter id: 83 Numerical gradient of -0.018384 is not close to the backpropagation gradient of -3.146432!\n",
      "Parameter id: 84 Numerical gradient of -0.001745 is not close to the backpropagation gradient of 0.075671!\n",
      "Parameter id: 85 Numerical gradient of 0.002327 is not close to the backpropagation gradient of 0.222658!\n",
      "Parameter id: 86 Numerical gradient of -0.002107 is not close to the backpropagation gradient of -0.337488!\n",
      "Parameter id: 87 Numerical gradient of -0.003670 is not close to the backpropagation gradient of -0.329119!\n",
      "Parameter id: 88 Numerical gradient of 0.020436 is not close to the backpropagation gradient of 1.554287!\n",
      "Parameter id: 89 Numerical gradient of -0.010847 is not close to the backpropagation gradient of -1.432625!\n",
      "Parameter id: 90 Numerical gradient of -0.080900 is not close to the backpropagation gradient of -6.330327!\n",
      "Parameter id: 91 Numerical gradient of -0.009940 is not close to the backpropagation gradient of -1.270391!\n",
      "Parameter id: 92 Numerical gradient of -0.018900 is not close to the backpropagation gradient of -3.167943!\n",
      "Parameter id: 93 Numerical gradient of -0.008941 is not close to the backpropagation gradient of -2.071074!\n",
      "Parameter id: 94 Numerical gradient of -0.000947 is not close to the backpropagation gradient of 0.084307!\n",
      "Parameter id: 95 Numerical gradient of 0.001193 is not close to the backpropagation gradient of 0.115528!\n",
      "Parameter id: 96 Numerical gradient of -0.002396 is not close to the backpropagation gradient of -0.368920!\n",
      "Parameter id: 97 Numerical gradient of -0.003355 is not close to the backpropagation gradient of -0.305159!\n",
      "Parameter id: 98 Numerical gradient of 0.011871 is not close to the backpropagation gradient of 0.869188!\n",
      "Parameter id: 99 Numerical gradient of -0.008414 is not close to the backpropagation gradient of -1.136892!\n",
      "Parameter id: 100 Numerical gradient of 0.089854 is not close to the backpropagation gradient of 7.279742!\n",
      "Parameter id: 101 Numerical gradient of 0.010930 is not close to the backpropagation gradient of 1.400911!\n",
      "Parameter id: 102 Numerical gradient of 0.024745 is not close to the backpropagation gradient of 3.867052!\n",
      "Parameter id: 103 Numerical gradient of 0.015876 is not close to the backpropagation gradient of 2.829393!\n",
      "Parameter id: 104 Numerical gradient of 0.001553 is not close to the backpropagation gradient of -0.073436!\n",
      "Parameter id: 105 Numerical gradient of -0.001954 is not close to the backpropagation gradient of -0.181227!\n",
      "Parameter id: 106 Numerical gradient of 0.002295 is not close to the backpropagation gradient of 0.362019!\n",
      "Parameter id: 107 Numerical gradient of 0.003587 is not close to the backpropagation gradient of 0.326134!\n",
      "Parameter id: 108 Numerical gradient of -0.018161 is not close to the backpropagation gradient of -1.335412!\n",
      "Parameter id: 109 Numerical gradient of 0.010139 is not close to the backpropagation gradient of 1.346486!\n",
      "Parameter id: 110 Numerical gradient of -0.076245 is not close to the backpropagation gradient of -6.371771!\n",
      "Parameter id: 111 Numerical gradient of -0.009466 is not close to the backpropagation gradient of -1.264120!\n",
      "Parameter id: 112 Numerical gradient of -0.015289 is not close to the backpropagation gradient of -3.058317!\n",
      "Parameter id: 113 Numerical gradient of -0.003425 is not close to the backpropagation gradient of -1.757233!\n",
      "Parameter id: 114 Numerical gradient of -0.000860 is not close to the backpropagation gradient of 0.070268!\n",
      "Parameter id: 115 Numerical gradient of 0.001033 is not close to the backpropagation gradient of 0.121483!\n",
      "Parameter id: 116 Numerical gradient of -0.003055 is not close to the backpropagation gradient of -0.440937!\n",
      "Parameter id: 117 Numerical gradient of -0.003300 is not close to the backpropagation gradient of -0.315698!\n",
      "Parameter id: 118 Numerical gradient of 0.006721 is not close to the backpropagation gradient of 0.708543!\n",
      "Parameter id: 119 Numerical gradient of -0.007160 is not close to the backpropagation gradient of -1.076190!\n",
      "Parameter id: 120 Numerical gradient of 0.078290 is not close to the backpropagation gradient of 5.953019!\n",
      "Parameter id: 121 Numerical gradient of 0.009948 is not close to the backpropagation gradient of 1.291452!\n",
      "Parameter id: 122 Numerical gradient of 0.019313 is not close to the backpropagation gradient of 3.171300!\n",
      "Parameter id: 123 Numerical gradient of 0.009261 is not close to the backpropagation gradient of 2.207055!\n",
      "Parameter id: 124 Numerical gradient of 0.001711 is not close to the backpropagation gradient of -0.053098!\n",
      "Parameter id: 125 Numerical gradient of -0.000997 is not close to the backpropagation gradient of -0.104118!\n",
      "Parameter id: 126 Numerical gradient of 0.000805 is not close to the backpropagation gradient of 0.210052!\n",
      "Parameter id: 127 Numerical gradient of 0.003010 is not close to the backpropagation gradient of 0.270693!\n",
      "Parameter id: 128 Numerical gradient of -0.014208 is not close to the backpropagation gradient of -1.053968!\n",
      "Parameter id: 129 Numerical gradient of 0.009140 is not close to the backpropagation gradient of 1.231881!\n",
      "Parameter id: 130 Numerical gradient of 0.101446 is not close to the backpropagation gradient of 8.985188!\n",
      "Parameter id: 131 Numerical gradient of -0.004511 is not close to the backpropagation gradient of -0.150702!\n",
      "Parameter id: 132 Numerical gradient of 0.059509 is not close to the backpropagation gradient of 8.051425!\n",
      "Parameter id: 133 Numerical gradient of 0.065415 is not close to the backpropagation gradient of 7.544316!\n",
      "Parameter id: 134 Numerical gradient of -0.003875 is not close to the backpropagation gradient of -0.707036!\n",
      "Parameter id: 135 Numerical gradient of -0.016017 is not close to the backpropagation gradient of -1.493858!\n",
      "Parameter id: 136 Numerical gradient of -0.018941 is not close to the backpropagation gradient of -1.625132!\n",
      "Parameter id: 137 Numerical gradient of -0.014011 is not close to the backpropagation gradient of -1.562471!\n",
      "Parameter id: 138 Numerical gradient of -0.106926 is not close to the backpropagation gradient of -9.545490!\n",
      "Parameter id: 139 Numerical gradient of 0.016853 is not close to the backpropagation gradient of 2.155370!\n",
      "Parameter id: 140 Numerical gradient of 0.073807 is not close to the backpropagation gradient of 13.192494!\n",
      "Parameter id: 141 Numerical gradient of 0.012301 is not close to the backpropagation gradient of -0.587652!\n",
      "Parameter id: 142 Numerical gradient of 0.015180 is not close to the backpropagation gradient of 0.612369!\n",
      "Parameter id: 143 Numerical gradient of 0.004541 is not close to the backpropagation gradient of -1.006575!\n",
      "Parameter id: 144 Numerical gradient of -0.000960 is not close to the backpropagation gradient of -1.383950!\n",
      "Parameter id: 145 Numerical gradient of -0.022001 is not close to the backpropagation gradient of -3.821577!\n",
      "Parameter id: 146 Numerical gradient of 0.005459 is not close to the backpropagation gradient of 3.151237!\n",
      "Parameter id: 147 Numerical gradient of -0.026070 is not close to the backpropagation gradient of -3.358406!\n",
      "Parameter id: 148 Numerical gradient of -0.012178 is not close to the backpropagation gradient of -1.499049!\n",
      "Parameter id: 149 Numerical gradient of -0.039773 is not close to the backpropagation gradient of -4.239421!\n",
      "Parameter id: 150 Numerical gradient of -0.010306 is not close to the backpropagation gradient of -1.059469!\n",
      "Parameter id: 151 Numerical gradient of 0.127105 is not close to the backpropagation gradient of 17.212185!\n",
      "Parameter id: 152 Numerical gradient of -0.051666 is not close to the backpropagation gradient of -5.825169!\n",
      "Parameter id: 153 Numerical gradient of -0.003836 is not close to the backpropagation gradient of -1.588103!\n",
      "Parameter id: 154 Numerical gradient of -0.031024 is not close to the backpropagation gradient of -4.137106!\n",
      "Parameter id: 155 Numerical gradient of -0.031343 is not close to the backpropagation gradient of -3.305631!\n",
      "Parameter id: 156 Numerical gradient of -0.037872 is not close to the backpropagation gradient of -4.688276!\n",
      "Parameter id: 157 Numerical gradient of 0.062743 is not close to the backpropagation gradient of 8.100419!\n",
      "Parameter id: 158 Numerical gradient of -0.028695 is not close to the backpropagation gradient of -3.111446!\n",
      "Parameter id: 159 Numerical gradient of -0.004689 is not close to the backpropagation gradient of -0.628826!\n",
      "Parameter id: 160 Numerical gradient of 0.002427 is not close to the backpropagation gradient of -1.501360!\n",
      "Parameter id: 161 Numerical gradient of -0.003149 is not close to the backpropagation gradient of -0.526687!\n",
      "Parameter id: 162 Numerical gradient of 0.063204 is not close to the backpropagation gradient of 8.484703!\n",
      "Parameter id: 163 Numerical gradient of 0.010594 is not close to the backpropagation gradient of 0.256327!\n",
      "Parameter id: 164 Numerical gradient of 0.001618 is not close to the backpropagation gradient of -0.235769!\n",
      "Parameter id: 165 Numerical gradient of -0.005032 is not close to the backpropagation gradient of -0.975265!\n",
      "Parameter id: 166 Numerical gradient of -0.008752 is not close to the backpropagation gradient of -1.252230!\n",
      "Parameter id: 167 Numerical gradient of -0.022861 is not close to the backpropagation gradient of -2.842511!\n",
      "Parameter id: 168 Numerical gradient of -0.002577 is not close to the backpropagation gradient of 0.887295!\n",
      "Parameter id: 169 Numerical gradient of -0.016403 is not close to the backpropagation gradient of -1.840867!\n",
      "Parameter id: 170 Numerical gradient of -0.003231 is not close to the backpropagation gradient of -0.426721!\n",
      "Parameter id: 171 Numerical gradient of -0.025069 is not close to the backpropagation gradient of -2.468241!\n",
      "Parameter id: 172 Numerical gradient of 0.008509 is not close to the backpropagation gradient of 0.413280!\n",
      "Parameter id: 173 Numerical gradient of 0.001145 is not close to the backpropagation gradient of 3.662254!\n",
      "Parameter id: 174 Numerical gradient of 0.005971 is not close to the backpropagation gradient of -0.454388!\n",
      "Parameter id: 175 Numerical gradient of 0.011976 is not close to the backpropagation gradient of 1.058129!\n",
      "Parameter id: 176 Numerical gradient of 0.007807 is not close to the backpropagation gradient of 0.036134!\n",
      "Parameter id: 177 Numerical gradient of 0.008909 is not close to the backpropagation gradient of 0.034802!\n",
      "Parameter id: 178 Numerical gradient of 0.002867 is not close to the backpropagation gradient of -0.740875!\n",
      "Parameter id: 179 Numerical gradient of -0.002087 is not close to the backpropagation gradient of 1.412252!\n",
      "Parameter id: 180 Numerical gradient of -0.006724 is not close to the backpropagation gradient of -1.294583!\n",
      "Parameter id: 181 Numerical gradient of -0.011723 is not close to the backpropagation gradient of -1.362507!\n",
      "Parameter id: 182 Numerical gradient of -0.009040 is not close to the backpropagation gradient of -1.259870!\n",
      "Parameter id: 183 Numerical gradient of -0.009100 is not close to the backpropagation gradient of -1.091348!\n",
      "Parameter id: 184 Numerical gradient of -0.116143 is not close to the backpropagation gradient of -15.377721!\n",
      "Parameter id: 185 Numerical gradient of 0.046124 is not close to the backpropagation gradient of 5.168588!\n",
      "Parameter id: 186 Numerical gradient of -0.001482 is not close to the backpropagation gradient of 0.880618!\n",
      "Parameter id: 187 Numerical gradient of 0.029822 is not close to the backpropagation gradient of 3.896571!\n",
      "Parameter id: 188 Numerical gradient of 0.033558 is not close to the backpropagation gradient of 3.460104!\n",
      "Parameter id: 189 Numerical gradient of 0.038987 is not close to the backpropagation gradient of 4.671509!\n",
      "Parameter id: 190 Numerical gradient of -0.058567 is not close to the backpropagation gradient of -7.579122!\n",
      "Parameter id: 191 Numerical gradient of 0.026402 is not close to the backpropagation gradient of 2.816767!\n",
      "Parameter id: 192 Numerical gradient of 0.003673 is not close to the backpropagation gradient of 0.448781!\n",
      "Parameter id: 193 Numerical gradient of -0.008916 is not close to the backpropagation gradient of 0.597070!\n",
      "Parameter id: 194 Numerical gradient of 0.006541 is not close to the backpropagation gradient of 1.016834!\n",
      "Parameter id: 195 Numerical gradient of -0.137129 is not close to the backpropagation gradient of -18.322818!\n",
      "Parameter id: 196 Numerical gradient of 0.057768 is not close to the backpropagation gradient of 6.541170!\n",
      "Parameter id: 197 Numerical gradient of 0.009929 is not close to the backpropagation gradient of 2.273960!\n",
      "Parameter id: 198 Numerical gradient of 0.034682 is not close to the backpropagation gradient of 4.561645!\n",
      "Parameter id: 199 Numerical gradient of 0.029463 is not close to the backpropagation gradient of 3.043362!\n",
      "Parameter id: 200 Numerical gradient of 0.036498 is not close to the backpropagation gradient of 4.600088!\n",
      "Parameter id: 201 Numerical gradient of -0.064508 is not close to the backpropagation gradient of -8.362456!\n",
      "Parameter id: 202 Numerical gradient of 0.031732 is not close to the backpropagation gradient of 3.400475!\n",
      "Parameter id: 203 Numerical gradient of 0.005199 is not close to the backpropagation gradient of 0.678460!\n",
      "Parameter id: 204 Numerical gradient of 0.003280 is not close to the backpropagation gradient of 2.075805!\n",
      "Parameter id: 205 Numerical gradient of -0.006912 is not close to the backpropagation gradient of -0.489693!\n",
      "Parameter id: 206 Numerical gradient of -0.128956 is not close to the backpropagation gradient of -17.199780!\n",
      "Parameter id: 207 Numerical gradient of 0.041032 is not close to the backpropagation gradient of 4.767256!\n",
      "Parameter id: 208 Numerical gradient of -0.000977 is not close to the backpropagation gradient of 1.129167!\n",
      "Parameter id: 209 Numerical gradient of 0.027393 is not close to the backpropagation gradient of 3.754659!\n",
      "Parameter id: 210 Numerical gradient of 0.028918 is not close to the backpropagation gradient of 3.010024!\n",
      "Parameter id: 211 Numerical gradient of 0.038055 is not close to the backpropagation gradient of 4.681328!\n",
      "Parameter id: 212 Numerical gradient of -0.054244 is not close to the backpropagation gradient of -7.188715!\n",
      "Parameter id: 213 Numerical gradient of 0.032175 is not close to the backpropagation gradient of 3.439889!\n",
      "Parameter id: 214 Numerical gradient of 0.008618 is not close to the backpropagation gradient of 1.007589!\n",
      "Parameter id: 215 Numerical gradient of 0.007538 is not close to the backpropagation gradient of 2.374778!\n",
      "Parameter id: 216 Numerical gradient of 0.000449 is not close to the backpropagation gradient of 0.223806!\n",
      "Parameter id: 217 Numerical gradient of 0.135612 is not close to the backpropagation gradient of 18.181755!\n",
      "Parameter id: 218 Numerical gradient of -0.053140 is not close to the backpropagation gradient of -6.026671!\n",
      "Parameter id: 219 Numerical gradient of -0.006890 is not close to the backpropagation gradient of -1.969049!\n",
      "Parameter id: 220 Numerical gradient of -0.033599 is not close to the backpropagation gradient of -4.439505!\n",
      "Parameter id: 221 Numerical gradient of -0.029701 is not close to the backpropagation gradient of -3.092761!\n",
      "Parameter id: 222 Numerical gradient of -0.037229 is not close to the backpropagation gradient of -4.672055!\n",
      "Parameter id: 223 Numerical gradient of 0.062325 is not close to the backpropagation gradient of 8.106054!\n",
      "Parameter id: 224 Numerical gradient of -0.031969 is not close to the backpropagation gradient of -3.433808!\n",
      "Parameter id: 225 Numerical gradient of -0.005983 is not close to the backpropagation gradient of -0.768960!\n",
      "Parameter id: 226 Numerical gradient of -0.004132 is not close to the backpropagation gradient of -2.159802!\n",
      "Parameter id: 227 Numerical gradient of 0.004706 is not close to the backpropagation gradient of 0.274801!\n",
      "Parameter id: 228 Numerical gradient of -0.131718 is not close to the backpropagation gradient of -17.786961!\n",
      "Parameter id: 229 Numerical gradient of 0.029704 is not close to the backpropagation gradient of 4.182766!\n",
      "Parameter id: 230 Numerical gradient of -0.004970 is not close to the backpropagation gradient of 0.977325!\n",
      "Parameter id: 231 Numerical gradient of 0.021443 is not close to the backpropagation gradient of 3.488844!\n",
      "Parameter id: 232 Numerical gradient of 0.024273 is not close to the backpropagation gradient of 2.784913!\n",
      "Parameter id: 233 Numerical gradient of 0.038138 is not close to the backpropagation gradient of 4.781739!\n",
      "Parameter id: 234 Numerical gradient of -0.046222 is not close to the backpropagation gradient of -6.734034!\n",
      "Parameter id: 235 Numerical gradient of 0.036129 is not close to the backpropagation gradient of 3.779732!\n",
      "Parameter id: 236 Numerical gradient of 0.012281 is not close to the backpropagation gradient of 1.252783!\n",
      "Parameter id: 237 Numerical gradient of 0.017888 is not close to the backpropagation gradient of 3.063902!\n",
      "Parameter id: 238 Numerical gradient of 0.003055 is not close to the backpropagation gradient of 0.208989!\n",
      "Parameter id: 239 Numerical gradient of 0.123480 is not close to the backpropagation gradient of 16.704067!\n",
      "Parameter id: 240 Numerical gradient of -0.044678 is not close to the backpropagation gradient of -5.177025!\n",
      "Parameter id: 241 Numerical gradient of 0.002659 is not close to the backpropagation gradient of -0.971170!\n",
      "Parameter id: 242 Numerical gradient of -0.027482 is not close to the backpropagation gradient of -3.808897!\n",
      "Parameter id: 243 Numerical gradient of -0.031538 is not close to the backpropagation gradient of -3.315478!\n",
      "Parameter id: 244 Numerical gradient of -0.038930 is not close to the backpropagation gradient of -4.737564!\n",
      "Parameter id: 245 Numerical gradient of 0.057771 is not close to the backpropagation gradient of 7.598355!\n",
      "Parameter id: 246 Numerical gradient of -0.029833 is not close to the backpropagation gradient of -3.204175!\n",
      "Parameter id: 247 Numerical gradient of -0.007697 is not close to the backpropagation gradient of -0.876553!\n",
      "Parameter id: 248 Numerical gradient of 0.001341 is not close to the backpropagation gradient of -1.540826!\n",
      "Parameter id: 249 Numerical gradient of -0.005095 is not close to the backpropagation gradient of -0.670735!\n",
      "Parameter id: 250 Numerical gradient of 0.105875 is not close to the backpropagation gradient of 15.288383!\n",
      "Parameter id: 251 Numerical gradient of -0.070712 is not close to the backpropagation gradient of -7.797227!\n",
      "Parameter id: 252 Numerical gradient of -0.009187 is not close to the backpropagation gradient of -2.190153!\n",
      "Parameter id: 253 Numerical gradient of -0.031130 is not close to the backpropagation gradient of -4.222232!\n",
      "Parameter id: 254 Numerical gradient of -0.023964 is not close to the backpropagation gradient of -2.513295!\n",
      "Parameter id: 255 Numerical gradient of -0.031068 is not close to the backpropagation gradient of -4.099416!\n",
      "Parameter id: 256 Numerical gradient of 0.071504 is not close to the backpropagation gradient of 9.084160!\n",
      "Parameter id: 257 Numerical gradient of -0.026967 is not close to the backpropagation gradient of -2.936972!\n",
      "Parameter id: 258 Numerical gradient of 0.000167 is not close to the backpropagation gradient of -0.158305!\n",
      "Parameter id: 259 Numerical gradient of 0.002279 is not close to the backpropagation gradient of -1.542103!\n",
      "Parameter id: 260 Numerical gradient of 0.013202 is not close to the backpropagation gradient of 1.087162!\n"
     ]
    }
   ],
   "source": [
    "# Do gradient checking\n",
    "model = ModelSort(input_size, output_size, hidden_size, seq_length)\n",
    "# Get the gradients of the parameters from a subset of the data\n",
    "backprop_grads = model.get_gradients(\n",
    "    x_train[:100], y_train[:100])\n",
    "\n",
    "eps = 1e-9  # Set the small change to compute the numerical gradient\n",
    "# Compute the numerical gradients of the parameters in all layers.\n",
    "for p_idx, param in enumerate(model.get_params_iter()):\n",
    "    grad_backprop = backprop_grads[p_idx]\n",
    "    # + eps\n",
    "    param += eps\n",
    "    plus_loss = model.loss(\n",
    "        model.predict_proba(x_train[0:100,:,:]), y_train[0:100,:,:])\n",
    "    # - eps\n",
    "    param -= 2 * eps\n",
    "    min_loss = model.loss(\n",
    "        model.predict_proba(x_train[0:100,:,:]), y_train[0:100,:,:])\n",
    "    # reset param value\n",
    "    param += eps\n",
    "    # calculate numerical gradient\n",
    "    grad_num = (plus_loss - min_loss) / (2*eps)\n",
    "    # Raise error if the numerical grade is not close to the \n",
    "    #  backprop gradient\n",
    "    if not np.isclose(grad_num, grad_backprop):\n",
    "        print((\n",
    "            f'Parameter id: {p_idx} '\n",
    "            f'Numerical gradient of {grad_num:.6f} is not close '\n",
    "            f'to the backpropagation gradient of {grad_backprop:.6f}!'\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
